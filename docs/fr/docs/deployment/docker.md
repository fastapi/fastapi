# FastAPI dans des conteneurs - Docker { #fastapi-in-containers-docker }

Lors du d√©ploiement d'applications FastAPI, une approche courante consiste √† construire une **image de conteneur Linux**. C'est g√©n√©ralement fait avec <a href="https://www.docker.com/" class="external-link" target="_blank">**Docker**</a>. Vous pouvez ensuite d√©ployer cette image de conteneur de plusieurs fa√ßons possibles.

L'utilisation de conteneurs Linux pr√©sente plusieurs avantages, notamment la **s√©curit√©**, la **r√©plicabilit√©**, la **simplicit√©**, entre autres.

/// tip | Astuce

Vous √™tes press√© et vous connaissez d√©j√† tout √ßa ? Allez directement au [`Dockerfile` ci-dessous üëá](#build-a-docker-image-for-fastapi).

///

<details>
<summary>Aper√ßu du Dockerfile üëÄ</summary>

```Dockerfile
FROM python:3.14

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

CMD ["fastapi", "run", "app/main.py", "--port", "80"]

# Si vous ex√©cutez derri√®re un proxy comme Nginx ou Traefik, ajoutez --proxy-headers
# CMD ["fastapi", "run", "app/main.py", "--port", "80", "--proxy-headers"]
```

</details>

## Qu'est-ce qu'un conteneur { #what-is-a-container }

Les conteneurs (principalement les conteneurs Linux) sont un moyen tr√®s **l√©ger** d'empaqueter des applications, y compris toutes leurs d√©pendances et les fichiers n√©cessaires, tout en les isolant des autres conteneurs (autres applications ou composants) dans le m√™me syst√®me.

Les conteneurs Linux s'ex√©cutent en utilisant le m√™me noyau Linux que l'h√¥te (machine, machine virtuelle, serveur cloud, etc.). Cela signifie simplement qu'ils sont tr√®s l√©gers (compar√©s √† des machines virtuelles compl√®tes √©mulant un syst√®me d'exploitation entier).

Ainsi, les conteneurs consomment **peu de ressources**, une quantit√© comparable √† l'ex√©cution directe des processus (alors qu'une machine virtuelle consommerait beaucoup plus).

Les conteneurs ont √©galement leurs propres processus d'ex√©cution **isol√©s** (g√©n√©ralement un seul processus), leur syst√®me de fichiers et leur r√©seau, ce qui simplifie le d√©ploiement, la s√©curit√©, le d√©veloppement, etc.

## Qu'est-ce qu'une image de conteneur { #what-is-a-container-image }

Un **conteneur** s'ex√©cute √† partir d'une **image de conteneur**.

Une image de conteneur est une version **statique** de tous les fichiers, des variables d'environnement et de la commande/le programme par d√©faut devant √™tre pr√©sents dans un conteneur. Ici, **statique** signifie que l'**image** du conteneur ne s'ex√©cute pas, elle n'est pas en cours d'ex√©cution, ce ne sont que les fichiers et m√©tadonn√©es empaquet√©s.

Par opposition √† une ¬´ **image de conteneur** ¬ª qui correspond aux contenus statiques stock√©s, un ¬´ **conteneur** ¬ª fait normalement r√©f√©rence √† l'instance en cours d'ex√©cution, la chose qui est **ex√©cut√©e**.

Lorsque le **conteneur** est d√©marr√© et en cours d'ex√©cution (d√©marr√© √† partir d'une **image de conteneur**), il peut cr√©er ou modifier des fichiers, des variables d'environnement, etc. Ces changements n'existeront que dans ce conteneur, mais ne persisteront pas dans l'image de conteneur sous-jacente (ils ne seront pas enregistr√©s sur le disque).

Une image de conteneur est comparable au **programme** et √† ses contenus, par exemple `python` et un fichier `main.py`.

Et le **conteneur** lui-m√™me (par opposition √† l'**image de conteneur**) est l'instance en cours d'ex√©cution r√©elle de l'image, comparable √† un **processus**. En fait, un conteneur ne fonctionne que lorsqu'il a un **processus en cours d'ex√©cution** (et normalement, il s'agit d'un seul processus). Le conteneur s'arr√™te lorsqu'aucun processus n'y est en cours d'ex√©cution.

## Images de conteneur { #container-images }

Docker a √©t√© l'un des principaux outils pour cr√©er et g√©rer des **images de conteneur** et des **conteneurs**.

Et il existe un <a href="https://hub.docker.com/" class="external-link" target="_blank">Docker Hub</a> public avec des **images de conteneur officielles** pr√©-construites pour de nombreux outils, environnements, bases de donn√©es et applications.

Par exemple, il existe une <a href="https://hub.docker.com/_/python" class="external-link" target="_blank">image Python officielle</a>.

Et il existe beaucoup d'autres images pour diff√©rentes choses comme des bases de donn√©es, par exemple :

* <a href="https://hub.docker.com/_/postgres" class="external-link" target="_blank">PostgreSQL</a>
* <a href="https://hub.docker.com/_/mysql" class="external-link" target="_blank">MySQL</a>
* <a href="https://hub.docker.com/_/mongo" class="external-link" target="_blank">MongoDB</a>
* <a href="https://hub.docker.com/_/redis" class="external-link" target="_blank">Redis</a>, etc.

En utilisant une image de conteneur pr√©-construite, il est tr√®s facile de **combiner** et d'utiliser diff√©rents outils. Par exemple, pour essayer une nouvelle base de donn√©es. Dans la plupart des cas, vous pouvez utiliser les **images officielles** et simplement les configurer avec des variables d'environnement.

Ainsi, dans de nombreux cas, vous pouvez apprendre les conteneurs et Docker et r√©utiliser ces connaissances avec de nombreux outils et composants diff√©rents.

Vous ex√©cuteriez donc **plusieurs conteneurs** avec des √©l√©ments diff√©rents, comme une base de donn√©es, une application Python, un serveur web avec une application frontend React, et les connecter entre eux via leur r√©seau interne.

Tous les syst√®mes de gestion de conteneurs (comme Docker ou Kubernetes) disposent de ces fonctionnalit√©s r√©seau int√©gr√©es.

## Conteneurs et processus { #containers-and-processes }

Une **image de conteneur** inclut normalement dans ses m√©tadonn√©es le programme/la commande par d√©faut √† ex√©cuter lorsque le **conteneur** est d√©marr√© et les param√®tres √† transmettre √† ce programme. Tr√®s similaire √† ce que vous utiliseriez en ligne de commande.

Lorsqu'un **conteneur** est d√©marr√©, il ex√©cutera cette commande/ce programme (bien que vous puissiez la/le remplacer et faire ex√©cuter une autre commande/un autre programme).

Un conteneur fonctionne tant que le **processus principal** (commande ou programme) est en cours d'ex√©cution.

Un conteneur a normalement un **seul processus**, mais il est aussi possible de d√©marrer des sous-processus √† partir du processus principal, et ainsi vous aurez **plusieurs processus** dans le m√™me conteneur.

Mais il n'est pas possible d'avoir un conteneur en cours d'ex√©cution sans **au moins un processus en cours**. Si le processus principal s'arr√™te, le conteneur s'arr√™te.

## Construire une image Docker pour FastAPI { #build-a-docker-image-for-fastapi }

Tr√®s bien, construisons quelque chose maintenant ! üöÄ

Je vais vous montrer comment construire une **image Docker** pour FastAPI **√† partir de z√©ro**, bas√©e sur l'image **officielle Python**.

C'est ce que vous voudrez faire dans **la plupart des cas**, par exemple :

* Utiliser **Kubernetes** ou des outils similaires
* Ex√©cuter sur un **Raspberry Pi**
* Utiliser un service cloud qui ex√©cuterait une image de conteneur pour vous, etc.

### D√©pendances des paquets { #package-requirements }

Vous aurez normalement les **d√©pendances des paquets** de votre application dans un fichier.

Cela d√©pendra principalement de l'outil que vous utilisez pour **installer** ces d√©pendances.

La mani√®re la plus courante consiste √† avoir un fichier `requirements.txt` avec les noms des paquets et leurs versions, un par ligne.

Vous utiliserez bien s√ªr les m√™mes id√©es que vous avez lues dans [√Ä propos des versions de FastAPI](versions.md){.internal-link target=_blank} pour d√©finir les plages de versions.

Par exemple, votre `requirements.txt` pourrait ressembler √† :

```
fastapi[standard]>=0.113.0,<0.114.0
pydantic>=2.7.0,<3.0.0
```

Et vous installerez normalement ces d√©pendances de paquets avec `pip`, par exemple :

<div class="termy">

```console
$ pip install -r requirements.txt
---> 100%
Successfully installed fastapi pydantic
```

</div>

/// info

Il existe d'autres formats et outils pour d√©finir et installer des d√©pendances de paquets.

///

### Cr√©er le code **FastAPI** { #create-the-fastapi-code }

* Cr√©ez un r√©pertoire `app` et entrez dedans.
* Cr√©ez un fichier vide `__init__.py`.
* Cr√©ez un fichier `main.py` avec :

```Python
from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: str | None = None):
    return {"item_id": item_id, "q": q}
```

### Dockerfile { #dockerfile }

Maintenant, dans le m√™me r√©pertoire de projet, cr√©ez un fichier `Dockerfile` avec :

```{ .dockerfile .annotate }
# (1)!
FROM python:3.14

# (2)!
WORKDIR /code

# (3)!
COPY ./requirements.txt /code/requirements.txt

# (4)!
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (5)!
COPY ./app /code/app

# (6)!
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

1. D√©marrer √† partir de l'image de base Python officielle.

2. D√©finir le r√©pertoire de travail courant sur `/code`.

    C'est l√† que nous placerons le fichier `requirements.txt` et le r√©pertoire `app`.

3. Copier le fichier des d√©pendances vers le r√©pertoire `/code`.

    Copier **uniquement** le fichier des d√©pendances en premier, pas le reste du code.

    Comme ce fichier **ne change pas souvent**, Docker le d√©tectera et utilisera le **cache** pour cette √©tape, ce qui activera le cache pour l'√©tape suivante aussi.

4. Installer les d√©pendances list√©es dans le fichier des d√©pendances.

    L'option `--no-cache-dir` indique √† `pip` de ne pas enregistrer localement les paquets t√©l√©charg√©s, car cela ne sert que si `pip` devait √™tre relanc√© pour installer les m√™mes paquets, mais ce n'est pas le cas lorsque l'on travaille avec des conteneurs.

    /// note | Remarque

    Le `--no-cache-dir` concerne uniquement `pip`, cela n'a rien √† voir avec Docker ou les conteneurs.

    ///

    L'option `--upgrade` indique √† `pip` de mettre √† niveau les paquets s'ils sont d√©j√† install√©s.

    Comme l'√©tape pr√©c√©dente de copie du fichier peut √™tre d√©tect√©e par le **cache Docker**, cette √©tape **utilisera √©galement le cache Docker** lorsqu'il est disponible.

    L'utilisation du cache √† cette √©tape vous **fera gagner** beaucoup de **temps** lors de la reconstruction de l'image encore et encore pendant le d√©veloppement, au lieu de **t√©l√©charger et installer** toutes les d√©pendances **√† chaque fois**.

5. Copier le r√©pertoire `./app` dans le r√©pertoire `/code`.

    Comme cela contient tout le code qui est ce qui **change le plus fr√©quemment**, le **cache** Docker ne sera pas facilement utilis√© pour cette √©tape ou pour les **√©tapes suivantes**.

    Il est donc important de placer cela **vers la fin** du `Dockerfile`, pour optimiser les temps de construction de l'image de conteneur.

6. D√©finir la **commande** pour utiliser `fastapi run`, qui utilise Uvicorn sous le capot.

    `CMD` prend une liste de cha√Ænes, chacune de ces cha√Ænes correspond √† ce que vous taperiez en ligne de commande s√©par√© par des espaces.

    Cette commande sera ex√©cut√©e √† partir du **r√©pertoire de travail courant**, le m√™me r√©pertoire `/code` que vous avez d√©fini plus haut avec `WORKDIR /code`.

/// tip | Astuce

Passez en revue ce que fait chaque ligne en cliquant sur chaque bulle num√©rot√©e dans le code. üëÜ

///

/// warning | Alertes

Vous devez vous assurer d'utiliser **toujours** la **forme exec** de l'instruction `CMD`, comme expliqu√© ci-dessous.

///

#### Utiliser `CMD` - Forme Exec { #use-cmd-exec-form }

L'instruction Docker <a href="https://docs.docker.com/reference/dockerfile/#cmd" class="external-link" target="_blank">`CMD`</a> peut √™tre √©crite sous deux formes :

‚úÖ Forme **Exec** :

```Dockerfile
# ‚úÖ √Ä faire
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

‚õîÔ∏è Forme **Shell** :

```Dockerfile
# ‚õîÔ∏è √Ä ne pas faire
CMD fastapi run app/main.py --port 80
```

Assurez-vous d'utiliser toujours la forme **exec** pour garantir que FastAPI peut s'arr√™ter proprement et que les [√©v√©nements de cycle de vie](../advanced/events.md){.internal-link target=_blank} sont d√©clench√©s.

Vous pouvez en lire davantage dans la <a href="https://docs.docker.com/reference/dockerfile/#shell-and-exec-form" class="external-link" target="_blank">documentation Docker sur les formes shell et exec</a>.

Cela peut √™tre tr√®s visible lors de l'utilisation de `docker compose`. Voir cette section de la FAQ Docker Compose pour plus de d√©tails techniques : <a href="https://docs.docker.com/compose/faq/#why-do-my-services-take-10-seconds-to-recreate-or-stop" class="external-link" target="_blank">Pourquoi mes services mettent-ils 10 secondes √† se recr√©er ou √† s'arr√™ter ?</a>.

#### Structure du r√©pertoire { #directory-structure }

Vous devriez maintenant avoir une structure de r√©pertoire comme :

```
.
‚îú‚îÄ‚îÄ app
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ requirements.txt
```

#### Derri√®re un proxy de terminaison TLS { #behind-a-tls-termination-proxy }

Si vous ex√©cutez votre conteneur derri√®re un proxy de terminaison TLS (load balancer) comme Nginx ou Traefik, ajoutez l'option `--proxy-headers`, cela indiquera √† Uvicorn (via la CLI FastAPI) de faire confiance aux en-t√™tes envoy√©s par ce proxy lui indiquant que l'application s'ex√©cute derri√®re HTTPS, etc.

```Dockerfile
CMD ["fastapi", "run", "app/main.py", "--proxy-headers", "--port", "80"]
```

#### Cache Docker { #docker-cache }

Il y a une astuce importante dans ce `Dockerfile`, nous copions d'abord **le fichier des d√©pendances seul**, pas le reste du code. Laissez-moi vous expliquer pourquoi.

```Dockerfile
COPY ./requirements.txt /code/requirements.txt
```

Docker et d'autres outils **construisent** ces images de conteneur **de mani√®re incr√©mentale**, en ajoutant **une couche au-dessus de l'autre**, en commen√ßant par le haut du `Dockerfile` et en ajoutant tous les fichiers cr√©√©s par chacune des instructions du `Dockerfile`.

Docker et des outils similaires utilisent √©galement un **cache interne** lors de la construction de l'image : si un fichier n'a pas chang√© depuis la derni√®re construction de l'image de conteneur, alors il va **r√©utiliser la m√™me couche** cr√©√©e la derni√®re fois, au lieu de recopier le fichier et cr√©er une nouvelle couche √† partir de z√©ro.

√âviter simplement la copie des fichiers n'am√©liore pas n√©cessairement les choses de mani√®re significative, mais comme il a utilis√© le cache pour cette √©tape, il peut **utiliser le cache pour l'√©tape suivante**. Par exemple, il peut utiliser le cache pour l'instruction qui installe les d√©pendances avec :

```Dockerfile
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt
```

Le fichier des d√©pendances **ne changera pas fr√©quemment**. Ainsi, en copiant uniquement ce fichier, Docker pourra **utiliser le cache** pour cette √©tape.

Et ensuite, Docker pourra **utiliser le cache pour l'√©tape suivante** qui t√©l√©charge et installe ces d√©pendances. Et c'est l√† que nous **gagnons beaucoup de temps**. ‚ú® ... et √©vitons l'ennui en attendant. üò™üòÜ

T√©l√©charger et installer les d√©pendances de paquets **peut prendre des minutes**, mais utiliser le **cache** ne **prendra que quelques secondes** au plus.

Et comme vous reconstruirez l'image de conteneur encore et encore pendant le d√©veloppement pour v√©rifier que vos modifications de code fonctionnent, cela vous fera gagner beaucoup de temps cumul√©.

Ensuite, vers la fin du `Dockerfile`, nous copions tout le code. Comme c'est ce qui **change le plus fr√©quemment**, nous le pla√ßons vers la fin, car presque toujours, tout ce qui suit cette √©tape ne pourra pas utiliser le cache.

```Dockerfile
COPY ./app /code/app
```

### Construire l'image Docker { #build-the-docker-image }

Maintenant que tous les fichiers sont en place, construisons l'image de conteneur.

* Allez dans le r√©pertoire du projet (l√† o√π se trouve votre `Dockerfile`, contenant votre r√©pertoire `app`).
* Construisez votre image FastAPI :

<div class="termy">

```console
$ docker build -t myimage .

---> 100%
```

</div>

/// tip | Astuce

Remarquez le `.` √† la fin, √©quivalent √† `./`, il indique √† Docker le r√©pertoire √† utiliser pour construire l'image de conteneur.

Dans ce cas, c'est le m√™me r√©pertoire courant (`.`).

///

### D√©marrer le conteneur Docker { #start-the-docker-container }

* Ex√©cutez un conteneur bas√© sur votre image :

<div class="termy">

```console
$ docker run -d --name mycontainer -p 80:80 myimage
```

</div>

## V√©rifier { #check-it }

Vous devriez pouvoir le v√©rifier via l'URL de votre conteneur Docker, par exemple : <a href="http://192.168.99.100/items/5?q=somequery" class="external-link" target="_blank">http://192.168.99.100/items/5?q=somequery</a> ou <a href="http://127.0.0.1/items/5?q=somequery" class="external-link" target="_blank">http://127.0.0.1/items/5?q=somequery</a> (ou √©quivalent, en utilisant votre h√¥te Docker).

Vous verrez quelque chose comme :

```JSON
{"item_id": 5, "q": "somequery"}
```

## Documentation interactive de l'API { #interactive-api-docs }

Vous pouvez maintenant aller sur <a href="http://192.168.99.100/docs" class="external-link" target="_blank">http://192.168.99.100/docs</a> ou <a href="http://127.0.0.1/docs" class="external-link" target="_blank">http://127.0.0.1/docs</a> (ou √©quivalent, en utilisant votre h√¥te Docker).

Vous verrez la documentation interactive automatique de l'API (fournie par <a href="https://github.com/swagger-api/swagger-ui" class="external-link" target="_blank">Swagger UI</a>) :

![Swagger UI](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)

## Documentation alternative de l'API { #alternative-api-docs }

Et vous pouvez aussi aller sur <a href="http://192.168.99.100/redoc" class="external-link" target="_blank">http://192.168.99.100/redoc</a> ou <a href="http://127.0.0.1/redoc" class="external-link" target="_blank">http://127.0.0.1/redoc</a> (ou √©quivalent, en utilisant votre h√¥te Docker).

Vous verrez la documentation automatique alternative (fournie par <a href="https://github.com/Rebilly/ReDoc" class="external-link" target="_blank">ReDoc</a>) :

![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)

## Construire une image Docker avec un FastAPI mono-fichier { #build-a-docker-image-with-a-single-file-fastapi }

Si votre FastAPI est un seul fichier, par exemple `main.py` sans r√©pertoire `./app`, votre structure de fichiers pourrait ressembler √† ceci :

```
.
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ requirements.txt
```

Vous n'auriez alors qu'√† changer les chemins correspondants pour copier le fichier dans le `Dockerfile` :

```{ .dockerfile .annotate hl_lines="10  13" }
FROM python:3.14

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (1)!
COPY ./main.py /code/

# (2)!
CMD ["fastapi", "run", "main.py", "--port", "80"]
```

1. Copier le fichier `main.py` directement dans le r√©pertoire `/code` (sans r√©pertoire `./app`).

2. Utiliser `fastapi run` pour servir votre application dans le fichier unique `main.py`.

Lorsque vous passez le fichier √† `fastapi run`, il d√©tectera automatiquement qu'il s'agit d'un fichier unique et non d'un package et saura comment l'importer et servir votre application FastAPI. üòé

## Concepts de d√©ploiement { #deployment-concepts }

Parlons √† nouveau de certains des m√™mes [Concepts de d√©ploiement](concepts.md){.internal-link target=_blank} en termes de conteneurs.

Les conteneurs sont principalement un outil pour simplifier le processus de **construction et de d√©ploiement** d'une application, mais ils n'imposent pas une approche particuli√®re pour g√©rer ces **concepts de d√©ploiement**, et il existe plusieurs strat√©gies possibles.

La **bonne nouvelle**, c'est qu'avec chaque strat√©gie diff√©rente, il existe un moyen de couvrir tous les concepts de d√©ploiement. üéâ

Passons en revue ces **concepts de d√©ploiement** en termes de conteneurs :

* HTTPS
* Ex√©cution au d√©marrage
* Red√©marrages
* R√©plication (le nombre de processus en cours d'ex√©cution)
* M√©moire
* √âtapes pr√©alables au d√©marrage

## HTTPS { #https }

Si l'on se concentre uniquement sur l'**image de conteneur** pour une application FastAPI (et plus tard sur le **conteneur** en cours d'ex√©cution), HTTPS serait normalement g√©r√© **√† l'ext√©rieur** par un autre outil.

Cela pourrait √™tre un autre conteneur, par exemple avec <a href="https://traefik.io/" class="external-link" target="_blank">Traefik</a>, g√©rant **HTTPS** et l'acquisition **automatique** des **certificats**.

/// tip | Astuce

Traefik s'int√®gre avec Docker, Kubernetes, et d'autres, donc il est tr√®s facile de configurer HTTPS pour vos conteneurs avec lui.

///

Alternativement, HTTPS pourrait √™tre g√©r√© par un fournisseur cloud comme l'un de leurs services (tout en ex√©cutant l'application dans un conteneur).

## Ex√©cution au d√©marrage et red√©marrages { #running-on-startup-and-restarts }

Il y a normalement un autre outil charg√© de **d√©marrer et ex√©cuter** votre conteneur.

Cela pourrait √™tre **Docker** directement, **Docker Compose**, **Kubernetes**, un **service cloud**, etc.

Dans la plupart (ou toutes) des situations, il existe une option simple pour activer l'ex√©cution du conteneur au d√©marrage et activer les red√©marrages en cas d'√©chec. Par exemple, dans Docker, c'est l'option de ligne de commande `--restart`.

Sans utiliser de conteneurs, faire en sorte que les applications s'ex√©cutent au d√©marrage et avec red√©marrages peut √™tre fastidieux et difficile. Mais en **travaillant avec des conteneurs**, dans la plupart des cas, cette fonctionnalit√© est incluse par d√©faut. ‚ú®

## R√©plication - Nombre de processus { #replication-number-of-processes }

Si vous avez un <dfn title="Groupe de machines configur√©es pour √™tre connect√©es et fonctionner ensemble d'une certaine mani√®re.">cluster</dfn> de machines avec **Kubernetes**, Docker Swarm Mode, Nomad, ou un autre syst√®me complexe similaire pour g√©rer des conteneurs distribu√©s sur plusieurs machines, alors vous voudrez probablement **g√©rer la r√©plication** au **niveau du cluster** plut√¥t que d'utiliser un **gestionnaire de processus** (comme Uvicorn avec workers) dans chaque conteneur.

L'un de ces syst√®mes de gestion de conteneurs distribu√©s comme Kubernetes dispose normalement d'une mani√®re int√©gr√©e de g√©rer la **r√©plication des conteneurs** tout en supportant l'**√©quilibrage de charge** des requ√™tes entrantes. Le tout au **niveau du cluster**.

Dans ces cas, vous voudrez probablement construire une **image Docker √† partir de z√©ro** comme [expliqu√© ci-dessus](#dockerfile), en installant vos d√©pendances et en ex√©cutant **un seul processus Uvicorn** au lieu d'utiliser plusieurs workers Uvicorn.

### √âquilibreur de charge { #load-balancer }

Lors de l'utilisation de conteneurs, vous aurez normalement un composant **√† l'√©coute sur le port principal**. Cela pourrait √™tre un autre conteneur qui est √©galement un **proxy de terminaison TLS** pour g√©rer **HTTPS** ou un outil similaire.

Comme ce composant prend la **charge** des requ√™tes et la distribue entre les workers de fa√ßon (esp√©rons-le) **√©quilibr√©e**, on l'appelle √©galement commun√©ment un **√©quilibreur de charge**.

/// tip | Astuce

Le m√™me composant de **proxy de terminaison TLS** utilis√© pour HTTPS sera probablement aussi un **√©quilibreur de charge**.

///

Et en travaillant avec des conteneurs, le m√™me syst√®me que vous utilisez pour les d√©marrer et les g√©rer dispose d√©j√† d'outils internes pour transmettre la **communication r√©seau** (par ex. les requ√™tes HTTP) depuis cet **√©quilibreur de charge** (qui peut aussi √™tre un **proxy de terminaison TLS**) vers le ou les conteneurs avec votre application.

### Un √©quilibreur de charge - Plusieurs conteneurs worker { #one-load-balancer-multiple-worker-containers }

Lorsque vous travaillez avec **Kubernetes** ou des syst√®mes de gestion de conteneurs distribu√©s similaires, l'utilisation de leurs m√©canismes r√©seau internes permet au **seul √©quilibreur de charge** √† l'√©coute sur le **port** principal de transmettre la communication (les requ√™tes) vers potentiellement **plusieurs conteneurs** ex√©cutant votre application.

Chacun de ces conteneurs ex√©cutant votre application aura normalement **un seul processus** (par ex. un processus Uvicorn ex√©cutant votre application FastAPI). Ils seront tous des **conteneurs identiques**, ex√©cutant la m√™me chose, mais chacun avec son propre processus, sa m√©moire, etc. De cette fa√ßon, vous profiterez de la **parall√©lisation** sur **diff√©rents c≈ìurs** du CPU, voire sur **diff√©rentes machines**.

Et le syst√®me de conteneurs distribu√©s avec l'**√©quilibreur de charge** **distribuera les requ√™tes** √† chacun des conteneurs ex√©cutant votre application **√† tour de r√¥le**. Ainsi, chaque requ√™te pourrait √™tre trait√©e par l'un des multiples **conteneurs r√©pliqu√©s** ex√©cutant votre application.

Et normalement cet **√©quilibreur de charge** pourra g√©rer des requ√™tes qui vont vers *d'autres* applications dans votre cluster (par ex. vers un autre domaine, ou sous un autre pr√©fixe de chemin d'URL), et transmettra cette communication aux bons conteneurs pour *cette autre* application s'ex√©cutant dans votre cluster.

### Un processus par conteneur { #one-process-per-container }

Dans ce type de sc√©nario, vous voudrez probablement avoir **un seul processus (Uvicorn) par conteneur**, puisque vous g√©rez d√©j√† la r√©plication au niveau du cluster.

Donc, dans ce cas, vous **ne voudrez pas** avoir plusieurs workers dans le conteneur, par exemple avec l'option de ligne de commande `--workers`. Vous voudrez avoir **un seul processus Uvicorn** par conteneur (mais probablement plusieurs conteneurs).

Avoir un autre gestionnaire de processus √† l'int√©rieur du conteneur (comme ce serait le cas avec plusieurs workers) n'ajouterait que de la **complexit√© inutile** que vous g√©rez tr√®s probablement d√©j√† avec votre syst√®me de cluster.

### Conteneurs avec plusieurs processus et cas particuliers { #containers-with-multiple-processes-and-special-cases }

Bien s√ªr, il existe des **cas particuliers** o√π vous pourriez vouloir avoir **un conteneur** avec plusieurs **processus worker Uvicorn** √† l'int√©rieur.

Dans ces cas, vous pouvez utiliser l'option de ligne de commande `--workers` pour d√©finir le nombre de workers que vous souhaitez ex√©cuter :

```{ .dockerfile .annotate }
FROM python:3.14

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

# (1)!
CMD ["fastapi", "run", "app/main.py", "--port", "80", "--workers", "4"]
```

1. Ici, nous utilisons l'option de ligne de commande `--workers` pour d√©finir le nombre de workers √† 4.

Voici quelques exemples o√π cela pourrait avoir du sens :

#### Une application simple { #a-simple-app }

Vous pourriez vouloir un gestionnaire de processus dans le conteneur si votre application est **suffisamment simple** pour s'ex√©cuter sur un **seul serveur**, pas un cluster.

#### Docker Compose { #docker-compose }

Vous pourriez d√©ployer sur un **seul serveur** (pas un cluster) avec **Docker Compose**, donc vous n'auriez pas un moyen simple de g√©rer la r√©plication des conteneurs (avec Docker Compose) tout en pr√©servant le r√©seau partag√© et l'**√©quilibrage de charge**.

Vous pourriez alors vouloir avoir **un seul conteneur** avec un **gestionnaire de processus** qui d√©marre **plusieurs processus worker** √† l'int√©rieur.

---

L'id√©e principale est que **rien** de tout cela ne sont des **r√®gles grav√©es dans la pierre** que vous devez suivre aveugl√©ment. Vous pouvez utiliser ces id√©es pour **√©valuer votre propre cas d'usage** et d√©cider de la meilleure approche pour votre syst√®me, en v√©rifiant comment g√©rer les concepts suivants :

* S√©curit√© - HTTPS
* Ex√©cution au d√©marrage
* Red√©marrages
* R√©plication (le nombre de processus en cours d'ex√©cution)
* M√©moire
* √âtapes pr√©alables au d√©marrage

## M√©moire { #memory }

Si vous ex√©cutez **un seul processus par conteneur**, vous aurez une quantit√© de m√©moire consomm√©e plus ou moins bien d√©finie, stable et limit√©e par chacun de ces conteneurs (plus d'un s'ils sont r√©pliqu√©s).

Vous pouvez alors d√©finir ces m√™mes limites et exigences de m√©moire dans vos configurations pour votre syst√®me de gestion de conteneurs (par exemple dans **Kubernetes**). De cette fa√ßon, il pourra **r√©pliquer les conteneurs** sur les **machines disponibles** en tenant compte de la quantit√© de m√©moire dont ils ont besoin et de la quantit√© disponible sur les machines du cluster.

Si votre application est **simple**, cela ne sera probablement **pas un probl√®me**, et vous n'aurez peut-√™tre pas besoin de sp√©cifier des limites de m√©moire strictes. Mais si vous **utilisez beaucoup de m√©moire** (par exemple avec des mod√®les de **machine learning**), vous devez v√©rifier combien de m√©moire vous consommez et ajuster le **nombre de conteneurs** qui s'ex√©cutent sur **chaque machine** (et peut-√™tre ajouter plus de machines √† votre cluster).

Si vous ex√©cutez **plusieurs processus par conteneur**, vous devez vous assurer que le nombre de processus d√©marr√©s ne **consomme pas plus de m√©moire** que ce qui est disponible.

## √âtapes pr√©alables au d√©marrage et conteneurs { #previous-steps-before-starting-and-containers }

Si vous utilisez des conteneurs (par ex. Docker, Kubernetes), alors il existe deux approches principales que vous pouvez utiliser.

### Plusieurs conteneurs { #multiple-containers }

Si vous avez **plusieurs conteneurs**, probablement chacun ex√©cutant un **seul processus** (par exemple, dans un cluster **Kubernetes**), alors vous voudrez probablement avoir un **conteneur s√©par√©** effectuant le travail des **√©tapes pr√©alables** dans un seul conteneur, ex√©cutant un seul processus, **avant** d'ex√©cuter les conteneurs worker r√©pliqu√©s.

/// info

Si vous utilisez Kubernetes, ce sera probablement un <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" class="external-link" target="_blank">Init Container</a>.

///

Si, dans votre cas d'usage, il n'y a pas de probl√®me √† ex√©cuter ces √©tapes pr√©alables **plusieurs fois en parall√®le** (par exemple si vous n'ex√©cutez pas de migrations de base de donn√©es, mais v√©rifiez simplement si la base de donn√©es est pr√™te), alors vous pourriez aussi simplement les mettre dans chaque conteneur juste avant de d√©marrer le processus principal.

### Un seul conteneur { #single-container }

Si vous avez une configuration simple, avec **un seul conteneur** qui d√©marre ensuite plusieurs **processus worker** (ou un seul processus aussi), vous pouvez alors ex√©cuter ces √©tapes pr√©alables dans le m√™me conteneur, juste avant de d√©marrer le processus avec l'application.

### Image Docker de base { #base-docker-image }

Il existait une image Docker officielle FastAPI : <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>. Mais elle est d√©sormais d√©pr√©ci√©e. ‚õîÔ∏è

Vous ne devriez probablement **pas** utiliser cette image Docker de base (ni aucune autre similaire).

Si vous utilisez **Kubernetes** (ou autres) et que vous d√©finissez d√©j√† la **r√©plication** au niveau du cluster, avec plusieurs **conteneurs**. Dans ces cas, il est pr√©f√©rable de **construire une image √† partir de z√©ro** comme d√©crit ci-dessus : [Construire une image Docker pour FastAPI](#build-a-docker-image-for-fastapi).

Et si vous devez avoir plusieurs workers, vous pouvez simplement utiliser l'option de ligne de commande `--workers`.

/// note | D√©tails techniques

L'image Docker a √©t√© cr√©√©e √† une √©poque o√π Uvicorn ne supportait pas la gestion et le red√©marrage des workers morts, il fallait donc utiliser Gunicorn avec Uvicorn, ce qui ajoutait pas mal de complexit√©, uniquement pour que Gunicorn g√®re et red√©marre les processus worker Uvicorn.

Mais maintenant qu'Uvicorn (et la commande `fastapi`) supporte l'usage de `--workers`, il n'y a plus de raison d'utiliser une image Docker de base au lieu de construire la v√¥tre (c'est √† peu pr√®s la m√™me quantit√© de code üòÖ).

///

## D√©ployer l'image de conteneur { #deploy-the-container-image }

Apr√®s avoir une image de conteneur (Docker), il existe plusieurs fa√ßons de la d√©ployer.

Par exemple :

* Avec **Docker Compose** sur un seul serveur
* Avec un cluster **Kubernetes**
* Avec un cluster Docker Swarm Mode
* Avec un autre outil comme Nomad
* Avec un service cloud qui prend votre image de conteneur et la d√©ploie

## Image Docker avec `uv` { #docker-image-with-uv }

Si vous utilisez <a href="https://github.com/astral-sh/uv" class="external-link" target="_blank">uv</a> pour installer et g√©rer votre projet, vous pouvez suivre leur <a href="https://docs.astral.sh/uv/guides/integration/docker/" class="external-link" target="_blank">guide Docker pour uv</a>.

## R√©capitulatif { #recap }

Avec les syst√®mes de conteneurs (par ex. avec **Docker** et **Kubernetes**), il devient assez simple de g√©rer tous les **concepts de d√©ploiement** :

* HTTPS
* Ex√©cution au d√©marrage
* Red√©marrages
* R√©plication (le nombre de processus en cours d'ex√©cution)
* M√©moire
* √âtapes pr√©alables au d√©marrage

Dans la plupart des cas, vous ne voudrez probablement pas utiliser d'image de base, et au contraire **construire une image de conteneur √† partir de z√©ro** bas√©e sur l'image Docker Python officielle.

En prenant soin de l'**ordre** des instructions dans le `Dockerfile` et du **cache Docker**, vous pouvez **minimiser les temps de construction**, maximiser votre productivit√© (et √©viter l'ennui). üòé
