# FastAPI dans des conteneurs - Docker { #fastapi-in-containers-docker }

Lors du dÃ©ploiement d'applications FastAPI, une approche courante consiste Ã  construire une **image de conteneur Linux**. C'est gÃ©nÃ©ralement fait avec <a href="https://www.docker.com/" class="external-link" target="_blank">**Docker**</a>. Vous pouvez ensuite dÃ©ployer cette image de conteneur de plusieurs maniÃ¨res possibles.

L'utilisation de conteneurs Linux prÃ©sente plusieurs avantages, notamment la **sÃ©curitÃ©**, la **rÃ©plicabilitÃ©**, la **simplicitÃ©**, et d'autres.

/// tip | Astuce

PressÃ© et vous connaissez dÃ©jÃ  tout Ã§a ? Passez au [`Dockerfile` ci-dessous ğŸ‘‡](#build-a-docker-image-for-fastapi).

///

<details>
<summary>AperÃ§u du Dockerfile ğŸ‘€</summary>

```Dockerfile
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

CMD ["fastapi", "run", "app/main.py", "--port", "80"]

# Si vous exÃ©cutez derriÃ¨re un proxy comme Nginx ou Traefik, ajoutez --proxy-headers
# CMD ["fastapi", "run", "app/main.py", "--port", "80", "--proxy-headers"]
```

</details>

## Qu'est-ce qu'un conteneur { #what-is-a-container }

Les conteneurs (principalement les conteneurs Linux) sont une maniÃ¨re trÃ¨s **lÃ©gÃ¨re** d'emballer des applications, y compris toutes leurs dÃ©pendances et fichiers nÃ©cessaires, tout en les gardant isolÃ©es des autres conteneurs (autres applications ou composants) dans le mÃªme systÃ¨me.

Les conteneurs Linux s'exÃ©cutent en utilisant le mÃªme noyau Linux que lâ€™hÃ´te (machine, machine virtuelle, serveur cloud, etc.). Cela signifie simplement quâ€™ils sont trÃ¨s lÃ©gers (comparÃ©s aux machines virtuelles complÃ¨tes qui Ã©muleraient un systÃ¨me dâ€™exploitation entier).

De cette faÃ§on, les conteneurs consomment **peu de ressources**, une quantitÃ© comparable Ã  lâ€™exÃ©cution des processus directement (une machine virtuelle consommerait bien plus).

Les conteneurs ont Ã©galement leurs **processus isolÃ©s** (gÃ©nÃ©ralement un seul processus), leur systÃ¨me de fichiers et leur rÃ©seau, ce qui simplifie le dÃ©ploiement, la sÃ©curitÃ©, le dÃ©veloppement, etc.

## Qu'est-ce qu'une image de conteneur { #what-is-a-container-image }

Un **conteneur** est exÃ©cutÃ© Ã  partir dâ€™une **image de conteneur**.

Une image de conteneur est une version **statique** de tous les fichiers, variables dâ€™environnement et de la commande/programme par dÃ©faut qui doivent Ãªtre prÃ©sents dans un conteneur. **Statique** signifie ici que lâ€™**image** du conteneur nâ€™est pas en cours dâ€™exÃ©cution, elle nâ€™est pas exÃ©cutÃ©e, ce sont uniquement les fichiers et mÃ©tadonnÃ©es empaquetÃ©s.

Par opposition Ã  une Â«**image de conteneur**Â» qui est le contenu statique stockÃ©, un Â«**conteneur**Â» fait normalement rÃ©fÃ©rence Ã  lâ€™instance en cours dâ€™exÃ©cution, la chose qui est **exÃ©cutÃ©e**.

Lorsque le **conteneur** est dÃ©marrÃ© et en cours dâ€™exÃ©cution (dÃ©marrÃ© Ã  partir dâ€™une **image de conteneur**), il peut crÃ©er ou modifier des fichiers, des variables dâ€™environnement, etc. Ces changements nâ€™existeront que dans ce conteneur, mais ne persisteront pas dans lâ€™image de conteneur sous-jacente (ils ne seront pas sauvegardÃ©s sur le disque).

Une image de conteneur est comparable au **programme** et Ã  ses fichiers, par exemple `python` et un fichier `main.py`.

Et le **conteneur** lui-mÃªme (par opposition Ã  lâ€™**image de conteneur**) est lâ€™instance rÃ©ellement en cours dâ€™exÃ©cution de lâ€™image, comparable Ã  un **processus**. En fait, un conteneur nâ€™est en cours dâ€™exÃ©cution que lorsquâ€™il a un **processus en cours** (et normalement un seul processus). Le conteneur sâ€™arrÃªte lorsquâ€™il nâ€™y a plus de processus en cours Ã  lâ€™intÃ©rieur.

## Images de conteneur { #container-images }

Docker a Ã©tÃ© lâ€™un des principaux outils pour crÃ©er et gÃ©rer des **images de conteneur** et des **conteneurs**.

Il existe un <a href="https://hub.docker.com/" class="external-link" target="_blank">Docker Hub</a> public avec des **images de conteneur officielles** prÃ©construites pour de nombreux outils, environnements, bases de donnÃ©es et applications.

Par exemple, il existe une <a href="https://hub.docker.com/_/python" class="external-link" target="_blank">image Python</a> officielle.

Et il existe de nombreuses autres images pour diffÃ©rentes choses comme des bases de donnÃ©es, par exemple pourÂ :

* <a href="https://hub.docker.com/_/postgres" class="external-link" target="_blank">PostgreSQL</a>
* <a href="https://hub.docker.com/_/mysql" class="external-link" target="_blank">MySQL</a>
* <a href="https://hub.docker.com/_/mongo" class="external-link" target="_blank">MongoDB</a>
* <a href="https://hub.docker.com/_/redis" class="external-link" target="_blank">Redis</a>, etc.

En utilisant une image de conteneur prÃ©construite, il est trÃ¨s facile de **combiner** et dâ€™utiliser diffÃ©rents outils. Par exemple, pour essayer une nouvelle base de donnÃ©es. Dans la plupart des cas, vous pouvez utiliser les **images officielles**, et simplement les configurer avec des variables dâ€™environnement.

De cette maniÃ¨re, dans de nombreux cas, vous pouvez apprendre les conteneurs et Docker et rÃ©utiliser ces connaissances avec de nombreux outils et composants diffÃ©rents.

Ainsi, vous exÃ©cuteriez **plusieurs conteneurs** avec diffÃ©rentes choses, comme une base de donnÃ©es, une application Python, un serveur web avec une application frontend React, et vous les connecteriez ensemble via leur rÃ©seau interne.

Tous les systÃ¨mes de gestion de conteneurs (comme Docker ou Kubernetes) intÃ¨grent ces fonctionnalitÃ©s rÃ©seau.

## Conteneurs et processus { #containers-and-processes }

Une **image de conteneur** inclut normalement dans ses mÃ©tadonnÃ©es le programme ou la commande par dÃ©faut Ã  exÃ©cuter lorsque le **conteneur** est dÃ©marrÃ© et les paramÃ¨tres Ã  passer Ã  ce programme. TrÃ¨s similaire Ã  ce que vous feriez en ligne de commande.

Lorsquâ€™un **conteneur** est dÃ©marrÃ©, il exÃ©cute cette commande/ce programme (bien que vous puissiez la/le remplacer et faire exÃ©cuter une commande/un programme diffÃ©rent).

Un conteneur est en cours dâ€™exÃ©cution tant que le **processus principal** (commande ou programme) est en cours dâ€™exÃ©cution.

Un conteneur a normalement un **seul processus**, mais il est Ã©galement possible de dÃ©marrer des sous-processus Ã  partir du processus principal, et ainsi vous aurez **plusieurs processus** dans le mÃªme conteneur.

Mais il nâ€™est pas possible dâ€™avoir un conteneur en cours dâ€™exÃ©cution sans **au moins un processus en cours**. Si le processus principal sâ€™arrÃªte, le conteneur sâ€™arrÃªte.

## Construire une image Docker pour FastAPI { #build-a-docker-image-for-fastapi }

Dâ€™accord, construisons quelque chose maintenant ! ğŸš€

Je vais vous montrer comment construire une **image Docker** pour FastAPI **depuis zÃ©ro**, basÃ©e sur lâ€™image **Python officielle**.

Câ€™est ce que vous voudrez faire dans **la plupart des cas**, par exempleÂ :

* En utilisant **Kubernetes** ou des outils similaires
* Lors de lâ€™exÃ©cution sur un **Raspberry Pi**
* En utilisant un service cloud qui exÃ©cuterait une image de conteneur pour vous, etc.

### DÃ©pendances des packages { #package-requirements }

Vous avez normalement les **dÃ©pendances** de votre application dans un fichier.

Cela dÃ©pend principalement de lâ€™outil que vous utilisez pour **installer** ces dÃ©pendances.

La maniÃ¨re la plus courante de le faire est dâ€™avoir un fichier `requirements.txt` avec les noms des packages et leurs versions, un par ligne.

Vous utiliseriez bien sÃ»r les mÃªmes idÃ©es lues dans [Ã€ propos des versions de FastAPI](versions.md){.internal-link target=_blank} pour dÃ©finir les plages de versions.

Par exemple, votre `requirements.txt` pourrait ressembler Ã Â :

```
fastapi[standard]>=0.113.0,<0.114.0
pydantic>=2.7.0,<3.0.0
```

Et vous installeriez normalement ces dÃ©pendances de packages avec `pip`, par exempleÂ :

<div class="termy">

```console
$ pip install -r requirements.txt
---> 100%
Successfully installed fastapi pydantic
```

</div>

/// info

Il existe dâ€™autres formats et outils pour dÃ©finir et installer des dÃ©pendances de packages.

///

### CrÃ©er le code **FastAPI** { #create-the-fastapi-code }

* CrÃ©ez un rÃ©pertoire `app` et entrez dedans.
* CrÃ©ez un fichier vide `__init__.py`.
* CrÃ©ez un fichier `main.py` avecÂ :

```Python
from typing import Union

from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}
```

### Dockerfile { #dockerfile }

Maintenant, dans le mÃªme rÃ©pertoire de projet, crÃ©ez un fichier `Dockerfile` avecÂ :

```{ .dockerfile .annotate }
# (1)!
FROM python:3.9

# (2)!
WORKDIR /code

# (3)!
COPY ./requirements.txt /code/requirements.txt

# (4)!
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (5)!
COPY ./app /code/app

# (6)!
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

1. DÃ©marrer Ã  partir de lâ€™image de base Python officielle.

2. DÃ©finir le rÃ©pertoire de travail courant sur `/code`.

    Câ€™est lÃ  que nous placerons le fichier `requirements.txt` et le rÃ©pertoire `app`.

3. Copier le fichier des dÃ©pendances dans le rÃ©pertoire `/code`.

    Copier **uniquement** le fichier des dÃ©pendances en premier, pas le reste du code.

    Comme ce fichier **ne change pas souvent**, Docker le dÃ©tectera et utilisera le **cache** pour cette Ã©tape, activant aussi le cache pour lâ€™Ã©tape suivante.

4. Installer les dÃ©pendances de packages du fichier des dÃ©pendances.

    Lâ€™option `--no-cache-dir` indique Ã  `pip` de ne pas enregistrer localement les packages tÃ©lÃ©chargÃ©s, ce qui nâ€™est utile que si `pip` devait Ãªtre relancÃ© pour installer les mÃªmes packages, ce qui nâ€™est pas le cas lorsquâ€™on travaille avec des conteneurs.

    /// note | Remarque

    Le `--no-cache-dir` concerne uniquement `pip`, cela nâ€™a rien Ã  voir avec Docker ou les conteneurs.

    ///

    Lâ€™option `--upgrade` indique Ã  `pip` de mettre Ã  niveau les packages sâ€™ils sont dÃ©jÃ  installÃ©s.

    Comme lâ€™Ã©tape prÃ©cÃ©dente de copie du fichier peut Ãªtre dÃ©tectÃ©e par le **cache Docker**, cette Ã©tape **utilisera Ã©galement le cache Docker** lorsquâ€™il est disponible.

    Utiliser le cache Ã  cette Ã©tape vous fera **gagner** beaucoup de **temps** lors de la reconstruction de lâ€™image Ã  maintes reprises pendant le dÃ©veloppement, au lieu de **tÃ©lÃ©charger et installer** toutes les dÃ©pendances **Ã  chaque fois**.

5. Copier le rÃ©pertoire `./app` dans le rÃ©pertoire `/code`.

    Comme cela contient tout le code, qui est ce qui **change le plus frÃ©quemment**, le **cache** Docker ne sera pas facilement utilisÃ© pour cette Ã©tape ni pour les **Ã©tapes suivantes**.

    Il est donc important de mettre ceci **vers la fin** du `Dockerfile`, pour optimiser les temps de construction de lâ€™image de conteneur.

6. DÃ©finir la **commande** pour utiliser `fastapi run`, qui utilise Uvicorn en dessous.

    `CMD` prend une liste de chaÃ®nes, chacune de ces chaÃ®nes est ce que vous taperiez en ligne de commande sÃ©parÃ© par des espaces.

    Cette commande sera exÃ©cutÃ©e depuis le **rÃ©pertoire de travail courant**, le mÃªme rÃ©pertoire `/code` que vous avez dÃ©fini ci-dessus avec `WORKDIR /code`.

/// tip | Astuce

Passez en revue ce que fait chaque ligne en cliquant sur chaque bulle numÃ©rotÃ©e dans le code. ğŸ‘†

///

/// warning | Attention

Assurez-vous dâ€™utiliser **toujours** la **forme exec** de lâ€™instruction `CMD`, comme expliquÃ© ci-dessous.

///

#### Utiliser `CMD` - forme Exec { #use-cmd-exec-form }

Lâ€™instruction Docker <a href="https://docs.docker.com/reference/dockerfile/#cmd" class="external-link" target="_blank">`CMD`</a> peut Ãªtre Ã©crite sous deux formesÂ :

âœ… Forme **exec**Â :

```Dockerfile
# âœ… Ã€ faire
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

â›”ï¸ Forme **shell**Â :

```Dockerfile
# â›”ï¸ Ã€ ne pas faire
CMD fastapi run app/main.py --port 80
```

Assurez-vous dâ€™utiliser toujours la forme **exec** afin que FastAPI puisse sâ€™arrÃªter proprement et que les [Ã©vÃ©nements de durÃ©e de vie](../advanced/events.md){.internal-link target=_blank} soient dÃ©clenchÃ©s.

Vous pouvez en lire davantage dans la <a href="https://docs.docker.com/reference/dockerfile/#shell-and-exec-form" class="external-link" target="_blank">documentation Docker sur les formes shell et exec</a>.

Cela peut Ãªtre assez perceptible avec `docker compose`. Voir cette section de la FAQ Docker Compose pour plus de dÃ©tails techniquesÂ : <a href="https://docs.docker.com/compose/faq/#why-do-my-services-take-10-seconds-to-recreate-or-stop" class="external-link" target="_blank">Pourquoi mes services prennent-ils 10 secondes pour Ãªtre recrÃ©Ã©s ou arrÃªtÃ©s ?</a>.

#### Structure des rÃ©pertoires { #directory-structure }

Vous devriez maintenant avoir une structure de rÃ©pertoires commeÂ :

```
.
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

#### DerriÃ¨re un proxy de terminaison TLS { #behind-a-tls-termination-proxy }

Si vous exÃ©cutez votre conteneur derriÃ¨re un proxy de terminaison TLS (Ã©quilibreur de charge) comme Nginx ou Traefik, ajoutez lâ€™option `--proxy-headers`. Cela indiquera Ã  Uvicorn (via la CLI FastAPI) de faire confiance aux en-tÃªtes envoyÃ©s par ce proxy lui indiquant que lâ€™application sâ€™exÃ©cute derriÃ¨re HTTPS, etc.

```Dockerfile
CMD ["fastapi", "run", "app/main.py", "--proxy-headers", "--port", "80"]
```

#### Cache Docker { #docker-cache }

Il y a une astuce importante dans ce `Dockerfile`Â : nous copions dâ€™abord **le fichier des dÃ©pendances seul**, pas le reste du code. Laissez-moi vous expliquer pourquoi.

```Dockerfile
COPY ./requirements.txt /code/requirements.txt
```

Docker et dâ€™autres outils **construisent** ces images de conteneur **de maniÃ¨re incrÃ©mentale**, en ajoutant **une couche au-dessus de lâ€™autre**, en commenÃ§ant par le haut du `Dockerfile` et en ajoutant les fichiers crÃ©Ã©s par chacune des instructions du `Dockerfile`.

Docker et des outils similaires utilisent Ã©galement un **cache interne** lors de la construction de lâ€™imageÂ : si un fichier nâ€™a pas changÃ© depuis la derniÃ¨re construction, il **rÃ©utilisera la mÃªme couche** crÃ©Ã©e prÃ©cÃ©demment, au lieu de recopier le fichier et de crÃ©er une nouvelle couche Ã  partir de zÃ©ro.

Ã‰viter simplement la copie de fichiers nâ€™amÃ©liore pas forcÃ©ment Ã©normÃ©ment les choses, mais comme le cache a Ã©tÃ© utilisÃ© pour cette Ã©tape, il peut **Ãªtre utilisÃ© pour lâ€™Ã©tape suivante**. Par exemple, il pourra Ãªtre utilisÃ© pour lâ€™instruction qui installe les dÃ©pendancesÂ :

```Dockerfile
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt
```

Le fichier avec les dÃ©pendances des packages **ne changera pas frÃ©quemment**. Ainsi, en copiant uniquement ce fichier, Docker pourra **utiliser le cache** pour cette Ã©tape.

Et ensuite, Docker pourra **utiliser le cache pour lâ€™Ã©tape suivante** qui tÃ©lÃ©charge et installe ces dÃ©pendances. Et câ€™est lÃ  que nous **Ã©conomisons beaucoup de temps**. âœ¨ ... et Ã©vitons lâ€™ennui en attendant. ğŸ˜ªğŸ˜†

TÃ©lÃ©charger et installer les dÃ©pendances de packages **peut prendre des minutes**, alors quâ€™utiliser le **cache** ne **prendra que quelques secondes** au maximum.

Et comme vous reconstruirez lâ€™image de conteneur encore et encore pendant le dÃ©veloppement pour vÃ©rifier que vos modifications de code fonctionnent, cela vous fera gagner beaucoup de temps cumulÃ©.

Puis, vers la fin du `Dockerfile`, nous copions tout le code. Comme câ€™est ce qui **change le plus frÃ©quemment**, nous le mettons vers la fin, car presque toujours, tout ce qui suit cette Ã©tape ne pourra pas utiliser le cache.

```Dockerfile
COPY ./app /code/app
```

### Construire lâ€™image Docker { #build-the-docker-image }

Maintenant que tous les fichiers sont en place, construisons lâ€™image de conteneur.

* Allez dans le rÃ©pertoire du projet (lÃ  oÃ¹ se trouve votre `Dockerfile`, contenant votre rÃ©pertoire `app`).
* Construisez votre image FastAPIÂ :

<div class="termy">

```console
$ docker build -t myimage .

---> 100%
```

</div>

/// tip | Astuce

Remarquez le `.` Ã  la fin, câ€™est Ã©quivalent Ã  `./`, il indique Ã  Docker le rÃ©pertoire Ã  utiliser pour construire lâ€™image de conteneur.

Dans ce cas, câ€™est le rÃ©pertoire courant (`.`).

///

### DÃ©marrer le conteneur Docker { #start-the-docker-container }

* ExÃ©cutez un conteneur basÃ© sur votre imageÂ :

<div class="termy">

```console
$ docker run -d --name mycontainer -p 80:80 myimage
```

</div>

## VÃ©rifier { #check-it }

Vous devriez pouvoir le vÃ©rifier dans lâ€™URL de votre conteneur Docker, par exempleÂ : <a href="http://192.168.99.100/items/5?q=somequery" class="external-link" target="_blank">http://192.168.99.100/items/5?q=somequery</a> ou <a href="http://127.0.0.1/items/5?q=somequery" class="external-link" target="_blank">http://127.0.0.1/items/5?q=somequery</a> (ou Ã©quivalent, en utilisant votre hÃ´te Docker).

Vous verrez quelque chose commeÂ :

```JSON
{"item_id": 5, "q": "somequery"}
```

## Documentation interactive de lâ€™API { #interactive-api-docs }

Vous pouvez maintenant aller sur <a href="http://192.168.99.100/docs" class="external-link" target="_blank">http://192.168.99.100/docs</a> ou <a href="http://127.0.0.1/docs" class="external-link" target="_blank">http://127.0.0.1/docs</a> (ou Ã©quivalent, en utilisant votre hÃ´te Docker).

Vous verrez la documentation API interactive automatique (fournie par <a href="https://github.com/swagger-api/swagger-ui" class="external-link" target="_blank">Swagger UI</a>)Â :

![Swagger UI](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)

## Documentation API alternative { #alternative-api-docs }

Et vous pouvez Ã©galement aller sur <a href="http://192.168.99.100/redoc" class="external-link" target="_blank">http://192.168.99.100/redoc</a> ou <a href="http://127.0.0.1/redoc" class="external-link" target="_blank">http://127.0.0.1/redoc</a> (ou Ã©quivalent, en utilisant votre hÃ´te Docker).

Vous verrez la documentation automatique alternative (fournie par <a href="https://github.com/Rebilly/ReDoc" class="external-link" target="_blank">ReDoc</a>)Â :

![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)

## Construire une image Docker avec un FastAPI monofichier { #build-a-docker-image-with-a-single-file-fastapi }

Si votre FastAPI est un seul fichier, par exemple `main.py` sans rÃ©pertoire `./app`, votre structure de fichiers pourrait ressembler Ã  ceciÂ :

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt
```

Vous nâ€™auriez alors quâ€™Ã  changer les chemins correspondants pour copier le fichier dans le `Dockerfile`Â :

```{ .dockerfile .annotate hl_lines="10  13" }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (1)!
COPY ./main.py /code/

# (2)!
CMD ["fastapi", "run", "main.py", "--port", "80"]
```

1. Copier le fichier `main.py` directement dans le rÃ©pertoire `/code` (sans rÃ©pertoire `./app`).

2. Utiliser `fastapi run` pour servir votre application dans le fichier unique `main.py`.

Quand vous passez le fichier Ã  `fastapi run`, il dÃ©tectera automatiquement quâ€™il sâ€™agit dâ€™un fichier unique et non dâ€™un package et saura comment lâ€™importer et servir votre application FastAPI. ğŸ˜

## Concepts de dÃ©ploiement { #deployment-concepts }

Parlons Ã  nouveau de certains des mÃªmes [Concepts de dÃ©ploiement](concepts.md){.internal-link target=_blank} en termes de conteneurs.

Les conteneurs sont principalement un outil pour simplifier le processus de **construction et de dÃ©ploiement** dâ€™une application, mais ils nâ€™imposent pas une approche particuliÃ¨re pour gÃ©rer ces **concepts de dÃ©ploiement**, et il existe plusieurs stratÃ©gies possibles.

La **bonne nouvelle** est quâ€™avec chaque stratÃ©gie diffÃ©rente, il existe un moyen de couvrir tous les concepts de dÃ©ploiement. ğŸ‰

RÃ©examinons ces **concepts de dÃ©ploiement** en termes de conteneursÂ :

* HTTPS
* ExÃ©cution au dÃ©marrage
* RedÃ©marrages
* RÃ©plication (le nombre de processus en cours)
* MÃ©moire
* Ã‰tapes prÃ©alables avant de dÃ©marrer

## HTTPS { #https }

Si lâ€™on se concentre uniquement sur **lâ€™image de conteneur** pour une application FastAPI (et plus tard le **conteneur** en cours), HTTPS serait normalement gÃ©rÃ© **en externe** par un autre outil.

Cela pourrait Ãªtre un autre conteneur, par exemple avec <a href="https://traefik.io/" class="external-link" target="_blank">Traefik</a>, gÃ©rant **HTTPS** et lâ€™acquisition **automatique** des **certificats**.

/// tip | Astuce

Traefik a des intÃ©grations avec Docker, Kubernetes, et dâ€™autres, il est donc trÃ¨s facile de configurer HTTPS pour vos conteneurs avec lui.

///

Alternativement, HTTPS pourrait Ãªtre gÃ©rÃ© par un fournisseur cloud comme lâ€™un de leurs services (tout en exÃ©cutant lâ€™application dans un conteneur).

## ExÃ©cution au dÃ©marrage et redÃ©marrages { #running-on-startup-and-restarts }

Il y a normalement un autre outil chargÃ© de **dÃ©marrer et exÃ©cuter** votre conteneur.

Cela pourrait Ãªtre **Docker** directement, **Docker Compose**, **Kubernetes**, un **service cloud**, etc.

Dans la plupart (ou toutes) les situations, il y a une option simple pour activer lâ€™exÃ©cution du conteneur au dÃ©marrage et les redÃ©marrages en cas dâ€™Ã©chec. Par exemple, dans Docker, câ€™est lâ€™option de ligne de commande `--restart`.

Sans utiliser les conteneurs, faire en sorte que les applications sâ€™exÃ©cutent au dÃ©marrage et avec redÃ©marrages peut Ãªtre fastidieux et difficile. Mais en **travaillant avec des conteneurs**, dans la plupart des cas, cette fonctionnalitÃ© est incluse par dÃ©faut. âœ¨

## RÃ©plication - Nombre de processus { #replication-number-of-processes }

Si vous avez un <abbr title="Un groupe de machines configurÃ©es pour Ãªtre connectÃ©es et travailler ensemble d'une certaine maniÃ¨re.">cluster</abbr> de machines avec **Kubernetes**, Docker Swarm Mode, Nomad, ou un autre systÃ¨me complexe similaire pour gÃ©rer des conteneurs distribuÃ©s sur plusieurs machines, alors vous voudrez probablement **gÃ©rer la rÃ©plication** au **niveau du cluster** plutÃ´t que dâ€™utiliser un **gestionnaire de processus** (comme Uvicorn avec des workers) dans chaque conteneur.

Lâ€™un de ces systÃ¨mes de gestion de conteneurs distribuÃ©s, comme Kubernetes, dispose normalement dâ€™un moyen intÃ©grÃ© de gÃ©rer la **rÃ©plication des conteneurs** tout en prenant en charge **lâ€™Ã©quilibrage de charge** pour les requÃªtes entrantes. Tout cela au **niveau du cluster**.

Dans ces cas, vous voudrez probablement construire une **image Docker depuis zÃ©ro** comme [expliquÃ© ci-dessus](#dockerfile), en installant vos dÃ©pendances, et en exÃ©cutant **un seul processus Uvicorn** au lieu dâ€™utiliser plusieurs workers Uvicorn.

### Ã‰quilibreur de charge { #load-balancer }

Avec les conteneurs, vous avez normalement un composant **Ã  lâ€™Ã©coute sur le port principal**. Il pourrait sâ€™agir dâ€™un autre conteneur qui est Ã©galement un **proxy de terminaison TLS** pour gÃ©rer **HTTPS**, ou dâ€™un outil similaire.

Comme ce composant prend la **charge** des requÃªtes et les distribue entre les workers de faÃ§on (espÃ©rons-le) **Ã©quilibrÃ©e**, on lâ€™appelle aussi couramment un **Ã©quilibreur de charge**.

/// tip | Astuce

Le mÃªme composant **proxy de terminaison TLS** utilisÃ© pour HTTPS sera probablement aussi un **Ã©quilibreur de charge**.

///

Et en travaillant avec des conteneurs, le mÃªme systÃ¨me que vous utilisez pour les dÃ©marrer et les gÃ©rer disposera dÃ©jÃ  dâ€™outils internes pour transmettre la **communication rÃ©seau** (par ex. les requÃªtes HTTP) depuis cet **Ã©quilibreur de charge** (qui peut Ã©galement Ãªtre un **proxy de terminaison TLS**) vers le ou les conteneurs avec votre application.

### Un Ã©quilibreur de charge - plusieurs conteneurs worker { #one-load-balancer-multiple-worker-containers }

Avec **Kubernetes** ou des systÃ¨mes de gestion de conteneurs distribuÃ©s similaires, lâ€™utilisation de leurs mÃ©canismes rÃ©seau internes permet au **seul** Ã©quilibreur de charge qui Ã©coute sur le **port** principal de transmettre la communication (les requÃªtes) vers **plusieurs conteneurs** exÃ©cutant votre application.

Chacun de ces conteneurs exÃ©cutant votre application aura normalement **un seul processus** (par ex. un processus Uvicorn exÃ©cutant votre application FastAPI). Ils seront tous des **conteneurs identiques**, exÃ©cutant la mÃªme chose, mais chacun avec son propre processus, sa propre mÃ©moire, etc. De cette maniÃ¨re, vous profitez de la **parallÃ©lisation** sur **diffÃ©rents cÅ“urs** du CPU, voire sur **diffÃ©rentes machines**.

Et le systÃ¨me de conteneurs distribuÃ© avec lâ€™**Ã©quilibreur de charge** **distribuera les requÃªtes** Ã  chacun des conteneurs exÃ©cutant votre application **Ã  tour de rÃ´le**. Ainsi, chaque requÃªte pourra Ãªtre traitÃ©e par lâ€™un des **conteneurs rÃ©pliquÃ©s** exÃ©cutant votre application.

Et normalement, cet **Ã©quilibreur de charge** sera capable de gÃ©rer les requÃªtes qui vont vers *dâ€™autres* applications de votre cluster (par ex. vers un autre domaine, ou sous un autre prÃ©fixe de chemin dâ€™URL), et transmettra cette communication aux bons conteneurs pour *cette autre* application sâ€™exÃ©cutant dans votre cluster.

### Un processus par conteneur { #one-process-per-container }

Dans ce type de scÃ©nario, vous voudrez probablement avoir **un seul processus (Uvicorn) par conteneur**, car vous gÃ©rez dÃ©jÃ  la rÃ©plication au niveau du cluster.

Dans ce cas, vous ne voudrez **pas** avoir plusieurs workers dans le conteneur, par exemple avec lâ€™option de ligne de commande `--workers`. Vous voudrez avoir simplement **un seul processus Uvicorn** par conteneur (mais probablement plusieurs conteneurs).

Avoir un autre gestionnaire de processus dans le conteneur (comme ce serait le cas avec plusieurs workers) ne ferait quâ€™ajouter une **complexitÃ© inutile** que votre systÃ¨me de cluster gÃ¨re trÃ¨s probablement dÃ©jÃ .

### Conteneurs avec plusieurs processus et cas particuliers { #containers-with-multiple-processes-and-special-cases }

Bien sÃ»r, il existe des **cas particuliers** oÃ¹ vous pourriez vouloir avoir **un conteneur** avec plusieurs **processus worker Uvicorn** Ã  lâ€™intÃ©rieur.

Dans ces cas, vous pouvez utiliser lâ€™option de ligne de commande `--workers` pour dÃ©finir le nombre de workers que vous souhaitez exÃ©cuterÂ :

```{ .dockerfile .annotate }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

# (1)!
CMD ["fastapi", "run", "app/main.py", "--port", "80", "--workers", "4"]
```

1. Ici, nous utilisons lâ€™option de ligne de commande `--workers` pour dÃ©finir le nombre de workers Ã  4.

Voici quelques exemples oÃ¹ cela peut avoir du sensÂ :

#### Une application simple { #a-simple-app }

Vous pourriez vouloir un gestionnaire de processus dans le conteneur si votre application est **suffisamment simple** pour sâ€™exÃ©cuter sur un **seul serveur**, et non un cluster.

#### Docker Compose { #docker-compose }

Vous pourriez dÃ©ployer sur un **seul serveur** (pas un cluster) avec **Docker Compose**, vous nâ€™auriez donc pas un moyen simple de gÃ©rer la rÃ©plication de conteneurs (avec Docker Compose) tout en conservant le rÃ©seau partagÃ© et **lâ€™Ã©quilibrage de charge**.

Vous pourriez alors vouloir avoir **un seul conteneur** avec un **gestionnaire de processus** dÃ©marrant **plusieurs processus worker** Ã  lâ€™intÃ©rieur.

---

Lâ€™idÃ©e principale est quâ€™**aucune** de ces approches nâ€™est **gravÃ©e dans la pierre** que vous devez suivre aveuglÃ©ment. Vous pouvez utiliser ces idÃ©es pour **Ã©valuer votre propre cas dâ€™utilisation** et dÃ©cider de la meilleure approche pour votre systÃ¨me, en vÃ©rifiant comment gÃ©rer les conceptsÂ :

* SÃ©curitÃ© - HTTPS
* ExÃ©cution au dÃ©marrage
* RedÃ©marrages
* RÃ©plication (le nombre de processus en cours)
* MÃ©moire
* Ã‰tapes prÃ©alables avant de dÃ©marrer

## MÃ©moire { #memory }

Si vous exÃ©cutez **un seul processus par conteneur**, vous aurez une quantitÃ© de mÃ©moire consommÃ©e plus ou moins bien dÃ©finie, stable et limitÃ©e par chacun de ces conteneurs (plus dâ€™un sâ€™ils sont rÃ©pliquÃ©s).

Vous pourrez ensuite dÃ©finir ces mÃªmes limites et exigences de mÃ©moire dans vos configurations pour votre systÃ¨me de gestion de conteneurs (par exemple dans **Kubernetes**). Ainsi, il pourra **rÃ©pliquer les conteneurs** sur les **machines disponibles** en tenant compte de la quantitÃ© de mÃ©moire nÃ©cessaire pour eux et de la quantitÃ© disponible sur les machines du cluster.

Si votre application est **simple**, cela ne sera probablement **pas un problÃ¨me**, et vous nâ€™aurez peut-Ãªtre pas besoin de spÃ©cifier des limites strictes de mÃ©moire. Mais si vous **utilisez beaucoup de mÃ©moire** (par exemple avec des modÃ¨les de **machine learning**), vous devriez vÃ©rifier la quantitÃ© de mÃ©moire que vous consommez et ajuster le **nombre de conteneurs** exÃ©cutÃ©s sur **chaque machine** (et peut-Ãªtre ajouter davantage de machines Ã  votre cluster).

Si vous exÃ©cutez **plusieurs processus par conteneur**, vous devrez vous assurer que le nombre de processus lancÃ©s ne **consomme pas plus de mÃ©moire** que celle disponible.

## Ã‰tapes prÃ©alables avant de dÃ©marrer et conteneurs { #previous-steps-before-starting-and-containers }

Si vous utilisez des conteneurs (par ex. Docker, Kubernetes), alors il y a deux approches principales que vous pouvez utiliser.

### Plusieurs conteneurs { #multiple-containers }

Si vous avez **plusieurs conteneurs**, probablement chacun exÃ©cutant un **seul processus** (par exemple, dans un cluster **Kubernetes**), alors vous voudrez probablement avoir un **conteneur sÃ©parÃ©** effectuant le travail des **Ã©tapes prÃ©alables** dans un seul conteneur, exÃ©cutant un seul processus, **avant** dâ€™exÃ©cuter les conteneurs worker rÃ©pliquÃ©s.

/// info

Si vous utilisez Kubernetes, il sâ€™agira probablement dâ€™un <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" class="external-link" target="_blank">Init Container</a>.

///

Si, dans votre cas dâ€™utilisation, il nâ€™y a pas de problÃ¨me Ã  exÃ©cuter ces Ã©tapes prÃ©alables **plusieurs fois en parallÃ¨le** (par exemple si vous nâ€™exÃ©cutez pas de migrations de base de donnÃ©es, mais vÃ©rifiez simplement si la base est prÃªte), vous pouvez aussi simplement les placer dans chaque conteneur juste avant de dÃ©marrer le processus principal.

### Un seul conteneur { #single-container }

Si vous avez une configuration simple, avec un **seul conteneur** qui dÃ©marre ensuite plusieurs **processus worker** (ou aussi un seul processus), alors vous pouvez exÃ©cuter ces Ã©tapes prÃ©alables dans le mÃªme conteneur, juste avant de dÃ©marrer le processus avec lâ€™application.

### Image Docker de base { #base-docker-image }

Il existait une image Docker officielle FastAPIÂ : <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>. Mais elle est maintenant dÃ©prÃ©ciÃ©e. â›”ï¸

Vous ne devriez probablement **pas** utiliser cette image Docker de base (ni aucune autre similaire).

Si vous utilisez **Kubernetes** (ou autres) et que vous dÃ©finissez dÃ©jÃ  la **rÃ©plication** au niveau du cluster, avec plusieurs **conteneurs**, dans ces cas, il vaut mieux **construire une image depuis zÃ©ro** comme dÃ©crit ci-dessusÂ : [Construire une image Docker pour FastAPI](#build-a-docker-image-for-fastapi).

Et si vous avez besoin dâ€™avoir plusieurs workers, vous pouvez simplement utiliser lâ€™option de ligne de commande `--workers`.

/// note | DÃ©tails techniques

Lâ€™image Docker a Ã©tÃ© crÃ©Ã©e Ã  une Ã©poque oÃ¹ Uvicorn ne prenait pas en charge la gestion et le redÃ©marrage des workers morts, il fallait donc utiliser Gunicorn avec Uvicorn, ce qui ajoutait pas mal de complexitÃ©, uniquement pour que Gunicorn gÃ¨re et redÃ©marre les processus worker Uvicorn.

Mais maintenant quâ€™Uvicorn (et la commande `fastapi`) prennent en charge lâ€™utilisation de `--workers`, il nâ€™y a plus de raison dâ€™utiliser une image Docker de base au lieu de construire la vÃ´tre (cela reprÃ©sente Ã  peu prÃ¨s la mÃªme quantitÃ© de code ğŸ˜…).

///

## DÃ©ployer lâ€™image de conteneur { #deploy-the-container-image }

AprÃ¨s avoir une image de conteneur (Docker), il existe plusieurs faÃ§ons de la dÃ©ployer.

Par exempleÂ :

* Avec **Docker Compose** sur un seul serveur
* Avec un cluster **Kubernetes**
* Avec un cluster en mode Docker Swarm
* Avec un autre outil comme Nomad
* Avec un service cloud qui prend votre image de conteneur et la dÃ©ploie

## Image Docker avec `uv` { #docker-image-with-uv }

Si vous utilisez <a href="https://github.com/astral-sh/uv" class="external-link" target="_blank">uv</a> pour installer et gÃ©rer votre projet, vous pouvez suivre leur <a href="https://docs.astral.sh/uv/guides/integration/docker/" class="external-link" target="_blank">guide Docker uv</a>.

## RÃ©capitulatif { #recap }

Avec les systÃ¨mes de conteneurs (par ex. avec **Docker** et **Kubernetes**), il devient assez simple de gÃ©rer tous les **concepts de dÃ©ploiement**Â :

* HTTPS
* ExÃ©cution au dÃ©marrage
* RedÃ©marrages
* RÃ©plication (le nombre de processus en cours)
* MÃ©moire
* Ã‰tapes prÃ©alables avant de dÃ©marrer

Dans la plupart des cas, vous ne voudrez probablement pas utiliser dâ€™image de base, et plutÃ´t **construire une image de conteneur depuis zÃ©ro** basÃ©e sur lâ€™image Docker Python officielle.

En prenant soin de **lâ€™ordre** des instructions dans le `Dockerfile` et du **cache Docker**, vous pouvez **minimiser les temps de construction** pour maximiser votre productivitÃ© (et Ã©viter lâ€™ennui). ğŸ˜
