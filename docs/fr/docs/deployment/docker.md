# FastAPI dans des conteneurs - Docker { #fastapi-in-containers-docker }

Lors du dÃ©ploiement dâ€™applications FastAPI, une approche courante consiste Ã  construire une **image de conteneur Linux**. Cela se fait gÃ©nÃ©ralement avec <a href="https://www.docker.com/" class="external-link" target="_blank">**Docker**</a>. Vous pouvez ensuite dÃ©ployer cette image de conteneur de lâ€™une de plusieurs maniÃ¨res possibles.

Lâ€™utilisation de conteneurs Linux prÃ©sente plusieurs avantages, notamment la **sÃ©curitÃ©**, la **rÃ©plicabilitÃ©**, la **simplicitÃ©**, et dâ€™autres.

/// tip | Astuce

Vous Ãªtes pressÃ©(e) et vous connaissez dÃ©jÃ  tout Ã§a ? Allez directement au [`Dockerfile` ci-dessous ğŸ‘‡](#build-a-docker-image-for-fastapi).

///

<details>
<summary>AperÃ§u du Dockerfile ğŸ‘€</summary>

```Dockerfile
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

CMD ["fastapi", "run", "app/main.py", "--port", "80"]

# If running behind a proxy like Nginx or Traefik add --proxy-headers
# CMD ["fastapi", "run", "app/main.py", "--port", "80", "--proxy-headers"]
```

</details>

## Quâ€™est-ce quâ€™un conteneur { #what-is-a-container }

Les conteneurs (principalement les conteneurs Linux) sont une maniÃ¨re trÃ¨s **lÃ©gÃ¨re** dâ€™empaqueter des applications, y compris toutes leurs dÃ©pendances et les fichiers nÃ©cessaires, tout en les gardant isolÃ©es des autres conteneurs (dâ€™autres applications ou composants) sur le mÃªme systÃ¨me.

Les conteneurs Linux sâ€™exÃ©cutent en utilisant le mÃªme kernel Linux que lâ€™hÃ´te (machine, machine virtuelle, serveur cloud, etc.). Cela signifie simplement quâ€™ils sont trÃ¨s lÃ©gers (comparÃ©s Ã  des machines virtuelles complÃ¨tes Ã©mulant un systÃ¨me dâ€™exploitation entier).

Ainsi, les conteneurs consomment **peu de ressources**, une quantitÃ© comparable Ã  lâ€™exÃ©cution directe des processus (une machine virtuelle consommerait bien plus).

Les conteneurs ont aussi leurs propres processus en cours dâ€™exÃ©cution **isolÃ©s** (gÃ©nÃ©ralement un seul processus), leur systÃ¨me de fichiers et leur rÃ©seau, ce qui simplifie le dÃ©ploiement, la sÃ©curitÃ©, le dÃ©veloppement, etc.

## Quâ€™est-ce quâ€™une image de conteneur { #what-is-a-container-image }

Un **conteneur** sâ€™exÃ©cute Ã  partir dâ€™une **image de conteneur**.

Une image de conteneur est une version **statique** de tous les fichiers, des variables dâ€™environnement, et de la commande/du programme par dÃ©faut qui doivent Ãªtre prÃ©sents dans un conteneur. **Statique** signifie ici que lâ€™**image** de conteneur ne sâ€™exÃ©cute pas, elle nâ€™est pas lancÃ©e, ce sont uniquement les fichiers empaquetÃ©s et les mÃ©tadonnÃ©es.

Contrairement Ã  une Â«â€¯image de conteneurâ€¯Â» qui correspond au contenu statique stockÃ©, un Â«â€¯conteneurâ€¯Â» dÃ©signe gÃ©nÃ©ralement lâ€™instance en cours dâ€™exÃ©cution, la chose qui est **exÃ©cutÃ©e**.

Quand le **conteneur** est dÃ©marrÃ© et sâ€™exÃ©cute (dÃ©marrÃ© depuis une **image de conteneur**), il peut crÃ©er ou modifier des fichiers, des variables dâ€™environnement, etc. Ces changements nâ€™existeront que dans ce conteneur, et ne persisteront pas dans lâ€™image de conteneur sous-jacente (ils ne seront pas enregistrÃ©s sur disque).

Une image de conteneur est comparable au fichier et au contenu dâ€™un **programme**, par exemple `python` et un fichier `main.py`.

Et le **conteneur** lui-mÃªme (par opposition Ã  lâ€™**image de conteneur**) est lâ€™instance rÃ©ellement exÃ©cutÃ©e de lâ€™image, comparable Ã  un **processus**. En fait, un conteneur ne sâ€™exÃ©cute que lorsquâ€™il a un **processus en cours dâ€™exÃ©cution** (et normalement câ€™est un seul processus). Le conteneur sâ€™arrÃªte lorsquâ€™il nâ€™y a plus de processus en cours dâ€™exÃ©cution Ã  lâ€™intÃ©rieur.

## Images de conteneur { #container-images }

Docker a Ã©tÃ© lâ€™un des principaux outils pour crÃ©er et gÃ©rer les **images de conteneur** et les **conteneurs**.

Et il existe un <a href="https://hub.docker.com/" class="external-link" target="_blank">Docker Hub</a> public avec des **images de conteneur officielles** prÃ©fabriquÃ©es pour de nombreux outils, environnements, bases de donnÃ©es, et applications.

Par exemple, il existe une <a href="https://hub.docker.com/_/python" class="external-link" target="_blank">image Python</a> officielle.

Et il existe beaucoup dâ€™autres images pour diffÃ©rentes choses comme des bases de donnÃ©es, par exemple pour :

* <a href="https://hub.docker.com/_/postgres" class="external-link" target="_blank">PostgreSQL</a>
* <a href="https://hub.docker.com/_/mysql" class="external-link" target="_blank">MySQL</a>
* <a href="https://hub.docker.com/_/mongo" class="external-link" target="_blank">MongoDB</a>
* <a href="https://hub.docker.com/_/redis" class="external-link" target="_blank">Redis</a>, etc.

En utilisant une image de conteneur prÃ©fabriquÃ©e, il est trÃ¨s facile de **combiner** et dâ€™utiliser diffÃ©rents outils. Par exemple, pour tester une nouvelle base de donnÃ©es. Dans la plupart des cas, vous pouvez utiliser les **images officielles** et simplement les configurer via des variables dâ€™environnement.

De cette faÃ§on, dans de nombreux cas, vous pouvez apprendre les conteneurs et Docker et rÃ©utiliser ces connaissances avec beaucoup dâ€™outils et de composants diffÃ©rents.

Ainsi, vous exÃ©cuteriez **plusieurs conteneurs** avec diffÃ©rentes choses, comme une base de donnÃ©es, une application Python, un serveur web avec une application frontend React, et vous les connecteriez entre eux via leur rÃ©seau interne.

Tous les systÃ¨mes de gestion de conteneurs (comme Docker ou Kubernetes) intÃ¨grent ces fonctionnalitÃ©s rÃ©seau.

## Conteneurs et processus { #containers-and-processes }

Une **image de conteneur** inclut normalement dans ses mÃ©tadonnÃ©es le programme ou la commande par dÃ©faut Ã  exÃ©cuter lorsque le **conteneur** est dÃ©marrÃ©, ainsi que les paramÃ¨tres Ã  passer Ã  ce programme. TrÃ¨s similaire Ã  ce que ce serait en ligne de commande.

Quand un **conteneur** est dÃ©marrÃ©, il exÃ©cutera cette commande/ce programme (bien que vous puissiez lâ€™outrepasser et lui faire exÃ©cuter une commande/un programme diffÃ©rent).

Un conteneur sâ€™exÃ©cute tant que le **processus principal** (commande ou programme) sâ€™exÃ©cute.

Un conteneur a normalement un **seul processus**, mais il est aussi possible de dÃ©marrer des sous-processus depuis le processus principal, et ainsi vous aurez **plusieurs processus** dans le mÃªme conteneur.

Mais il nâ€™est pas possible dâ€™avoir un conteneur en cours dâ€™exÃ©cution sans **au moins un processus en cours dâ€™exÃ©cution**. Si le processus principal sâ€™arrÃªte, le conteneur sâ€™arrÃªte.

## Construire une image Docker pour FastAPI { #build-a-docker-image-for-fastapi }

Ok, construisons quelque chose maintenant ! ğŸš€

Je vais vous montrer comment construire une **image Docker** pour FastAPI **Ã  partir de zÃ©ro**, sur la base de lâ€™**image Python officielle**.

Câ€™est ce que vous voudrez faire dans **la plupart des cas**, par exemple :

* Utiliser **Kubernetes** ou des outils similaires
* ExÃ©cuter sur un **Raspberry Pi**
* Utiliser un service cloud qui exÃ©cute une image de conteneur pour vous, etc.

### Exigences de packages { #package-requirements }

Vous aurez normalement les **exigences de packages** de votre application dans un fichier.

Cela dÃ©pendra principalement de lâ€™outil que vous utilisez pour **installer** ces exigences.

La maniÃ¨re la plus courante de le faire est dâ€™avoir un fichier `requirements.txt` avec les noms de packages et leurs versions, un par ligne.

Vous utiliseriez bien sÃ»r les mÃªmes idÃ©es que celles prÃ©sentÃ©es dans [Ã€ propos des versions de FastAPI](versions.md){.internal-link target=_blank} pour dÃ©finir les plages de versions.

Par exemple, votre `requirements.txt` pourrait ressembler Ã  :

```
fastapi[standard]>=0.113.0,<0.114.0
pydantic>=2.7.0,<3.0.0
```

Et vous installeriez normalement ces dÃ©pendances de packages avec `pip`, par exemple :

<div class="termy">

```console
$ pip install -r requirements.txt
---> 100%
Successfully installed fastapi pydantic
```

</div>

/// info

Il existe dâ€™autres formats et outils pour dÃ©finir et installer des dÃ©pendances de packages.

///

### CrÃ©er le code **FastAPI** { #create-the-fastapi-code }

* CrÃ©ez un rÃ©pertoire `app` et entrez dedans.
* CrÃ©ez un fichier vide `__init__.py`.
* CrÃ©ez un fichier `main.py` avec :

```Python
from typing import Union

from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}
```

### Dockerfile { #dockerfile }

Maintenant, dans le mÃªme rÃ©pertoire de projet, crÃ©ez un fichier `Dockerfile` avec :

```{ .dockerfile .annotate }
# (1)!
FROM python:3.9

# (2)!
WORKDIR /code

# (3)!
COPY ./requirements.txt /code/requirements.txt

# (4)!
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (5)!
COPY ./app /code/app

# (6)!
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

1. Partir de lâ€™image de base Python officielle.

2. DÃ©finir le rÃ©pertoire de travail courant sur `/code`.

    Câ€™est lÃ  que nous mettrons le fichier `requirements.txt` et le rÃ©pertoire `app`.

3. Copier le fichier contenant les exigences dans le rÃ©pertoire `/code`.

    Copier **uniquement** le fichier contenant les exigences dâ€™abord, pas le reste du code.

    Comme ce fichier **ne change pas souvent**, Docker le dÃ©tectera et utilisera le **cache** pour cette Ã©tape, permettant dâ€™utiliser le cache pour lâ€™Ã©tape suivante aussi.

4. Installer les dÃ©pendances de packages du fichier dâ€™exigences.

    Lâ€™option `--no-cache-dir` indique Ã  `pip` de ne pas enregistrer localement les packages tÃ©lÃ©chargÃ©s, car cela ne sert que si `pip` devait Ãªtre relancÃ© pour installer les mÃªmes packages, mais ce nâ€™est pas le cas lorsquâ€™on travaille avec des conteneurs.

    /// note | Remarque

    `--no-cache-dir` est uniquement liÃ© Ã  `pip`, il nâ€™a rien Ã  voir avec Docker ou les conteneurs.

    ///

    Lâ€™option `--upgrade` indique Ã  `pip` de mettre Ã  niveau les packages sâ€™ils sont dÃ©jÃ  installÃ©s.

    Comme lâ€™Ã©tape prÃ©cÃ©dente de copie du fichier pourrait Ãªtre dÃ©tectÃ©e par le **cache Docker**, cette Ã©tape va aussi **utiliser le cache Docker** lorsquâ€™il est disponible.

    Utiliser le cache Ã  cette Ã©tape va vous **faire gagner** beaucoup de **temps** lorsque vous reconstruisez lâ€™image encore et encore pendant le dÃ©veloppement, au lieu de **tÃ©lÃ©charger et installer** toutes les dÃ©pendances **Ã  chaque fois**.

5. Copier le rÃ©pertoire `./app` dans le rÃ©pertoire `/code`.

    Comme cela contient tout le code, qui est ce qui **change le plus frÃ©quemment**, le **cache** Docker ne sera pas facilement utilisÃ© pour cette Ã©tape ou pour les **Ã©tapes suivantes**.

    Il est donc important de placer cela **prÃ¨s de la fin** du `Dockerfile`, pour optimiser les temps de build de lâ€™image de conteneur.

6. DÃ©finir la **commande** pour utiliser `fastapi run`, qui utilise Uvicorn en dessous.

    `CMD` prend une liste de chaÃ®nes de caractÃ¨res, chacune de ces chaÃ®nes correspond Ã  ce que vous taperiez en ligne de commande, sÃ©parÃ© par des espaces.

    Cette commande sera exÃ©cutÃ©e depuis le **rÃ©pertoire de travail courant**, le mÃªme rÃ©pertoire `/code` que vous avez dÃ©fini plus haut avec `WORKDIR /code`.

/// tip | Astuce

Passez en revue ce que fait chaque ligne en cliquant sur chaque bulle numÃ©rotÃ©e dans le code. ğŸ‘†

///

/// warning | Alertes

Vous devez vous assurer dâ€™utiliser **toujours** la **forme exec** de lâ€™instruction `CMD`, comme expliquÃ© ci-dessous.

///

#### Utiliser `CMD` - forme exec { #use-cmd-exec-form }

Lâ€™instruction Docker <a href="https://docs.docker.com/reference/dockerfile/#cmd" class="external-link" target="_blank">`CMD`</a> peut sâ€™Ã©crire sous deux formes :

âœ… Forme **exec** :

```Dockerfile
# âœ… Do this
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

â›”ï¸ Forme **shell** :

```Dockerfile
# â›”ï¸ Don't do this
CMD fastapi run app/main.py --port 80
```

Vous devez vous assurer de toujours utiliser la forme **exec** pour garantir que FastAPI puisse sâ€™arrÃªter proprement et que les [Ã©vÃ©nements de lifespan](../advanced/events.md){.internal-link target=_blank} soient dÃ©clenchÃ©s.

Vous pouvez en lire plus Ã  ce sujet dans la <a href="https://docs.docker.com/reference/dockerfile/#shell-and-exec-form" class="external-link" target="_blank">documentation Docker sur les formes shell et exec</a>.

Cela peut Ãªtre assez visible lors de lâ€™utilisation de `docker compose`. Consultez cette section de la FAQ Docker Compose pour plus de dÃ©tails techniques : <a href="https://docs.docker.com/compose/faq/#why-do-my-services-take-10-seconds-to-recreate-or-stop" class="external-link" target="_blank">Why do my services take 10 seconds to recreate or stop?</a>.

#### Structure de rÃ©pertoires { #directory-structure }

Vous devriez maintenant avoir une structure de rÃ©pertoires comme :

```
.
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

#### DerriÃ¨re un proxy de terminaison TLS { #behind-a-tls-termination-proxy }

Si vous exÃ©cutez votre conteneur derriÃ¨re un proxy de terminaison TLS (load balancer) comme Nginx ou Traefik, ajoutez lâ€™option `--proxy-headers` ; cela indiquera Ã  Uvicorn (via la CLI FastAPI) de faire confiance aux en-tÃªtes envoyÃ©s par ce proxy lui indiquant que lâ€™application sâ€™exÃ©cute derriÃ¨re HTTPS, etc.

```Dockerfile
CMD ["fastapi", "run", "app/main.py", "--proxy-headers", "--port", "80"]
```

#### Cache Docker { #docker-cache }

Il y a une astuce importante dans ce `Dockerfile` : nous copions dâ€™abord **le fichier des dÃ©pendances seul**, pas le reste du code. Je vais vous expliquer pourquoi.

```Dockerfile
COPY ./requirements.txt /code/requirements.txt
```

Docker et dâ€™autres outils **construisent** ces images de conteneur **de maniÃ¨re incrÃ©mentale**, en ajoutant **une couche par-dessus lâ€™autre**, en commenÃ§ant par le haut du `Dockerfile` et en ajoutant tous les fichiers crÃ©Ã©s par chacune des instructions du `Dockerfile`.

Docker et des outils similaires utilisent aussi un **cache interne** lors de la construction de lâ€™image : si un fichier nâ€™a pas changÃ© depuis la derniÃ¨re construction de lâ€™image de conteneur, alors il va **rÃ©utiliser la mÃªme couche** crÃ©Ã©e la derniÃ¨re fois, au lieu de copier le fichier Ã  nouveau et de crÃ©er une nouvelle couche Ã  partir de zÃ©ro.

Le simple fait dâ€™Ã©viter la copie de fichiers nâ€™amÃ©liore pas forcÃ©ment beaucoup les choses, mais comme le cache a Ã©tÃ© utilisÃ© pour cette Ã©tape, il peut **Ãªtre utilisÃ© pour lâ€™Ã©tape suivante**. Par exemple, il pourrait Ãªtre utilisÃ© pour lâ€™instruction qui installe les dÃ©pendances avec :

```Dockerfile
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt
```

Le fichier des exigences de packages **ne changera pas frÃ©quemment**. Donc, en ne copiant que ce fichier, Docker pourra **utiliser le cache** pour cette Ã©tape.

Et ensuite, Docker pourra **utiliser le cache pour lâ€™Ã©tape suivante** qui tÃ©lÃ©charge et installe ces dÃ©pendances. Et câ€™est lÃ  que nous **gagnons beaucoup de temps**. âœ¨ ... et Ã©vitons lâ€™ennui dâ€™attendre. ğŸ˜ªğŸ˜†

Le tÃ©lÃ©chargement et lâ€™installation des dÃ©pendances de packages **peuvent prendre des minutes**, mais utiliser le **cache** **prendrait au maximum quelques secondes**.

Et comme vous reconstruiriez lâ€™image de conteneur encore et encore pendant le dÃ©veloppement pour vÃ©rifier que vos modifications de code fonctionnent, cela vous ferait gagner beaucoup de temps cumulÃ©.

Ensuite, prÃ¨s de la fin du `Dockerfile`, nous copions tout le code. Comme câ€™est ce qui **change le plus frÃ©quemment**, nous le mettons prÃ¨s de la fin, car presque toujours, tout ce qui vient aprÃ¨s cette Ã©tape ne pourra pas utiliser le cache.

```Dockerfile
COPY ./app /code/app
```

### Construire lâ€™image Docker { #build-the-docker-image }

Maintenant que tous les fichiers sont en place, construisons lâ€™image de conteneur.

* Allez dans le rÃ©pertoire du projet (dans lequel se trouve votre `Dockerfile`, contenant votre rÃ©pertoire `app`).
* Construisez votre image FastAPI :

<div class="termy">

```console
$ docker build -t myimage .

---> 100%
```

</div>

/// tip | Astuce

Remarquez le `.` Ã  la fin, il est Ã©quivalent Ã  `./` : il indique Ã  Docker le rÃ©pertoire Ã  utiliser pour construire lâ€™image de conteneur.

Dans ce cas, câ€™est le mÃªme rÃ©pertoire courant (`.`).

///

### DÃ©marrer le conteneur Docker { #start-the-docker-container }

* ExÃ©cutez un conteneur basÃ© sur votre image :

<div class="termy">

```console
$ docker run -d --name mycontainer -p 80:80 myimage
```

</div>

## VÃ©rifier { #check-it }

Vous devriez pouvoir le vÃ©rifier via lâ€™URL de votre conteneur Docker, par exemple : <a href="http://192.168.99.100/items/5?q=somequery" class="external-link" target="_blank">http://192.168.99.100/items/5?q=somequery</a> ou <a href="http://127.0.0.1/items/5?q=somequery" class="external-link" target="_blank">http://127.0.0.1/items/5?q=somequery</a> (ou Ã©quivalent, en utilisant votre hÃ´te Docker).

Vous verrez quelque chose comme :

```JSON
{"item_id": 5, "q": "somequery"}
```

## Documentation interactive de lâ€™API { #interactive-api-docs }

Vous pouvez maintenant aller sur <a href="http://192.168.99.100/docs" class="external-link" target="_blank">http://192.168.99.100/docs</a> ou <a href="http://127.0.0.1/docs" class="external-link" target="_blank">http://127.0.0.1/docs</a> (ou Ã©quivalent, en utilisant votre hÃ´te Docker).

Vous verrez la documentation interactive automatique de lâ€™API (fournie par <a href="https://github.com/swagger-api/swagger-ui" class="external-link" target="_blank">Swagger UI</a>) :

![Swagger UI](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)

## Documentation de lâ€™API alternative { #alternative-api-docs }

Et vous pouvez Ã©galement aller sur <a href="http://192.168.99.100/redoc" class="external-link" target="_blank">http://192.168.99.100/redoc</a> ou <a href="http://127.0.0.1/redoc" class="external-link" target="_blank">http://127.0.0.1/redoc</a> (ou Ã©quivalent, en utilisant votre hÃ´te Docker).

Vous verrez la documentation automatique alternative (fournie par <a href="https://github.com/Rebilly/ReDoc" class="external-link" target="_blank">ReDoc</a>) :

![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)

## Construire une image Docker avec un FastAPI dans un seul fichier { #build-a-docker-image-with-a-single-file-fastapi }

Si votre FastAPI est un seul fichier, par exemple `main.py` sans rÃ©pertoire `./app`, votre structure de fichiers pourrait ressembler Ã  ceci :

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt
```

Ensuite, vous nâ€™auriez quâ€™Ã  modifier les chemins correspondants pour copier le fichier dans le `Dockerfile` :

```{ .dockerfile .annotate hl_lines="10  13" }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (1)!
COPY ./main.py /code/

# (2)!
CMD ["fastapi", "run", "main.py", "--port", "80"]
```

1. Copier le fichier `main.py` directement dans le rÃ©pertoire `/code` (sans aucun rÃ©pertoire `./app`).

2. Utiliser `fastapi run` pour servir votre application dans le fichier unique `main.py`.

Quand vous passez le fichier Ã  `fastapi run`, il dÃ©tectera automatiquement quâ€™il sâ€™agit dâ€™un fichier unique et non dâ€™une partie dâ€™un package, et saura comment lâ€™importer et servir votre application FastAPI. ğŸ˜

## Concepts de dÃ©ploiement { #deployment-concepts }

Parlons Ã  nouveau de certains des mÃªmes [concepts de dÃ©ploiement](concepts.md){.internal-link target=_blank} en termes de conteneurs.

Les conteneurs sont principalement un outil pour simplifier le processus de **construction et de dÃ©ploiement** dâ€™une application, mais ils nâ€™imposent pas une approche particuliÃ¨re pour gÃ©rer ces **concepts de dÃ©ploiement**, et il existe plusieurs stratÃ©gies possibles.

La **bonne nouvelle**, câ€™est quâ€™avec chaque stratÃ©gie diffÃ©rente il existe un moyen de couvrir tous les concepts de dÃ©ploiement. ğŸ‰

Passons en revue ces **concepts de dÃ©ploiement** en termes de conteneurs :

* HTTPS
* ExÃ©cution au dÃ©marrage
* RedÃ©marrages
* RÃ©plication (le nombre de processus en cours dâ€™exÃ©cution)
* MÃ©moire
* Ã‰tapes prÃ©alables avant de dÃ©marrer

## HTTPS { #https }

Si nous nous concentrons uniquement sur lâ€™**image de conteneur** dâ€™une application FastAPI (et plus tard sur le **conteneur** en cours dâ€™exÃ©cution), HTTPS serait normalement gÃ©rÃ© **en externe** par un autre outil.

Cela pourrait Ãªtre un autre conteneur, par exemple avec <a href="https://traefik.io/" class="external-link" target="_blank">Traefik</a>, gÃ©rant **HTTPS** et lâ€™acquisition **automatique** de **certificats**.

/// tip | Astuce

Traefik dispose dâ€™intÃ©grations avec Docker, Kubernetes et dâ€™autres, il est donc trÃ¨s simple Ã  mettre en place et Ã  configurer pour HTTPS avec vos conteneurs.

///

Alternativement, HTTPS pourrait Ãªtre gÃ©rÃ© par un fournisseur cloud comme lâ€™un de ses services (tout en exÃ©cutant lâ€™application dans un conteneur).

## ExÃ©cution au dÃ©marrage et redÃ©marrages { #running-on-startup-and-restarts }

Il y a normalement un autre outil chargÃ© de **dÃ©marrer et exÃ©cuter** votre conteneur.

Cela pourrait Ãªtre **Docker** directement, **Docker Compose**, **Kubernetes**, un **service cloud**, etc.

Dans la plupart (ou tous) les cas, il existe une option simple pour activer lâ€™exÃ©cution du conteneur au dÃ©marrage et activer les redÃ©marrages en cas dâ€™Ã©chec. Par exemple, dans Docker, câ€™est lâ€™option en ligne de commande `--restart`.

Sans utiliser de conteneurs, faire exÃ©cuter des applications au dÃ©marrage et avec redÃ©marrages peut Ãªtre contraignant et difficile. Mais en **travaillant avec des conteneurs**, dans la plupart des cas cette fonctionnalitÃ© est incluse par dÃ©faut. âœ¨

## RÃ©plication - Nombre de processus { #replication-number-of-processes }

Si vous avez un <abbr title="Un groupe de machines configurÃ©es pour Ãªtre connectÃ©es et travailler ensemble dâ€™une certaine faÃ§on.">cluster</abbr> de machines avec **Kubernetes**, Docker Swarm Mode, Nomad, ou un autre systÃ¨me complexe similaire pour gÃ©rer des conteneurs distribuÃ©s sur plusieurs machines, alors vous voudrez probablement **gÃ©rer la rÃ©plication** au **niveau du cluster** au lieu dâ€™utiliser un **gestionnaire de processus** (comme Uvicorn avec des workers) dans chaque conteneur.

Un de ces systÃ¨mes de gestion de conteneurs distribuÃ©s comme Kubernetes dispose normalement dâ€™un moyen intÃ©grÃ© de gÃ©rer la **rÃ©plication des conteneurs** tout en prenant en charge lâ€™**Ã©quilibrage de charge** pour les requÃªtes entrantes. Le tout au **niveau du cluster**.

Dans ces cas, vous voudrez probablement construire une **image Docker Ã  partir de zÃ©ro** comme [expliquÃ© ci-dessus](#dockerfile), installer vos dÃ©pendances, et exÃ©cuter **un seul processus Uvicorn** au lieu dâ€™utiliser plusieurs workers Uvicorn.

### Load Balancer { #load-balancer }

Lors de lâ€™utilisation de conteneurs, vous aurez normalement un composant **Ã  lâ€™Ã©coute sur le port principal**. Cela pourrait Ã©ventuellement Ãªtre un autre conteneur qui est aussi un **proxy de terminaison TLS** pour gÃ©rer **HTTPS** ou un outil similaire.

Comme ce composant prendrait la **charge** des requÃªtes et la distribuerait entre les workers dâ€™une maniÃ¨re (espÃ©rons-le) **Ã©quilibrÃ©e**, on lâ€™appelle aussi communÃ©ment un **Load Balancer**.

/// tip | Astuce

Le mÃªme composant de **proxy de terminaison TLS** utilisÃ© pour HTTPS serait probablement aussi un **Load Balancer**.

///

Et en travaillant avec des conteneurs, le mÃªme systÃ¨me que vous utilisez pour les dÃ©marrer et les gÃ©rer aura dÃ©jÃ  des outils internes pour transmettre la **communication rÃ©seau** (par exemple les requÃªtes HTTP) depuis ce **load balancer** (qui pourrait aussi Ãªtre un **proxy de terminaison TLS**) vers le(s) conteneur(s) avec votre application.

### Un load balancer - Plusieurs conteneurs workers { #one-load-balancer-multiple-worker-containers }

En travaillant avec **Kubernetes** ou des systÃ¨mes distribuÃ©s de gestion de conteneurs similaires, utiliser leurs mÃ©canismes rÃ©seau internes permettrait au **load balancer** unique qui Ã©coute sur le **port** principal de transmettre la communication (les requÃªtes) Ã  potentiellement **plusieurs conteneurs** exÃ©cutant votre application.

Chacun de ces conteneurs exÃ©cutant votre application aurait normalement **un seul processus** (par exemple un processus Uvicorn exÃ©cutant votre application FastAPI). Ce seraient tous des **conteneurs identiques**, exÃ©cutant la mÃªme chose, mais chacun avec son propre processus, sa mÃ©moire, etc. Ainsi, vous profiteriez de la **parallÃ©lisation** sur **diffÃ©rents cÅ“urs** du CPU, ou mÃªme sur **diffÃ©rentes machines**.

Et le systÃ¨me de conteneurs distribuÃ©s avec le **load balancer** **distribuerait les requÃªtes** Ã  chacun des conteneurs avec votre application **Ã  tour de rÃ´le**. Ainsi, chaque requÃªte pourrait Ãªtre traitÃ©e par lâ€™un des multiples **conteneurs rÃ©pliquÃ©s** exÃ©cutant votre application.

Et normalement ce **load balancer** serait capable de gÃ©rer des requÃªtes allant vers *dâ€™autres* applications dans votre cluster (par exemple vers un domaine diffÃ©rent, ou sous un prÃ©fixe de chemin dâ€™URL diffÃ©rent), et transmettrait cette communication aux bons conteneurs pour *cette autre* application sâ€™exÃ©cutant dans votre cluster.

### Un processus par conteneur { #one-process-per-container }

Dans ce type de scÃ©nario, vous voudrez probablement avoir **un seul processus (Uvicorn) par conteneur**, puisque vous gÃ©rez dÃ©jÃ  la rÃ©plication au niveau du cluster.

Donc, dans ce cas, vous **ne** voudrez **pas** avoir plusieurs workers dans le conteneur, par exemple avec lâ€™option en ligne de commande `--workers`. Vous voudrez avoir un **seul processus Uvicorn** par conteneur (mais probablement plusieurs conteneurs).

Avoir un autre gestionnaire de processus Ã  lâ€™intÃ©rieur du conteneur (comme ce serait le cas avec plusieurs workers) ne ferait quâ€™ajouter une **complexitÃ© inutile** que vous gÃ©rez trÃ¨s probablement dÃ©jÃ  avec votre systÃ¨me de cluster.

### Conteneurs avec plusieurs processus et cas particuliers { #containers-with-multiple-processes-and-special-cases }

Bien sÃ»r, il existe des **cas particuliers** oÃ¹ vous pourriez vouloir avoir **un conteneur** avec plusieurs **processus workers Uvicorn** Ã  lâ€™intÃ©rieur.

Dans ces cas, vous pouvez utiliser lâ€™option en ligne de commande `--workers` pour dÃ©finir le nombre de workers que vous souhaitez exÃ©cuter :

```{ .dockerfile .annotate }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

# (1)!
CMD ["fastapi", "run", "app/main.py", "--port", "80", "--workers", "4"]
```

1. Ici, nous utilisons lâ€™option en ligne de commande `--workers` pour dÃ©finir le nombre de workers Ã  4.

Voici quelques exemples oÃ¹ cela pourrait avoir du sens :

#### Une application simple { #a-simple-app }

Vous pourriez vouloir un gestionnaire de processus dans le conteneur si votre application est **suffisamment simple** pour pouvoir sâ€™exÃ©cuter sur un **seul serveur**, pas un cluster.

#### Docker Compose { #docker-compose }

Vous pourriez dÃ©ployer sur un **seul serveur** (pas un cluster) avec **Docker Compose**, et vous nâ€™auriez donc pas un moyen simple de gÃ©rer la rÃ©plication des conteneurs (avec Docker Compose) tout en prÃ©servant le rÃ©seau partagÃ© et lâ€™**Ã©quilibrage de charge**.

Vous pourriez alors vouloir avoir **un seul conteneur** avec un **gestionnaire de processus** dÃ©marrant **plusieurs processus worker** Ã  lâ€™intÃ©rieur.

---

Le point principal est que **rien** de tout cela nâ€™est une **rÃ¨gle gravÃ©e dans le marbre** que vous devez suivre aveuglÃ©ment. Vous pouvez utiliser ces idÃ©es pour **Ã©valuer votre propre cas dâ€™usage** et dÃ©cider quelle est la meilleure approche pour votre systÃ¨me, en examinant comment gÃ©rer les concepts de :

* SÃ©curitÃ© - HTTPS
* ExÃ©cution au dÃ©marrage
* RedÃ©marrages
* RÃ©plication (le nombre de processus en cours dâ€™exÃ©cution)
* MÃ©moire
* Ã‰tapes prÃ©alables avant de dÃ©marrer

## MÃ©moire { #memory }

Si vous exÃ©cutez **un seul processus par conteneur**, vous aurez une quantitÃ© de mÃ©moire plus ou moins bien dÃ©finie, stable, et limitÃ©e consommÃ©e par chacun de ces conteneurs (plus dâ€™un si vous les rÃ©pliquez).

Et ensuite, vous pouvez dÃ©finir ces mÃªmes limites et exigences de mÃ©moire dans vos configurations pour votre systÃ¨me de gestion de conteneurs (par exemple dans **Kubernetes**). Ainsi, il pourra **rÃ©pliquer les conteneurs** sur les **machines disponibles** en tenant compte de la quantitÃ© de mÃ©moire nÃ©cessaire et de la quantitÃ© disponible sur les machines du cluster.

Si votre application est **simple**, ce ne sera probablement **pas un problÃ¨me**, et vous pourriez ne pas avoir besoin de spÃ©cifier des limites strictes de mÃ©moire. Mais si vous **utilisez beaucoup de mÃ©moire** (par exemple avec des modÃ¨les de **machine learning**), vous devriez vÃ©rifier la quantitÃ© de mÃ©moire consommÃ©e et ajuster le **nombre de conteneurs** qui sâ€™exÃ©cutent sur **chaque machine** (et peut-Ãªtre ajouter plus de machines Ã  votre cluster).

Si vous exÃ©cutez **plusieurs processus par conteneur**, vous devez vous assurer que le nombre de processus dÃ©marrÃ©s ne **consomme pas plus de mÃ©moire** que ce qui est disponible.

## Ã‰tapes prÃ©alables avant de dÃ©marrer et conteneurs { #previous-steps-before-starting-and-containers }

Si vous utilisez des conteneurs (par exemple Docker, Kubernetes), alors il existe deux approches principales que vous pouvez utiliser.

### Plusieurs conteneurs { #multiple-containers }

Si vous avez **plusieurs conteneurs**, probablement chacun exÃ©cutant un **seul processus** (par exemple, dans un cluster **Kubernetes**), vous voudrez probablement avoir un **conteneur sÃ©parÃ©** pour effectuer le travail des **Ã©tapes prÃ©alables** dans un conteneur unique, exÃ©cutant un seul processus, **avant** dâ€™exÃ©cuter les conteneurs workers rÃ©pliquÃ©s.

/// info

Si vous utilisez Kubernetes, ce serait probablement un <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" class="external-link" target="_blank">Init Container</a>.

///

Si, dans votre cas dâ€™usage, il nâ€™y a pas de problÃ¨me Ã  exÃ©cuter ces Ã©tapes prÃ©alables **plusieurs fois en parallÃ¨le** (par exemple si vous nâ€™exÃ©cutez pas des migrations de base de donnÃ©es, mais vÃ©rifiez simplement si la base de donnÃ©es est prÃªte), alors vous pourriez aussi les placer dans chaque conteneur juste avant de dÃ©marrer le processus principal.

### Conteneur unique { #single-container }

Si vous avez une configuration simple, avec un **conteneur unique** qui dÃ©marre ensuite plusieurs **processus worker** (ou aussi juste un processus), alors vous pourriez exÃ©cuter ces Ã©tapes prÃ©alables dans le mÃªme conteneur, juste avant de dÃ©marrer le processus avec lâ€™application.

### Image Docker de base { #base-docker-image }

Il existait une image Docker FastAPI officielle : <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>. Mais elle est maintenant dÃ©prÃ©ciÃ©e. â›”ï¸

Vous ne devriez probablement **pas** utiliser cette image Docker de base (ni une autre similaire).

Si vous utilisez **Kubernetes** (ou dâ€™autres) et que vous dÃ©finissez dÃ©jÃ  la **rÃ©plication** au niveau du cluster, avec plusieurs **conteneurs**. Dans ces cas, il vaut mieux **construire une image Ã  partir de zÃ©ro** comme dÃ©crit ci-dessus : [Construire une image Docker pour FastAPI](#build-a-docker-image-for-fastapi).

Et si vous devez avoir plusieurs workers, vous pouvez simplement utiliser lâ€™option en ligne de commande `--workers`.

/// note | DÃ©tails techniques

Lâ€™image Docker a Ã©tÃ© crÃ©Ã©e Ã  une Ã©poque oÃ¹ Uvicorn ne prenait pas en charge la gestion et le redÃ©marrage des workers morts, il Ã©tait donc nÃ©cessaire dâ€™utiliser Gunicorn avec Uvicorn, ce qui ajoutait pas mal de complexitÃ©, simplement pour que Gunicorn gÃ¨re et redÃ©marre les processus workers Uvicorn.

Mais maintenant quâ€™Uvicorn (et la commande `fastapi`) prennent en charge lâ€™utilisation de `--workers`, il nâ€™y a aucune raison dâ€™utiliser une image Docker de base au lieu de construire la vÃ´tre (câ€™est Ã  peu prÃ¨s la mÃªme quantitÃ© de code ğŸ˜…).

///

## DÃ©ployer lâ€™image de conteneur { #deploy-the-container-image }

AprÃ¨s avoir une image de conteneur (Docker), il existe plusieurs faÃ§ons de la dÃ©ployer.

Par exemple :

* Avec **Docker Compose** sur un seul serveur
* Avec un cluster **Kubernetes**
* Avec un cluster en mode Docker Swarm
* Avec un autre outil comme Nomad
* Avec un service cloud qui prend votre image de conteneur et la dÃ©ploie

## Image Docker avec `uv` { #docker-image-with-uv }

Si vous utilisez <a href="https://github.com/astral-sh/uv" class="external-link" target="_blank">uv</a> pour installer et gÃ©rer votre projet, vous pouvez suivre leur <a href="https://docs.astral.sh/uv/guides/integration/docker/" class="external-link" target="_blank">guide Docker uv</a>.

## RÃ©capitulatif { #recap }

En utilisant des systÃ¨mes de conteneurs (par ex. avec **Docker** et **Kubernetes**), il devient assez simple de gÃ©rer tous les **concepts de dÃ©ploiement** :

* HTTPS
* ExÃ©cution au dÃ©marrage
* RedÃ©marrages
* RÃ©plication (le nombre de processus en cours dâ€™exÃ©cution)
* MÃ©moire
* Ã‰tapes prÃ©alables avant de dÃ©marrer

Dans la plupart des cas, vous ne voudrez probablement pas utiliser une image de base, et vous voudrez plutÃ´t **construire une image de conteneur Ã  partir de zÃ©ro** basÃ©e sur lâ€™image Docker Python officielle.

En prenant soin de lâ€™**ordre** des instructions dans le `Dockerfile` et du **cache Docker**, vous pouvez **minimiser les temps de build**, afin de maximiser votre productivitÃ© (et dâ€™Ã©viter lâ€™ennui). ğŸ˜
