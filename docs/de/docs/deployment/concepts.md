# Deployment-Konzepte { #deployments-concepts }

Bei dem Deployment ‚Äì der Bereitstellung ‚Äì einer **FastAPI**-Anwendung, oder eigentlich jeder Art von Web-API, gibt es mehrere Konzepte, die Sie wahrscheinlich interessieren, und mithilfe der Sie die **am besten geeignete** Methode zur **Bereitstellung Ihrer Anwendung** finden k√∂nnen.

Einige wichtige Konzepte sind:

* Sicherheit ‚Äì HTTPS
* Beim Hochfahren ausf√ºhren
* Neustarts
* Replikation (die Anzahl der laufenden Prozesse)
* Arbeitsspeicher
* Schritte vor dem Start

Wir werden sehen, wie diese sich auf das **Deployment** auswirken.

Letztendlich besteht das ultimative Ziel darin, **Ihre API-Clients** auf **sichere** Weise zu versorgen, um **Unterbrechungen** zu vermeiden und die **Rechenressourcen** (z. B. entfernte Server/virtuelle Maschinen) so effizient wie m√∂glich zu nutzen. üöÄ

Ich erz√§hle Ihnen hier etwas mehr √ºber diese **Konzepte**, was Ihnen hoffentlich die **Intuition** gibt, die Sie ben√∂tigen, um zu entscheiden, wie Sie Ihre API in sehr unterschiedlichen Umgebungen bereitstellen, m√∂glicherweise sogar in **zuk√ºnftigen**, die jetzt noch nicht existieren.

Durch die Ber√ºcksichtigung dieser Konzepte k√∂nnen Sie die beste Variante der Bereitstellung **Ihrer eigenen APIs** **evaluieren und konzipieren**.

In den n√§chsten Kapiteln werde ich Ihnen mehr **konkrete Rezepte** f√ºr die Bereitstellung von FastAPI-Anwendungen geben.

Aber schauen wir uns zun√§chst einmal diese grundlegenden **konzeptionellen Ideen** an. Diese Konzepte gelten auch f√ºr jede andere Art von Web-API. üí°

## Sicherheit ‚Äì HTTPS { #security-https }

Im [vorherigen Kapitel √ºber HTTPS](https.md){.internal-link target=_blank} haben wir erfahren, wie HTTPS Verschl√ºsselung f√ºr Ihre API bereitstellt.

Wir haben auch gesehen, dass HTTPS normalerweise von einer Komponente **au√üerhalb** Ihres Anwendungsservers bereitgestellt wird, einem **TLS-Terminierungsproxy**.

Und es muss etwas geben, das f√ºr die **Erneuerung der HTTPS-Zertifikate** zust√§ndig ist, es k√∂nnte sich um dieselbe Komponente handeln oder um etwas anderes.

### Beispieltools f√ºr HTTPS { #example-tools-for-https }

Einige der Tools, die Sie als TLS-Terminierungsproxy verwenden k√∂nnen, sind:

* Traefik
    * Handhabt automatisch Zertifikat-Erneuerungen ‚ú®
* Caddy
    * Handhabt automatisch Zertifikat-Erneuerungen ‚ú®
* Nginx
    * Mit einer externen Komponente wie Certbot f√ºr Zertifikat-Erneuerungen
* HAProxy
    * Mit einer externen Komponente wie Certbot f√ºr Zertifikat-Erneuerungen
* Kubernetes mit einem Ingress Controller wie Nginx
    * Mit einer externen Komponente wie cert-manager f√ºr Zertifikat-Erneuerungen
* Es wird intern von einem Cloud-Anbieter als Teil seiner Dienste verwaltet (siehe unten üëá)

Eine andere M√∂glichkeit besteht darin, dass Sie einen **Cloud-Dienst** verwenden, der den gr√∂√üten Teil der Arbeit √ºbernimmt, einschlie√ülich der Einrichtung von HTTPS. Er k√∂nnte einige Einschr√§nkungen haben oder Ihnen mehr in Rechnung stellen, usw. In diesem Fall m√ºssten Sie jedoch nicht selbst einen TLS-Terminierungsproxy einrichten.

In den n√§chsten Kapiteln zeige ich Ihnen einige konkrete Beispiele.

---

Die n√§chsten zu ber√ºcksichtigenden Konzepte drehen sich dann um das Programm, das Ihre eigentliche API ausf√ºhrt (z. B. Uvicorn).

## Programm und Prozess { #program-and-process }

Wir werden viel √ºber den laufenden ‚Äû**Prozess**‚Äú sprechen, daher ist es n√ºtzlich, Klarheit dar√ºber zu haben, was das bedeutet und was der Unterschied zum Wort ‚Äû**Programm**‚Äú ist.

### Was ist ein Programm { #what-is-a-program }

Das Wort **Programm** wird h√§ufig zur Beschreibung vieler Dinge verwendet:

* Der **Code**, den Sie schreiben, die **Python-Dateien**.
* Die **Datei**, die vom Betriebssystem **ausgef√ºhrt** werden kann, zum Beispiel: `python`, `python.exe` oder `uvicorn`.
* Ein bestimmtes Programm, w√§hrend es auf dem Betriebssystem **l√§uft**, die CPU nutzt und Dinge im Arbeitsspeicher ablegt. Dies wird auch als **Prozess** bezeichnet.

### Was ist ein Prozess { #what-is-a-process }

Das Wort **Prozess** wird normalerweise spezifischer verwendet und bezieht sich nur auf das, was im Betriebssystem ausgef√ºhrt wird (wie im letzten Punkt oben):

* Ein bestimmtes Programm, w√§hrend es auf dem Betriebssystem **ausgef√ºhrt** wird.
    * Dies bezieht sich weder auf die Datei noch auf den Code, sondern **speziell** auf das, was vom Betriebssystem **ausgef√ºhrt** und verwaltet wird.
* Jedes Programm, jeder Code **kann nur dann Dinge tun**, wenn er **ausgef√ºhrt** wird, wenn also ein **Prozess l√§uft**.
* Der Prozess kann von Ihnen oder vom Betriebssystem **terminiert** (‚Äûbeendet‚Äú, ‚Äûgekillt‚Äú) werden. An diesem Punkt h√∂rt es auf zu laufen/ausgef√ºhrt zu werden und kann **keine Dinge mehr tun**.
* Hinter jeder Anwendung, die Sie auf Ihrem Computer ausf√ºhren, steckt ein Prozess, jedes laufende Programm, jedes Fenster usw. Und normalerweise laufen viele Prozesse **gleichzeitig**, w√§hrend ein Computer eingeschaltet ist.
* Es k√∂nnen **mehrere Prozesse** desselben **Programms** gleichzeitig ausgef√ºhrt werden.

Wenn Sie sich den ‚ÄûTask-Manager‚Äú oder ‚ÄûSystemmonitor‚Äú (oder √§hnliche Tools) in Ihrem Betriebssystem ansehen, k√∂nnen Sie viele dieser laufenden Prozesse sehen.

Und Sie werden beispielsweise wahrscheinlich feststellen, dass mehrere Prozesse dasselbe Browserprogramm ausf√ºhren (Firefox, Chrome, Edge, usw.). Normalerweise f√ºhren diese einen Prozess pro Browsertab sowie einige andere zus√§tzliche Prozesse aus.

<img class="shadow" src="/img/deployment/concepts/image01.png">

---

Nachdem wir nun den Unterschied zwischen den Begriffen **Prozess** und **Programm** kennen, sprechen wir weiter √ºber das Deployment.

## Beim Hochfahren ausf√ºhren { #running-on-startup }

Wenn Sie eine Web-API erstellen, m√∂chten Sie in den meisten F√§llen, dass diese **immer l√§uft**, ununterbrochen, damit Ihre Clients immer darauf zugreifen k√∂nnen. Es sei denn nat√ºrlich, Sie haben einen bestimmten Grund, warum Sie m√∂chten, dass diese nur in bestimmten Situationen ausgef√ºhrt wird. Meistens m√∂chten Sie jedoch, dass sie st√§ndig ausgef√ºhrt wird und **verf√ºgbar** ist.

### Auf einem entfernten Server { #in-a-remote-server }

Wenn Sie einen entfernten Server (einen Cloud-Server, eine virtuelle Maschine, usw.) einrichten, k√∂nnen Sie am einfachsten `fastapi run` (welches Uvicorn verwendet) oder etwas √Ñhnliches manuell ausf√ºhren, genau wie bei der lokalen Entwicklung.

Und es wird funktionieren und **w√§hrend der Entwicklung** n√ºtzlich sein.

Wenn Ihre Verbindung zum Server jedoch unterbrochen wird, wird der **laufende Prozess** wahrscheinlich abst√ºrzen.

Und wenn der Server neu gestartet wird (z. B. nach Updates oder Migrationen vom Cloud-Anbieter), werden Sie das wahrscheinlich **nicht bemerken**. Und deshalb wissen Sie nicht einmal, dass Sie den Prozess manuell neu starten m√ºssen. Ihre API bleibt also einfach tot. üò±

### Beim Hochfahren automatisch ausf√ºhren { #run-automatically-on-startup }

Im Allgemeinen m√∂chten Sie wahrscheinlich, dass das Serverprogramm (z. B. Uvicorn) beim Hochfahren des Servers automatisch gestartet wird und kein **menschliches Eingreifen** erforderlich ist, sodass immer ein Prozess mit Ihrer API ausgef√ºhrt wird (z. B. Uvicorn, welches Ihre FastAPI-Anwendung ausf√ºhrt).

### Separates Programm { #separate-program }

Um dies zu erreichen, haben Sie normalerweise ein **separates Programm**, welches sicherstellt, dass Ihre Anwendung beim Hochfahren ausgef√ºhrt wird. Und in vielen F√§llen w√ºrde es auch sicherstellen, dass auch andere Komponenten oder Anwendungen ausgef√ºhrt werden, beispielsweise eine Datenbank.

### Beispieltools zur Ausf√ºhrung beim Hochfahren { #example-tools-to-run-at-startup }

Einige Beispiele f√ºr Tools, die diese Aufgabe √ºbernehmen k√∂nnen, sind:

* Docker
* Kubernetes
* Docker Compose
* Docker im Schwarm-Modus
* Systemd
* Supervisor
* Es wird intern von einem Cloud-Anbieter im Rahmen seiner Dienste verwaltet
* Andere ...

In den n√§chsten Kapiteln werde ich Ihnen konkretere Beispiele geben.

## Neustart { #restarts }

√Ñhnlich wie Sie sicherstellen m√∂chten, dass Ihre Anwendung beim Hochfahren ausgef√ºhrt wird, m√∂chten Sie wahrscheinlich auch sicherstellen, dass diese nach Fehlern **neu gestartet** wird.

### Wir machen Fehler { #we-make-mistakes }

Wir, als Menschen, machen st√§ndig **Fehler**. Software hat fast *immer* **Bugs**, die an verschiedenen Stellen versteckt sind. üêõ

Und wir als Entwickler verbessern den Code st√§ndig, wenn wir diese Bugs finden und neue Funktionen implementieren (und m√∂glicherweise auch neue Bugs hinzuf√ºgen üòÖ).

### Kleine Fehler automatisch handhaben { #small-errors-automatically-handled }

Wenn beim Erstellen von Web-APIs mit FastAPI ein Fehler in unserem Code auftritt, wird FastAPI ihn normalerweise dem einzelnen <abbr title="Request ‚Äì Anfrage: Daten, die der Client zum Server sendet">Request</abbr> zur√ºckgeben, der den Fehler ausgel√∂st hat. üõ°

Der Client erh√§lt f√ºr diesen Request einen **500 Internal Server Error**, aber die Anwendung arbeitet bei den n√§chsten Requests weiter, anstatt einfach komplett abzust√ºrzen.

### Gr√∂√üere Fehler ‚Äì Abst√ºrze { #bigger-errors-crashes }

Dennoch kann es vorkommen, dass wir Code schreiben, der **die gesamte Anwendung zum Absturz bringt** und so zum Absturz von Uvicorn und Python f√ºhrt. üí•

Und dennoch m√∂chten Sie wahrscheinlich nicht, dass die Anwendung tot bleibt, weil an einer Stelle ein Fehler aufgetreten ist. Sie m√∂chten wahrscheinlich, dass sie zumindest f√ºr die *Pfadoperationen*, die nicht fehlerhaft sind, **weiterl√§uft**.

### Neustart nach Absturz { #restart-after-crash }

Aber in den F√§llen mit wirklich schwerwiegenden Fehlern, die den laufenden **Prozess** zum Absturz bringen, ben√∂tigen Sie eine externe Komponente, die den Prozess **neu startet**, zumindest ein paar Mal ...

/// tip | Tipp

... Obwohl es wahrscheinlich keinen Sinn macht, sie immer wieder neu zu starten, wenn die gesamte Anwendung einfach **sofort abst√ºrzt**. Aber in diesen F√§llen werden Sie es wahrscheinlich w√§hrend der Entwicklung oder zumindest direkt nach dem Deployment bemerken.

Konzentrieren wir uns also auf die Hauptf√§lle, in denen die Anwendung in bestimmten F√§llen **in der Zukunft** v√∂llig abst√ºrzen k√∂nnte und es dann dennoch sinnvoll ist, sie neu zu starten.

///

Sie m√∂chten wahrscheinlich, dass eine **externe Komponente** f√ºr den Neustart Ihrer Anwendung verantwortlich ist, da zu diesem Zeitpunkt dieselbe Anwendung mit Uvicorn und Python bereits abgest√ºrzt ist und es daher nichts im selben Code derselben Anwendung gibt, was etwas dagegen tun kann.

### Beispieltools zum automatischen Neustart { #example-tools-to-restart-automatically }

In den meisten F√§llen wird dasselbe Tool, das zum **Ausf√ºhren des Programms beim Hochfahren** verwendet wird, auch f√ºr automatische **Neustarts** verwendet.

Dies k√∂nnte zum Beispiel erledigt werden durch:

* Docker
* Kubernetes
* Docker Compose
* Docker im Schwarm-Modus
* Systemd
* Supervisor
* Intern von einem Cloud-Anbieter im Rahmen seiner Dienste
* Andere ...

## Replikation ‚Äì Prozesse und Arbeitsspeicher { #replication-processes-and-memory }

Wenn Sie eine FastAPI-Anwendung verwenden und ein Serverprogramm wie den `fastapi`-Befehl, der Uvicorn ausf√ºhrt, kann **ein einzelner Prozess** an mehrere Clients gleichzeitig ausliefern.

In vielen F√§llen m√∂chten Sie jedoch mehrere Workerprozesse gleichzeitig ausf√ºhren.

### Mehrere Prozesse ‚Äì Worker { #multiple-processes-workers }

Wenn Sie mehr Clients haben, als ein einzelner Prozess verarbeiten kann (z. B. wenn die virtuelle Maschine nicht sehr gro√ü ist) und die CPU des Servers **mehrere Kerne** hat, dann k√∂nnten **mehrere Prozesse** gleichzeitig mit derselben Anwendung laufen und alle Requests unter sich verteilen.

Wenn Sie mit **mehreren Prozessen** dasselbe API-Programm ausf√ºhren, werden diese √ºblicherweise als <abbr title="Arbeiter">**Worker**</abbr> bezeichnet.

### Workerprozesse und Ports { #worker-processes-and-ports }

Erinnern Sie sich aus der Dokumentation [√úber HTTPS](https.md){.internal-link target=_blank}, dass nur ein Prozess auf einer Kombination aus Port und IP-Adresse auf einem Server lauschen kann?

Das ist immer noch wahr.

Um also **mehrere Prozesse** gleichzeitig zu haben, muss es einen **einzelnen Prozess geben, der einen Port √ºberwacht**, welcher dann die Kommunikation auf irgendeine Weise an jeden Workerprozess √ºbertr√§gt.

### Arbeitsspeicher pro Prozess { #memory-per-process }

Wenn das Programm nun Dinge in den Arbeitsspeicher l√§dt, zum Beispiel ein Modell f√ºr maschinelles Lernen in einer Variablen oder den Inhalt einer gro√üen Datei in einer Variablen, verbraucht das alles **einen Teil des Arbeitsspeichers (RAM ‚Äì Random Access Memory)** des Servers.

Und mehrere Prozesse teilen sich normalerweise keinen Speicher. Das bedeutet, dass jeder laufende Prozess seine eigenen Dinge, eigenen Variablen und eigenen Speicher hat. Und wenn Sie in Ihrem Code viel Speicher verbrauchen, verbraucht **jeder Prozess** die gleiche Menge Speicher.

### Serverspeicher { #server-memory }

Wenn Ihr Code beispielsweise ein Machine-Learning-Modell mit **1 GB Gr√∂√üe** l√§dt und Sie einen Prozess mit Ihrer API ausf√ºhren, verbraucht dieser mindestens 1 GB RAM. Und wenn Sie **4 Prozesse** (4 Worker) starten, verbraucht jeder 1 GB RAM. Insgesamt verbraucht Ihre API also **4 GB RAM**.

Und wenn Ihr entfernter Server oder Ihre virtuelle Maschine nur √ºber 3 GB RAM verf√ºgt, f√ºhrt der Versuch, mehr als 4 GB RAM zu laden, zu Problemen. üö®

### Mehrere Prozesse ‚Äì Ein Beispiel { #multiple-processes-an-example }

Im folgenden Beispiel gibt es einen **Manager-Prozess**, welcher zwei **Workerprozesse** startet und steuert.

Dieser Manager-Prozess w√§re wahrscheinlich derjenige, welcher der IP am **Port** lauscht. Und er w√ºrde die gesamte Kommunikation an die Workerprozesse weiterleiten.

Diese Workerprozesse w√ºrden Ihre Anwendung ausf√ºhren, sie w√ºrden die Hauptberechnungen durchf√ºhren, um einen **<abbr title="Request ‚Äì Anfrage: Daten, die der Client zum Server sendet">Request</abbr>** entgegenzunehmen und eine **<abbr title="Response ‚Äì Antwort: Daten, die der Server zum anfragenden Client zur√ºcksendet">Response</abbr>** zur√ºckzugeben, und sie w√ºrden alles, was Sie in Variablen einf√ºgen, in den RAM laden.

<img src="/img/deployment/concepts/process-ram.drawio.svg">

Und nat√ºrlich w√ºrden auf derselben Maschine neben Ihrer Anwendung wahrscheinlich **andere Prozesse** laufen.

Ein interessantes Detail ist dabei, dass der Prozentsatz der von jedem Prozess verwendeten **CPU** im Laufe der Zeit stark **variieren** kann, der **Arbeitsspeicher (RAM)** jedoch normalerweise mehr oder weniger **stabil** bleibt.

Wenn Sie eine API haben, die jedes Mal eine vergleichbare Menge an Berechnungen durchf√ºhrt, und Sie viele Clients haben, dann wird die **CPU-Auslastung** wahrscheinlich *ebenfalls stabil sein* (anstatt st√§ndig schnell zu steigen und zu fallen).

### Beispiele f√ºr Replikation-Tools und -Strategien { #examples-of-replication-tools-and-strategies }

Es gibt mehrere Ans√§tze, um dies zu erreichen, und ich werde Ihnen in den n√§chsten Kapiteln mehr √ºber bestimmte Strategien erz√§hlen, beispielsweise wenn es um Docker und Container geht.

Die wichtigste zu ber√ºcksichtigende Einschr√§nkung besteht darin, dass es eine **einzelne** Komponente geben muss, welche die **√∂ffentliche IP** auf dem **Port** verwaltet. Und dann muss diese irgendwie die Kommunikation **weiterleiten**, an die replizierten **Prozesse/Worker**.

Hier sind einige m√∂gliche Kombinationen und Strategien:

* **Uvicorn** mit `--workers`
    * Ein Uvicorn-**Prozessmanager** w√ºrde der **IP** am **Port** lauschen, und er w√ºrde **mehrere Uvicorn-Workerprozesse** starten.
* **Kubernetes** und andere verteilte **Containersysteme**
    * Etwas in der **Kubernetes**-Ebene w√ºrde die **IP** und den **Port** abh√∂ren. Die Replikation h√§tte **mehrere Container**, in jedem wird jeweils **ein Uvicorn-Prozess** ausgef√ºhrt.
* **Cloud-Dienste**, welche das f√ºr Sie erledigen
    * Der Cloud-Dienst wird wahrscheinlich **die Replikation f√ºr Sie √ºbernehmen**. Er w√ºrde Sie m√∂glicherweise **einen auszuf√ºhrenden Prozess** oder ein **zu verwendendes Container-Image** definieren lassen, in jedem Fall w√§re es h√∂chstwahrscheinlich **ein einzelner Uvicorn-Prozess**, und der Cloud-Dienst w√§re auch verantwortlich f√ºr die Replikation.

/// tip | Tipp

Machen Sie sich keine Sorgen, wenn einige dieser Punkte zu **Containern**, Docker oder Kubernetes noch nicht viel Sinn ergeben.

Ich werde Ihnen in einem zuk√ºnftigen Kapitel mehr √ºber Container-Images, Docker, Kubernetes, usw. erz√§hlen: [FastAPI in Containern ‚Äì Docker](docker.md){.internal-link target=_blank}.

///

## Schritte vor dem Start { #previous-steps-before-starting }

Es gibt viele F√§lle, in denen Sie, **bevor Sie Ihre Anwendung starten**, einige Schritte ausf√ºhren m√∂chten.

Beispielsweise m√∂chten Sie m√∂glicherweise **Datenbankmigrationen** ausf√ºhren.

In den meisten F√§llen m√∂chten Sie diese Schritte jedoch nur **einmal** ausf√ºhren.

Sie m√∂chten also einen **einzelnen Prozess** haben, um diese **Vorab-Schritte** auszuf√ºhren, bevor Sie die Anwendung starten.

Und Sie m√ºssen sicherstellen, dass es sich um einen einzelnen Prozess handelt, der die Vorab-Schritte ausf√ºhrt, *auch* wenn Sie anschlie√üend **mehrere Prozesse** (mehrere Worker) f√ºr die Anwendung selbst starten. Wenn diese Schritte von **mehreren Prozessen** ausgef√ºhrt w√ºrden, w√ºrden diese die Arbeit **verdoppeln**, indem sie sie **parallel** ausf√ºhren, und wenn es sich bei den Schritten um etwas Delikates wie eine Datenbankmigration handelt, k√∂nnte das miteinander Konflikte verursachen.

Nat√ºrlich gibt es F√§lle, in denen es kein Problem darstellt, die Vorab-Schritte mehrmals auszuf√ºhren. In diesem Fall ist die Handhabung viel einfacher.

/// tip | Tipp

Bedenken Sie au√üerdem, dass Sie, abh√§ngig von Ihrer Einrichtung, in manchen F√§llen **gar keine Vorab-Schritte** ben√∂tigen, bevor Sie die Anwendung starten.

In diesem Fall m√ºssen Sie sich dar√ºber keine Sorgen machen. ü§∑

///

### Beispiele f√ºr Strategien f√ºr Vorab-Schritte { #examples-of-previous-steps-strategies }

Es h√§ngt **stark** davon ab, wie Sie **Ihr System bereitstellen**, und h√§ngt wahrscheinlich mit der Art und Weise zusammen, wie Sie Programme starten, Neustarts durchf√ºhren, usw.

Hier sind einige m√∂gliche Ideen:

* Ein ‚ÄûInit-Container‚Äú in Kubernetes, der vor Ihrem Anwendungs-Container ausgef√ºhrt wird
* Ein Bash-Skript, das die Vorab-Schritte ausf√ºhrt und dann Ihre Anwendung startet
    * Sie ben√∂tigen immer noch eine M√∂glichkeit, *dieses* Bash-Skript zu starten/neu zu starten, Fehler zu erkennen, usw.

/// tip | Tipp

Konkretere Beispiele hierf√ºr mit Containern gebe ich Ihnen in einem sp√§teren Kapitel: [FastAPI in Containern ‚Äì Docker](docker.md){.internal-link target=_blank}.

///

## Ressourcennutzung { #resource-utilization }

Ihr(e) Server ist (sind) eine **Ressource**, welche Sie mit Ihren Programmen, der Rechenzeit auf den CPUs und dem verf√ºgbaren RAM-Speicher verbrauchen oder **nutzen** k√∂nnen.

Wie viele Systemressourcen m√∂chten Sie verbrauchen/nutzen? Sie m√∂gen ‚Äûnicht viel‚Äú denken, aber in Wirklichkeit m√∂chten Sie tats√§chlich **so viel wie m√∂glich ohne Absturz** verwenden.

Wenn Sie f√ºr drei Server bezahlen, aber nur wenig von deren RAM und CPU nutzen, **verschwenden Sie wahrscheinlich Geld** üí∏ und wahrscheinlich **Strom f√ºr den Server** üåé, usw.

In diesem Fall k√∂nnte es besser sein, nur zwei Server zu haben und einen h√∂heren Prozentsatz von deren Ressourcen zu nutzen (CPU, Arbeitsspeicher, Festplatte, Netzwerkbandbreite, usw.).

Wenn Sie andererseits √ºber zwei Server verf√ºgen und **100 % ihrer CPU und ihres RAM** nutzen, wird irgendwann ein Prozess nach mehr Speicher fragen und der Server muss die Festplatte als ‚ÄûSpeicher‚Äú verwenden (was tausendmal langsamer sein kann) oder er k√∂nnte sogar **abst√ºrzen**. Oder ein Prozess muss m√∂glicherweise einige Berechnungen durchf√ºhren und m√ºsste warten, bis die CPU wieder frei ist.

In diesem Fall w√§re es besser, **einen zus√§tzlichen Server** zu besorgen und einige Prozesse darauf auszuf√ºhren, damit alle √ºber **genug RAM und CPU-Zeit** verf√ºgen.

Es besteht auch die M√∂glichkeit, dass es aus irgendeinem Grund zu **Spitzen** in der Nutzung Ihrer API kommt. Vielleicht ist diese viral gegangen, oder vielleicht haben andere Dienste oder Bots damit begonnen, sie zu nutzen. Und vielleicht m√∂chten Sie in solchen F√§llen √ºber zus√§tzliche Ressourcen verf√ºgen, um auf der sicheren Seite zu sein.

Sie k√∂nnen eine **beliebige Zahl** festlegen, um beispielsweise eine Ressourcenauslastung zwischen **50 % und 90 %** anzustreben. Der Punkt ist, dass dies wahrscheinlich die wichtigen Dinge sind, die Sie messen und verwenden sollten, um Ihre Deployments zu optimieren.

Sie k√∂nnen einfache Tools wie `htop` verwenden, um die in Ihrem Server verwendete CPU und den RAM oder die von jedem Prozess verwendete Menge anzuzeigen. Oder Sie k√∂nnen komplexere √úberwachungstools verwenden, die m√∂glicherweise auf mehrere Server usw. verteilt sind.

## Zusammenfassung { #recap }

Sie haben hier einige der wichtigsten Konzepte gelesen, die Sie wahrscheinlich ber√ºcksichtigen m√ºssen, wenn Sie entscheiden, wie Sie Ihre Anwendung bereitstellen:

* Sicherheit ‚Äì HTTPS
* Beim Hochfahren ausf√ºhren
* Neustarts
* Replikation (die Anzahl der laufenden Prozesse)
* Arbeitsspeicher
* Schritte vor dem Start

Das Verst√§ndnis dieser Ideen und deren Anwendung sollte Ihnen die n√∂tige Intuition vermitteln, um bei der Konfiguration und Optimierung Ihrer Deployments Entscheidungen zu treffen. ü§ì

In den n√§chsten Abschnitten gebe ich Ihnen konkretere Beispiele f√ºr m√∂gliche Strategien, die Sie verfolgen k√∂nnen. üöÄ
