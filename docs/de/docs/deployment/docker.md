# FastAPI in Containern ‚Äì Docker

Beim Deployment von FastAPI-Anwendungen besteht ein g√§ngiger Ansatz darin, ein **Linux-Containerimage** zu erstellen. Normalerweise erfolgt dies mit <a href="https://www.docker.com/" class="external-link" target="_blank">**Docker**</a>. Sie k√∂nnen dieses Containerimage dann auf eine von mehreren m√∂glichen Arten bereitstellen.

Die Verwendung von Linux-Containern bietet mehrere Vorteile, darunter **Sicherheit**, **Replizierbarkeit**, **Einfachheit** und andere.

/// tip | "Tipp"

Sie haben es eilig und kennen sich bereits aus? Springen Sie zum [`Dockerfile` unten üëá](#ein-docker-image-fur-fastapi-erstellen).

///

<Details>
<summary>Dockerfile-Vorschau üëÄ</summary>

```Dockerfile
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80"]

# Wenn Sie hinter einem Proxy wie Nginx oder Traefik sind, f√ºgen Sie --proxy-headers hinzu
# CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80", "--proxy-headers"]
```

</details>

## Was ist ein Container?

Container (haupts√§chlich Linux-Container) sind eine sehr **leichtgewichtige** M√∂glichkeit, Anwendungen einschlie√ülich aller ihrer Abh√§ngigkeiten und erforderlichen Dateien zu verpacken und sie gleichzeitig von anderen Containern (anderen Anwendungen oder Komponenten) im selben System isoliert zu halten.

Linux-Container werden mit demselben Linux-Kernel des Hosts (Maschine, virtuellen Maschine, Cloud-Servers, usw.) ausgef√ºhrt. Das bedeutet einfach, dass sie sehr leichtgewichtig sind (im Vergleich zu vollst√§ndigen virtuellen Maschinen, die ein gesamtes Betriebssystem emulieren).

Auf diese Weise verbrauchen Container **wenig Ressourcen**, eine Menge vergleichbar mit der direkten Ausf√ºhrung der Prozesse (eine virtuelle Maschine w√ºrde viel mehr verbrauchen).

Container verf√ºgen au√üerdem √ºber ihre eigenen **isoliert** laufenden Prozesse (√ºblicherweise nur einen Prozess), √ºber ihr eigenes Dateisystem und ihr eigenes Netzwerk, was die Bereitstellung, Sicherheit, Entwicklung usw. vereinfacht.

## Was ist ein Containerimage?

Ein **Container** wird von einem **Containerimage** ausgef√ºhrt.

Ein Containerimage ist eine **statische** Version aller Dateien, Umgebungsvariablen und des Standardbefehls/-programms, welche in einem Container vorhanden sein sollten. **Statisch** bedeutet hier, dass das Container-**Image** nicht l√§uft, nicht ausgef√ºhrt wird, sondern nur die gepackten Dateien und Metadaten enth√§lt.

Im Gegensatz zu einem ‚Äû**Containerimage**‚Äú, bei dem es sich um den gespeicherten statischen Inhalt handelt, bezieht sich ein ‚Äû**Container**‚Äú normalerweise auf die laufende Instanz, das Ding, das **ausgef√ºhrt** wird.

Wenn der **Container** gestartet und ausgef√ºhrt wird (gestartet von einem **Containerimage**), kann er Dateien, Umgebungsvariablen usw. erstellen oder √§ndern. Diese √Ñnderungen sind nur in diesem Container vorhanden, nicht im zugrunde liegenden bestehen Containerimage (werden nicht auf der Festplatte gespeichert).

Ein Containerimage ist vergleichbar mit der **Programmdatei** und ihrem Inhalt, z. B. `python` und eine Datei `main.py`.

Und der **Container** selbst (im Gegensatz zum **Containerimage**) ist die tats√§chlich laufende Instanz des Images, vergleichbar mit einem **Prozess**. Tats√§chlich l√§uft ein Container nur, wenn er einen **laufenden Prozess** hat (und normalerweise ist es nur ein einzelner Prozess). Der Container stoppt, wenn kein Prozess darin ausgef√ºhrt wird.

## Containerimages

Docker ist eines der wichtigsten Tools zum Erstellen und Verwalten von **Containerimages** und **Containern**.

Und es gibt einen √∂ffentlichen <a href="https://hub.docker.com/" class="external-link" target="_blank">Docker <abbr title="Umschlagsplatz">Hub</abbr></a> mit vorgefertigten **offiziellen Containerimages** f√ºr viele Tools, Umgebungen, Datenbanken und Anwendungen.

Beispielsweise gibt es ein offizielles <a href="https://hub.docker.com/_/python" class="external-link" target="_blank">Python-Image</a>.

Und es gibt viele andere Images f√ºr verschiedene Dinge wie Datenbanken, zum Beispiel f√ºr:

* <a href="https://hub.docker.com/_/postgres" class="external-link" target="_blank">PostgreSQL</a>
* <a href="https://hub.docker.com/_/mysql" class="external-link" target="_blank">MySQL</a>
* <a href="https://hub.docker.com/_/mongo" class="external-link" target="_blank">MongoDB</a>
* <a href="https://hub.docker.com/_/redis" class="external-link" target="_blank">Redis</a>, usw.

Durch die Verwendung eines vorgefertigten Containerimages ist es sehr einfach, verschiedene Tools zu **kombinieren** und zu verwenden. Zum Beispiel, um eine neue Datenbank auszuprobieren. In den meisten F√§llen k√∂nnen Sie die **offiziellen Images** verwenden und diese einfach mit Umgebungsvariablen konfigurieren.

Auf diese Weise k√∂nnen Sie in vielen F√§llen etwas √ºber Container und Docker lernen und dieses Wissen mit vielen verschiedenen Tools und Komponenten wiederverwenden.

Sie w√ºrden also **mehrere Container** mit unterschiedlichen Dingen ausf√ºhren, wie einer Datenbank, einer Python-Anwendung, einem Webserver mit einer React-Frontend-Anwendung, und diese √ºber ihr internes Netzwerk miteinander verbinden.

In alle Containerverwaltungssysteme (wie Docker oder Kubernetes) sind diese Netzwerkfunktionen integriert.

## Container und Prozesse

Ein **Containerimage** enth√§lt normalerweise in seinen Metadaten das Standardprogramm oder den Standardbefehl, der ausgef√ºhrt werden soll, wenn der **Container** gestartet wird, sowie die Parameter, die an dieses Programm √ºbergeben werden sollen. Sehr √§hnlich zu dem, was w√§re, wenn es √ºber die Befehlszeile gestartet werden w√ºrde.

Wenn ein **Container** gestartet wird, f√ºhrt er diesen Befehl/dieses Programm aus (Sie k√∂nnen ihn jedoch √ºberschreiben und einen anderen Befehl/ein anderes Programm ausf√ºhren lassen).

Ein Container l√§uft, solange der **Hauptprozess** (Befehl oder Programm) l√§uft.

Ein Container hat normalerweise einen **einzelnen Prozess**, aber es ist auch m√∂glich, Unterprozesse vom Hauptprozess aus zu starten, und auf diese Weise haben Sie **mehrere Prozesse** im selben Container.

Es ist jedoch nicht m√∂glich, einen laufenden Container, ohne **mindestens einen laufenden Prozess** zu haben. Wenn der Hauptprozess stoppt, stoppt der Container.

## Ein Docker-Image f√ºr FastAPI erstellen

Okay, wollen wir jetzt etwas bauen! üöÄ

Ich zeige Ihnen, wie Sie ein **Docker-Image** f√ºr FastAPI **von Grund auf** erstellen, basierend auf dem **offiziellen Python**-Image.

Das ist, was Sie in **den meisten F√§llen** tun m√∂chten, zum Beispiel:

* Bei Verwendung von **Kubernetes** oder √§hnlichen Tools
* Beim Betrieb auf einem **Raspberry Pi**
* Bei Verwendung eines Cloud-Dienstes, der ein Containerimage f√ºr Sie ausf√ºhrt, usw.

### Paketanforderungen

Normalerweise befinden sich die **Paketanforderungen** f√ºr Ihre Anwendung in einer Datei.

Dies h√§ngt haupts√§chlich von dem Tool ab, mit dem Sie diese Anforderungen **installieren**.

Die gebr√§uchlichste Methode besteht darin, eine Datei `requirements.txt` mit den Namen der Packages und deren Versionen zu erstellen, eine pro Zeile.

Sie w√ºrden nat√ºrlich die gleichen Ideen verwenden, die Sie in [√úber FastAPI-Versionen](versions.md){.internal-link target=_blank} gelesen haben, um die Versionsbereiche festzulegen.

Ihre `requirements.txt` k√∂nnte beispielsweise so aussehen:

```
fastapi>=0.68.0,<0.69.0
pydantic>=1.8.0,<2.0.0
uvicorn>=0.15.0,<0.16.0
```

Und normalerweise w√ºrden Sie diese Paketabh√§ngigkeiten mit `pip` installieren, zum Beispiel:

<div class="termy">

```console
$ pip install -r requirements.txt
---> 100%
Successfully installed fastapi pydantic uvicorn
```

</div>

/// info

Es gibt andere Formate und Tools zum Definieren und Installieren von Paketabh√§ngigkeiten.

Ich zeige Ihnen sp√§ter in einem Abschnitt unten ein Beispiel unter Verwendung von Poetry. üëá

///

### Den **FastAPI**-Code erstellen

* Erstellen Sie ein `app`-Verzeichnis und betreten Sie es.
* Erstellen Sie eine leere Datei `__init__.py`.
* Erstellen Sie eine `main.py`-Datei mit:

```Python
from typing import Union

from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}
```

### Dockerfile

Erstellen Sie nun im selben Projektverzeichnis eine Datei `Dockerfile` mit:

```{ .dockerfile .annotate }
# (1)
FROM python:3.9

# (2)
WORKDIR /code

# (3)
COPY ./requirements.txt /code/requirements.txt

# (4)
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (5)
COPY ./app /code/app

# (6)
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80"]
```

1. Beginne mit dem offiziellen Python-Basisimage.

2. Setze das aktuelle Arbeitsverzeichnis auf `/code`.

    Hier plazieren wir die Datei `requirements.txt` und das Verzeichnis `app`.

3. Kopiere die Datei mit den Paketanforderungen in das Verzeichnis `/code`.

    Kopieren Sie zuerst **nur** die Datei mit den Anforderungen, nicht den Rest des Codes.

    Da sich diese Datei **nicht oft √§ndert**, erkennt Docker das und verwendet den **Cache** f√ºr diesen Schritt, wodurch der Cache auch f√ºr den n√§chsten Schritt aktiviert wird.

4. Installiere die Paketabh√§ngigkeiten aus der Anforderungsdatei.

    Die Option `--no-cache-dir` weist `pip` an, die heruntergeladenen Pakete nicht lokal zu speichern, da dies nur ben√∂tigt wird, sollte `pip` erneut ausgef√ºhrt werden, um dieselben Pakete zu installieren, aber das ist beim Arbeiten mit Containern nicht der Fall.

    /// note | Hinweis

    Das `--no-cache-dir` bezieht sich nur auf `pip`, es hat nichts mit Docker oder Containern zu tun.

    ///

    Die Option `--upgrade` weist `pip` an, die Packages zu aktualisieren, wenn sie bereits installiert sind.

    Da der vorherige Schritt des Kopierens der Datei vom **Docker-Cache** erkannt werden konnte, wird dieser Schritt auch **den Docker-Cache verwenden**, sofern verf√ºgbar.

    Durch die Verwendung des Caches in diesem Schritt **sparen** Sie viel **Zeit**, wenn Sie das Image w√§hrend der Entwicklung immer wieder erstellen, anstatt **jedes Mal** alle Abh√§ngigkeiten **herunterzuladen und zu installieren**.

5. Kopiere das Verzeichnis `./app` in das Verzeichnis `/code`.

    Da hier der gesamte Code enthalten ist, der sich **am h√§ufigsten √§ndert**, wird der Docker-**Cache** nicht ohne weiteres f√ºr diesen oder andere **folgende Schritte** verwendet.

    Daher ist es wichtig, dies **nahe dem Ende** des `Dockerfile`s zu platzieren, um die Erstellungszeiten des Containerimages zu optimieren.

6. Lege den **Befehl** fest, um den `uvicorn`-Server zu starten.

    `CMD` nimmt eine Liste von Zeichenfolgen entgegen. Jede dieser Zeichenfolgen entspricht dem, was Sie durch Leerzeichen getrennt in die Befehlszeile eingeben w√ºrden.

    Dieser Befehl wird aus dem **aktuellen Arbeitsverzeichnis** ausgef√ºhrt, dem gleichen `/code`-Verzeichnis, das Sie oben mit `WORKDIR /code` festgelegt haben.

    Da das Programm unter `/code` gestartet wird und sich darin das Verzeichnis `./app` mit Ihrem Code befindet, kann **Uvicorn** `app` sehen und aus `app.main` **importieren**.

/// tip | "Tipp"

Lernen Sie, was jede Zeile bewirkt, indem Sie auf die Zahlenblasen im Code klicken. üëÜ

///

Sie sollten jetzt eine Verzeichnisstruktur wie diese haben:

```
.
‚îú‚îÄ‚îÄ app
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ requirements.txt
```

#### Hinter einem TLS-Terminierungsproxy

Wenn Sie Ihren Container hinter einem TLS-Terminierungsproxy (Load Balancer) wie Nginx oder Traefik ausf√ºhren, f√ºgen Sie die Option `--proxy-headers` hinzu. Das sagt Uvicorn, den von diesem Proxy gesendeten Headern zu vertrauen und dass die Anwendung hinter HTTPS ausgef√ºhrt wird, usw.

```Dockerfile
CMD ["uvicorn", "app.main:app", "--proxy-headers", "--host", "0.0.0.0", "--port", "80"]
```

#### Docker-Cache

In diesem `Dockerfile` gibt es einen wichtigen Trick: Wir kopieren zuerst die **Datei nur mit den Abh√§ngigkeiten**, nicht den Rest des Codes. Lassen Sie mich Ihnen erkl√§ren, warum.

```Dockerfile
COPY ./requirements.txt /code/requirements.txt
```

Docker und andere Tools **erstellen** diese Containerimages **inkrementell**, f√ºgen **eine Ebene √ºber der anderen** hinzu, beginnend am Anfang des `Dockerfile`s und f√ºgen alle durch die einzelnen Anweisungen des `Dockerfile`s erstellten Dateien hinzu.

Docker und √§hnliche Tools verwenden beim Erstellen des Images auch einen **internen Cache**. Wenn sich eine Datei seit der letzten Erstellung des Containerimages nicht ge√§ndert hat, wird **dieselbe Ebene wiederverwendet**, die beim letzten Mal erstellt wurde, anstatt die Datei erneut zu kopieren und eine neue Ebene von Grund auf zu erstellen.

Das blo√üe Vermeiden des Kopierens von Dateien f√ºhrt nicht unbedingt zu einer gro√üen Verbesserung, aber da der Cache f√ºr diesen Schritt verwendet wurde, kann **der Cache f√ºr den n√§chsten Schritt verwendet werden**. Beispielsweise k√∂nnte der Cache verwendet werden f√ºr die Anweisung, welche die Abh√§ngigkeiten installiert mit:

```Dockerfile
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt
```

Die Datei mit den Paketanforderungen wird sich **nicht h√§ufig √§ndern**. Wenn Docker also nur diese Datei kopiert, kann es f√ºr diesen Schritt **den Cache verwenden**.

Und dann kann Docker **den Cache f√ºr den n√§chsten Schritt verwenden**, der diese Abh√§ngigkeiten herunterl√§dt und installiert. Und hier **sparen wir viel Zeit**. ‚ú® ... und vermeiden die Langeweile beim Warten. üò™üòÜ

Das Herunterladen und Installieren der Paketabh√§ngigkeiten **k√∂nnte Minuten dauern**, aber die Verwendung des **Cache** w√ºrde h√∂chstens **Sekunden** dauern.

Und da Sie das Containerimage w√§hrend der Entwicklung immer wieder erstellen w√ºrden, um zu √ºberpr√ºfen, ob Ihre Code√§nderungen funktionieren, w√ºrde dies viel Zeit sparen.

Dann, gegen Ende des `Dockerfile`s, kopieren wir den gesamten Code. Da sich der **am h√§ufigsten √§ndert**, platzieren wir das am Ende, da fast immer alles nach diesem Schritt nicht mehr in der Lage sein wird, den Cache zu verwenden.

```Dockerfile
COPY ./app /code/app
```

### Das Docker-Image erstellen

Nachdem nun alle Dateien vorhanden sind, erstellen wir das Containerimage.

* Gehen Sie zum Projektverzeichnis (dort, wo sich Ihr `Dockerfile` und Ihr `app`-Verzeichnis befindet).
* Erstellen Sie Ihr FastAPI-Image:

<div class="termy">

```console
$ docker build -t myimage .

---> 100%
```

</div>

/// tip | "Tipp"

Beachten Sie das `.` am Ende, es entspricht `./` und teilt Docker mit, welches Verzeichnis zum Erstellen des Containerimages verwendet werden soll.

In diesem Fall handelt es sich um dasselbe aktuelle Verzeichnis (`.`).

///

### Den Docker-Container starten

* F√ºhren Sie einen Container basierend auf Ihrem Image aus:

<div class="termy">

```console
$ docker run -d --name mycontainer -p 80:80 myimage
```

</div>

## Es √ºberpr√ºfen

Sie sollten es in der URL Ihres Docker-Containers √ºberpr√ºfen k√∂nnen, zum Beispiel: <a href="http://192.168.99.100/items/5?q=somequery" class="external-link" target="_blank">http://192.168.99.100/items/5?q=somequery</a> oder <a href="http://127.0.0.1/items/5?q=somequery" class="external-link" target="_blank">http://127.0.0.1/items/5?q=somequery</a> (oder gleichwertig, unter Verwendung Ihres Docker-Hosts).

Sie werden etwas sehen wie:

```JSON
{"item_id": 5, "q": "somequery"}
```

## Interaktive API-Dokumentation

Jetzt k√∂nnen Sie auf <a href="http://192.168.99.100/docs" class="external-link" target="_blank">http://192.168.99.100/docs</a> oder <a href="http://127.0.0.1/docs" class="external-link" target="_blank">http://127.0.0.1/docs</a> gehen (oder √§hnlich, unter Verwendung Ihres Docker-Hosts).

Sie sehen die automatische interaktive API-Dokumentation (bereitgestellt von <a href="https://github.com/swagger-api/swagger-ui" class="external-link" target="_blank">Swagger UI</a>):

![Swagger-Oberfl√§che](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)

## Alternative API-Dokumentation

Sie k√∂nnen auch auf <a href="http://192.168.99.100/redoc" class="external-link" target="_blank">http://192.168.99.100/redoc</a> oder <a href="http://127.0.0.1/redoc" class="external-link" target="_blank">http://127.0.0.1/redoc</a> gehen (oder √§hnlich, unter Verwendung Ihres Docker-Hosts).

Sie sehen die alternative automatische Dokumentation (bereitgestellt von <a href="https://github.com/Rebilly/ReDoc" class="external-link" target="_blank">ReDoc</a>):

![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)

## Ein Docker-Image mit einem Single-File-FastAPI erstellen

Wenn Ihr FastAPI eine einzelne Datei ist, zum Beispiel `main.py` ohne ein `./app`-Verzeichnis, k√∂nnte Ihre Dateistruktur wie folgt aussehen:

```
.
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ requirements.txt
```

Dann m√ºssten Sie nur noch die entsprechenden Pfade √§ndern, um die Datei im `Dockerfile` zu kopieren:

```{ .dockerfile .annotate hl_lines="10  13" }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (1)
COPY ./main.py /code/

# (2)
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "80"]
```

1. Kopiere die Datei `main.py` direkt in das Verzeichnis `/code` (ohne ein Verzeichnis `./app`).

2. F√ºhre Uvicorn aus und weisen es an, das `app`-Objekt von `main` zu importieren (anstatt von `app.main` zu importieren).

Passen Sie dann den Uvicorn-Befehl an, um das neue Modul `main` anstelle von `app.main` zu verwenden, um das FastAPI-Objekt `app` zu importieren.

## Deployment-Konzepte

Lassen Sie uns noch einmal √ºber einige der gleichen [Deployment-Konzepte](concepts.md){.internal-link target=_blank} in Bezug auf Container sprechen.

Container sind haupts√§chlich ein Werkzeug, um den Prozess des **Erstellens und Deployments** einer Anwendung zu vereinfachen, sie erzwingen jedoch keinen bestimmten Ansatz f√ºr die Handhabung dieser **Deployment-Konzepte**, und es gibt mehrere m√∂gliche Strategien.

Die **gute Nachricht** ist, dass es mit jeder unterschiedlichen Strategie eine M√∂glichkeit gibt, alle Deployment-Konzepte abzudecken. üéâ

Sehen wir uns diese **Deployment-Konzepte** im Hinblick auf Container noch einmal an:

* Sicherheit ‚Äì HTTPS
* Beim Hochfahren ausf√ºhren
* Neustarts
* Replikation (die Anzahl der laufenden Prozesse)
* Arbeitsspeicher
* Schritte vor dem Start

## HTTPS

Wenn wir uns nur auf das **Containerimage** f√ºr eine FastAPI-Anwendung (und sp√§ter auf den laufenden **Container**) konzentrieren, w√ºrde HTTPS normalerweise **extern** von einem anderen Tool verarbeitet.

Es k√∂nnte sich um einen anderen Container handeln, zum Beispiel mit <a href="https://traefik.io/" class="external-link" target="_blank">Traefik</a>, welcher **HTTPS** und **automatischen** Erwerb von **Zertifikaten** handhabt.

/// tip | "Tipp"

Traefik verf√ºgt √ºber Integrationen mit Docker, Kubernetes und anderen, sodass Sie damit ganz einfach HTTPS f√ºr Ihre Container einrichten und konfigurieren k√∂nnen.

///

Alternativ k√∂nnte HTTPS von einem Cloud-Anbieter als einer seiner Dienste gehandhabt werden (w√§hrend die Anwendung weiterhin in einem Container ausgef√ºhrt wird).

## Beim Hochfahren ausf√ºhren und Neustarts

Normalerweise gibt es ein anderes Tool, das f√ºr das **Starten und Ausf√ºhren** Ihres Containers zust√§ndig ist.

Es k√∂nnte sich um **Docker** direkt, **Docker Compose**, **Kubernetes**, einen **Cloud-Dienst**, usw. handeln.

In den meisten (oder allen) F√§llen gibt es eine einfache Option, um die Ausf√ºhrung des Containers beim Hochfahren und Neustarts bei Fehlern zu erm√∂glichen. In Docker ist es beispielsweise die Befehlszeilenoption `--restart`.

Ohne die Verwendung von Containern kann es umst√§ndlich und schwierig sein, Anwendungen beim Hochfahren auszuf√ºhren und neu zu starten. Bei der **Arbeit mit Containern** ist diese Funktionalit√§t jedoch in den meisten F√§llen standardm√§√üig enthalten. ‚ú®

## Replikation ‚Äì Anzahl der Prozesse

Wenn Sie einen <abbr title="Eine Gruppe von Maschinen, die so konfiguriert sind, dass sie verbunden sind und auf irgendeine Weise zusammenarbeiten.">Cluster</abbr> von Maschinen mit **Kubernetes**, Docker Swarm Mode, Nomad verwenden, oder einem anderen, √§hnlich komplexen System zur Verwaltung verteilter Container auf mehreren Maschinen, m√∂chten Sie wahrscheinlich die **Replikation auf Cluster-Ebene abwickeln**, anstatt in jedem Container einen **Prozessmanager** (wie Gunicorn mit Workern) zu verwenden.

Diese verteilten Containerverwaltungssysteme wie Kubernetes verf√ºgen normalerweise √ºber eine integrierte M√∂glichkeit, die **Replikation von Containern** zu handhaben und gleichzeitig **Load Balancing** f√ºr die eingehenden Requests zu unterst√ºtzen. Alles auf **Cluster-Ebene**.

In diesen F√§llen m√∂chten Sie wahrscheinlich ein **Docker-Image von Grund auf** erstellen, wie [oben erkl√§rt](#dockerfile), Ihre Abh√§ngigkeiten installieren und **einen einzelnen Uvicorn-Prozess** ausf√ºhren, anstatt etwas wie Gunicorn mit Uvicorn-Workern auszuf√ºhren.

### Load Balancer

Bei der Verwendung von Containern ist normalerweise eine Komponente vorhanden, **die am Hauptport lauscht**. Es k√∂nnte sich um einen anderen Container handeln, der auch ein **TLS-Terminierungsproxy** ist, um **HTTPS** zu verarbeiten, oder ein √§hnliches Tool.

Da diese Komponente die **Last** an Requests aufnehmen und diese (hoffentlich) **ausgewogen** auf die Worker verteilen w√ºrde, wird sie √ºblicherweise auch **Load Balancer** ‚Äì Lastverteiler ‚Äì genannt.

/// tip | "Tipp"

Die gleiche **TLS-Terminierungsproxy**-Komponente, die f√ºr HTTPS verwendet wird, w√§re wahrscheinlich auch ein **Load Balancer**.

///

Und wenn Sie mit Containern arbeiten, verf√ºgt das gleiche System, mit dem Sie diese starten und verwalten, bereits √ºber interne Tools, um die **Netzwerkkommunikation** (z. B. HTTP-Requests) von diesem **Load Balancer** (das k√∂nnte auch ein **TLS-Terminierungsproxy** sein) zu den Containern mit Ihrer Anwendung weiterzuleiten.

### Ein Load Balancer ‚Äì mehrere Workercontainer

Bei der Arbeit mit **Kubernetes** oder √§hnlichen verteilten Containerverwaltungssystemen w√ºrde die Verwendung ihrer internen Netzwerkmechanismen es dem einzelnen **Load Balancer**, der den Haupt-**Port** √ºberwacht, erm√∂glichen, Kommunikation (Requests) an m√∂glicherweise **mehrere Container** weiterzuleiten, in denen Ihre Anwendung ausgef√ºhrt wird.

Jeder dieser Container, in denen Ihre Anwendung ausgef√ºhrt wird, verf√ºgt normalerweise √ºber **nur einen Prozess** (z. B. einen Uvicorn-Prozess, der Ihre FastAPI-Anwendung ausf√ºhrt). Es w√§ren alles **identische Container**, die das Gleiche ausf√ºhren, welche aber jeweils √ºber einen eigenen Prozess, Speicher, usw. verf√ºgen. Auf diese Weise w√ºrden Sie die **Parallelisierung** in **verschiedenen Kernen** der CPU nutzen. Oder sogar in **verschiedenen Maschinen**.

Und das verteilte Containersystem mit dem **Load Balancer** w√ºrde **die Requests abwechselnd** an jeden einzelnen Container mit Ihrer Anwendung verteilen. Jeder Request k√∂nnte also von einem der mehreren **replizierten Container** verarbeitet werden, in denen Ihre Anwendung ausgef√ºhrt wird.

Und normalerweise w√§re dieser **Load Balancer** in der Lage, Requests zu verarbeiten, die an *andere* Anwendungen in Ihrem Cluster gerichtet sind (z. B. eine andere Domain oder unter einem anderen URL-Pfad-Pr√§fix), und w√ºrde diese Kommunikation an die richtigen Container weiterleiten f√ºr *diese andere* Anwendung, die in Ihrem Cluster ausgef√ºhrt wird.

### Ein Prozess pro Container

In einem solchen Szenario m√∂chten Sie wahrscheinlich **einen einzelnen (Uvicorn-)Prozess pro Container** haben, da Sie die Replikation bereits auf Cluster ebene durchf√ºhren w√ºrden.

In diesem Fall m√∂chten Sie also **nicht** einen Prozessmanager wie Gunicorn mit Uvicorn-Workern oder Uvicorn mit seinen eigenen Uvicorn-Workern haben. Sie m√∂chten nur einen **einzelnen Uvicorn-Prozess** pro Container haben (wahrscheinlich aber mehrere Container).

Ein weiterer Prozessmanager im Container (wie es bei Gunicorn oder Uvicorn der Fall w√§re, welche Uvicorn-Worker verwalten) w√ºrde nur **unn√∂tige Komplexit√§t** hinzuf√ºgen, um welche Sie sich h√∂chstwahrscheinlich bereits mit Ihrem Clustersystem k√ºmmern.

### Container mit mehreren Prozessen und Sonderf√§lle

Nat√ºrlich gibt es **Sonderf√§lle**, in denen Sie **einen Container** mit einem **Gunicorn-Prozessmanager** haben m√∂chten, welcher mehrere **Uvicorn-Workerprozesse** darin startet.

In diesen F√§llen k√∂nnen Sie das **offizielle Docker-Image** verwenden, welches **Gunicorn** als Prozessmanager enth√§lt, welcher mehrere **Uvicorn-Workerprozesse** ausf√ºhrt, sowie einige Standardeinstellungen, um die Anzahl der Worker basierend auf den verf√ºgbaren CPU-Kernen automatisch anzupassen. Ich erz√§hle Ihnen weiter unten in [Offizielles Docker-Image mit Gunicorn ‚Äì Uvicorn](#offizielles-docker-image-mit-gunicorn-uvicorn) mehr dar√ºber.

Hier sind einige Beispiele, wann das sinnvoll sein k√∂nnte:

#### Eine einfache Anwendung

Sie k√∂nnten einen Prozessmanager im Container haben wollen, wenn Ihre Anwendung **einfach genug** ist, sodass Sie die Anzahl der Prozesse nicht (zumindest noch nicht) zu stark tunen m√ºssen und Sie einfach einen automatisierten Standard verwenden k√∂nnen (mit dem offiziellen Docker-Image), und Sie f√ºhren es auf einem **einzelnen Server** aus, nicht auf einem Cluster.

#### Docker Compose

Sie k√∂nnten das Deployment auf einem **einzelnen Server** (kein Cluster) mit **Docker Compose** durchf√ºhren, sodass Sie keine einfache M√∂glichkeit h√§tten, die Replikation von Containern (mit Docker Compose) zu verwalten und gleichzeitig das gemeinsame Netzwerk mit **Load Balancing** zu haben.

Dann m√∂chten Sie vielleicht **einen einzelnen Container** mit einem **Prozessmanager** haben, der darin **mehrere Workerprozesse** startet.

#### Prometheus und andere Gr√ºnde

Sie k√∂nnten auch **andere Gr√ºnde** haben, die es einfacher machen w√ºrden, einen **einzelnen Container** mit **mehreren Prozessen** zu haben, anstatt **mehrere Container** mit **einem einzelnen Prozess** in jedem von ihnen.

Beispielsweise k√∂nnten Sie (abh√§ngig von Ihrem Setup) ein Tool wie einen Prometheus-Exporter im selben Container haben, welcher Zugriff auf **jeden der eingehenden Requests** haben sollte.

Wenn Sie in hier **mehrere Container** h√§tten, w√ºrde Prometheus beim **Lesen der Metriken** standardm√§√üig jedes Mal diejenigen f√ºr **einen einzelnen Container** abrufen (f√ºr den Container, der den spezifischen Request verarbeitet hat), anstatt die **akkumulierten Metriken** f√ºr alle replizierten Container abzurufen.

In diesem Fall k√∂nnte einfacher sein, **einen Container** mit **mehreren Prozessen** und ein lokales Tool (z. B. einen Prometheus-Exporter) in demselben Container zu haben, welches Prometheus-Metriken f√ºr alle internen Prozesse sammelt und diese Metriken f√ºr diesen einzelnen Container offenlegt.

---

Der Hauptpunkt ist, dass **keine** dieser Regeln **in Stein gemei√üelt** ist, der man blind folgen muss. Sie k√∂nnen diese Ideen verwenden, um **Ihren eigenen Anwendungsfall zu evaluieren**, zu entscheiden, welcher Ansatz f√ºr Ihr System am besten geeignet ist und herauszufinden, wie Sie folgende Konzepte verwalten:

* Sicherheit ‚Äì HTTPS
* Beim Hochfahren ausf√ºhren
* Neustarts
* Replikation (die Anzahl der laufenden Prozesse)
* Arbeitsspeicher
* Schritte vor dem Start

## Arbeitsspeicher

Wenn Sie **einen einzelnen Prozess pro Container** ausf√ºhren, wird von jedem dieser Container (mehr als einer, wenn sie repliziert werden) eine mehr oder weniger klar definierte, stabile und begrenzte Menge an Arbeitsspeicher verbraucht.

Und dann k√∂nnen Sie dieselben Speichergrenzen und -anforderungen in Ihren Konfigurationen f√ºr Ihr Container-Management-System festlegen (z. B. in **Kubernetes**). Auf diese Weise ist es in der Lage, die Container auf den **verf√ºgbaren Maschinen** zu replizieren, wobei die von denen ben√∂tigte Speichermenge und die auf den Maschinen im Cluster verf√ºgbare Menge ber√ºcksichtigt werden.

Wenn Ihre Anwendung **einfach** ist, wird dies wahrscheinlich **kein Problem darstellen** und Sie m√ºssen m√∂glicherweise keine festen Speichergrenzen angeben. Wenn Sie jedoch **viel Speicher verbrauchen** (z. B. bei **Modellen f√ºr maschinelles Lernen**), sollten Sie √ºberpr√ºfen, wie viel Speicher Sie verbrauchen, und die **Anzahl der Container** anpassen, die in **jeder Maschine** ausgef√ºhrt werden. (und m√∂glicherweise weitere Maschinen zu Ihrem Cluster hinzuf√ºgen).

Wenn Sie **mehrere Prozesse pro Container** ausf√ºhren (zum Beispiel mit dem offiziellen Docker-Image), m√ºssen Sie sicherstellen, dass die Anzahl der gestarteten Prozesse nicht **mehr Speicher verbraucht** als verf√ºgbar ist.

## Schritte vor dem Start und Container

Wenn Sie Container (z. B. Docker, Kubernetes) verwenden, k√∂nnen Sie haupts√§chlich zwei Ans√§tze verwenden.

### Mehrere Container

Wenn Sie **mehrere Container** haben, von denen wahrscheinlich jeder einen **einzelnen Prozess** ausf√ºhrt (z. B. in einem **Kubernetes**-Cluster), dann m√∂chten Sie wahrscheinlich einen **separaten Container** haben, welcher die Arbeit der **Vorab-Schritte** in einem einzelnen Container, mit einem einzelnenen Prozess ausf√ºhrt, **bevor** die replizierten Workercontainer ausgef√ºhrt werden.

/// info

Wenn Sie Kubernetes verwenden, w√§re dies wahrscheinlich ein <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" class="external-link" target="_blank">Init-Container</a>.

///

Wenn es in Ihrem Anwendungsfall kein Problem darstellt, diese vorherigen Schritte **mehrmals parallel** auszuf√ºhren (z. B. wenn Sie keine Datenbankmigrationen ausf√ºhren, sondern nur pr√ºfen, ob die Datenbank bereits bereit ist), k√∂nnen Sie sie auch einfach in jedem Container direkt vor dem Start des Hauptprozesses einf√ºgen.

### Einzelner Container

Wenn Sie ein einfaches Setup mit einem **einzelnen Container** haben, welcher dann mehrere **Workerprozesse** (oder auch nur einen Prozess) startet, k√∂nnen Sie die Vorab-Schritte im selben Container direkt vor dem Starten des Prozesses mit der Anwendung ausf√ºhren. Das offizielle Docker-Image unterst√ºtzt das intern.

## Offizielles Docker-Image mit Gunicorn ‚Äì Uvicorn

Es gibt ein offizielles Docker-Image, in dem Gunicorn mit Uvicorn-Workern ausgef√ºhrt wird, wie in einem vorherigen Kapitel beschrieben: [Serverworker ‚Äì Gunicorn mit Uvicorn](server-workers.md){.internal-link target=_blank}.

Dieses Image w√§re vor allem in den oben beschriebenen Situationen n√ºtzlich: [Container mit mehreren Prozessen und Sonderf√§lle](#container-mit-mehreren-prozessen-und-sonderfalle).

* <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>.

/// warning | "Achtung"

Es besteht eine hohe Wahrscheinlichkeit, dass Sie dieses oder ein √§hnliches Basisimage **nicht** ben√∂tigen und es besser w√§re, wenn Sie das Image von Grund auf neu erstellen w√ºrden, wie [oben beschrieben in: Ein Docker-Image f√ºr FastAPI erstellen](#ein-docker-image-fur-fastapi-erstellen).

///

Dieses Image verf√ºgt √ºber einen **Auto-Tuning**-Mechanismus, um die **Anzahl der Arbeitsprozesse** basierend auf den verf√ºgbaren CPU-Kernen festzulegen.

Es verf√ºgt √ºber **vern√ºnftige Standardeinstellungen**, aber Sie k√∂nnen trotzdem alle Konfigurationen mit **Umgebungsvariablen** oder Konfigurationsdateien √§ndern und aktualisieren.

Es unterst√ºtzt auch die Ausf√ºhrung von <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker#pre_start_path" class="external-link" target="_blank">**Vorab-Schritten vor dem Start** </a> mit einem Skript.

/// tip | "Tipp"

Um alle Konfigurationen und Optionen anzuzeigen, gehen Sie zur Docker-Image-Seite: <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>.

///

### Anzahl der Prozesse auf dem offiziellen Docker-Image

Die **Anzahl der Prozesse** auf diesem Image wird **automatisch** anhand der verf√ºgbaren CPU-**Kerne** berechnet.

Das bedeutet, dass versucht wird, so viel **Leistung** wie m√∂glich aus der CPU herauszuquetschen.

Sie k√∂nnen das auch in der Konfiguration anpassen, indem Sie **Umgebungsvariablen**, usw. verwenden.

Das bedeutet aber auch, da die Anzahl der Prozesse von der CPU abh√§ngt, welche der Container ausf√ºhrt, dass die **Menge des verbrauchten Speichers** ebenfalls davon abh√§ngt.

Wenn Ihre Anwendung also viel Speicher verbraucht (z. B. bei Modellen f√ºr maschinelles Lernen) und Ihr Server √ºber viele CPU-Kerne, **aber wenig Speicher** verf√ºgt, k√∂nnte Ihr Container am Ende versuchen, mehr Speicher als vorhanden zu verwenden, was zu erheblichen Leistungseinbu√üen (oder sogar zum Absturz) f√ºhren kann. üö®

### Ein `Dockerfile` erstellen

So w√ºrden Sie ein `Dockerfile` basierend auf diesem Image erstellen:

```Dockerfile
FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9

COPY ./requirements.txt /app/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /app/requirements.txt

COPY ./app /app
```

### Gr√∂√üere Anwendungen

Wenn Sie dem Abschnitt zum Erstellen von [gr√∂√üeren Anwendungen mit mehreren Dateien](../tutorial/bigger-applications.md){.internal-link target=_blank} gefolgt sind, k√∂nnte Ihr `Dockerfile` stattdessen wie folgt aussehen:

```Dockerfile hl_lines="7"
FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9

COPY ./requirements.txt /app/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /app/requirements.txt

COPY ./app /app/app
```

### Wann verwenden

Sie sollten dieses offizielle Basisimage (oder ein √§hnliches) wahrscheinlich **nicht** benutzen, wenn Sie **Kubernetes** (oder andere) verwenden und Sie bereits **Replikation** auf Cluster ebene mit mehreren **Containern** eingerichtet haben. In diesen F√§llen ist es besser, **ein Image von Grund auf zu erstellen**, wie oben beschrieben: [Ein Docker-Image f√ºr FastAPI erstellen](#ein-docker-image-fur-fastapi-erstellen).

Dieses Image w√§re vor allem in den oben in [Container mit mehreren Prozessen und Sonderf√§lle](#container-mit-mehreren-prozessen-und-sonderfalle) beschriebenen Sonderf√§llen n√ºtzlich. Wenn Ihre Anwendung beispielsweise **einfach genug** ist, dass das Festlegen einer Standardanzahl von Prozessen basierend auf der CPU gut funktioniert, m√∂chten Sie sich nicht mit der manuellen Konfiguration der Replikation auf Cluster ebene herumschlagen und f√ºhren nicht mehr als einen Container mit Ihrer Anwendung aus. Oder wenn Sie das Deployment mit **Docker Compose** durchf√ºhren und auf einem einzelnen Server laufen, usw.

## Deployment des Containerimages

Nachdem Sie ein Containerimage (Docker) haben, gibt es mehrere M√∂glichkeiten, es bereitzustellen.

Zum Beispiel:

* Mit **Docker Compose** auf einem einzelnen Server
* Mit einem **Kubernetes**-Cluster
* Mit einem Docker Swarm Mode-Cluster
* Mit einem anderen Tool wie Nomad
* Mit einem Cloud-Dienst, der Ihr Containerimage nimmt und es bereitstellt

## Docker-Image mit Poetry

Wenn Sie <a href="https://python-poetry.org/" class="external-link" target="_blank">Poetry</a> verwenden, um die Abh√§ngigkeiten Ihres Projekts zu verwalten, k√∂nnen Sie Dockers mehrphasige Builds verwenden:

```{ .dockerfile .annotate }
# (1)
FROM python:3.9 as requirements-stage

# (2)
WORKDIR /tmp

# (3)
RUN pip install poetry

# (4)
COPY ./pyproject.toml ./poetry.lock* /tmp/

# (5)
RUN poetry export -f requirements.txt --output requirements.txt --without-hashes

# (6)
FROM python:3.9

# (7)
WORKDIR /code

# (8)
COPY --from=requirements-stage /tmp/requirements.txt /code/requirements.txt

# (9)
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (10)
COPY ./app /code/app

# (11)
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80"]
```

1. Dies ist die erste Phase, genannt `requirements-stage` ‚Äì ‚ÄûAnforderungsphase‚Äú.

2. Setze `/tmp` als aktuelles Arbeitsverzeichnis.

    Hier werden wir die Datei `requirements.txt` generieren.

3. Installiere Poetry in dieser Docker-Phase.

4. Kopiere die Dateien `pyproject.toml` und `poetry.lock` in das Verzeichnis `/tmp`.

    Da es `./poetry.lock*` verwendet (endet mit einem `*`), st√ºrzt es nicht ab, wenn diese Datei noch nicht verf√ºgbar ist.

5. Generiere die Datei `requirements.txt`.

6. Dies ist die letzte Phase. Alles hier bleibt im endg√ºltigen Containerimage erhalten.

7. Setze das aktuelle Arbeitsverzeichnis auf `/code`.

8. Kopiere die Datei `requirements.txt` in das Verzeichnis `/code`.

    Diese Datei existiert nur in der vorherigen Docker-Phase, deshalb verwenden wir `--from-requirements-stage`, um sie zu kopieren.

9. Installiere die Paketabh√§ngigkeiten von der generierten Datei `requirements.txt`.

10. Kopiere das Verzeichnis `app` in das Verzeichnis `/code`.

11. F√ºhre den Befehl `uvicorn` aus und weise ihn an, das aus `app.main` importierte `app`-Objekt zu verwenden.

/// tip | "Tipp"

Klicken Sie auf die Zahlenblasen, um zu sehen, was jede Zeile bewirkt.

///

Eine **Docker-Phase** ist ein Teil eines `Dockerfile`s, welcher als **tempor√§res Containerimage** fungiert und nur zum Generieren einiger Dateien f√ºr die sp√§tere Verwendung verwendet wird.

Die erste Phase wird nur zur **Installation von Poetry** und zur **Generierung der `requirements.txt`** mit deren Projektabh√§ngigkeiten aus der Datei `pyproject.toml` von Poetry verwendet.

Diese `requirements.txt`-Datei wird sp√§ter in der **n√§chsten Phase** mit `pip` verwendet.

Im endg√ºltigen Containerimage bleibt **nur die letzte Stufe** erhalten. Die vorherigen Stufen werden verworfen.

Bei der Verwendung von Poetry w√§re es sinnvoll, **mehrstufige Docker-Builds** zu verwenden, da Poetry und seine Abh√§ngigkeiten nicht wirklich im endg√ºltigen Containerimage installiert sein m√ºssen, sondern Sie brauchen **nur** die Datei `requirements.txt`, um Ihre Projektabh√§ngigkeiten zu installieren.

Dann w√ºrden Sie im n√§chsten (und letzten) Schritt das Image mehr oder weniger auf die gleiche Weise wie zuvor beschrieben erstellen.

### Hinter einem TLS-Terminierungsproxy ‚Äì Poetry

Auch hier gilt: Wenn Sie Ihren Container hinter einem TLS-Terminierungsproxy (Load Balancer) wie Nginx oder Traefik ausf√ºhren, f√ºgen Sie dem Befehl die Option `--proxy-headers` hinzu:

```Dockerfile
CMD ["uvicorn", "app.main:app", "--proxy-headers", "--host", "0.0.0.0", "--port", "80"]
```

## Zusammenfassung

Mithilfe von Containersystemen (z. B. mit **Docker** und **Kubernetes**) ist es ziemlich einfach, alle **Deployment-Konzepte** zu handhaben:

* HTTPS
* Beim Hochfahren ausf√ºhren
* Neustarts
* Replikation (die Anzahl der laufenden Prozesse)
* Arbeitsspeicher
* Schritte vor dem Start

In den meisten F√§llen m√∂chten Sie wahrscheinlich kein Basisimage verwenden und stattdessen **ein Containerimage von Grund auf erstellen**, eines basierend auf dem offiziellen Python-Docker-Image.

Indem Sie auf die **Reihenfolge** der Anweisungen im `Dockerfile` und den **Docker-Cache** achten, k√∂nnen Sie **die Build-Zeiten minimieren**, um Ihre Produktivit√§t zu erh√∂hen (und Langeweile zu vermeiden). üòé

In bestimmten Sonderf√§llen m√∂chten Sie m√∂glicherweise das offizielle Docker-Image f√ºr FastAPI verwenden. ü§ì
