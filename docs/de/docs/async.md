# NebenlÃ¤ufigkeit und async / await { #concurrency-and-async-await }

Details zur `async def`-Syntax fÃ¼r *Pfadoperation-Funktionen* und Hintergrundinformationen zu asynchronem Code, NebenlÃ¤ufigkeit und ParallelitÃ¤t.

## In Eile? { #in-a-hurry }

<abbr title="too long; didn't read â€“ Zu lang; nicht gelesen"><strong>TL;DR:</strong></abbr>

Wenn Sie Bibliotheken von Dritten verwenden, die mit `await` aufgerufen werden mÃ¼ssen, wie zum Beispiel:

```Python
results = await some_library()
```

Dann deklarieren Sie Ihre *Pfadoperation-Funktionen* mit `async def`, wie in:

```Python hl_lines="2"
@app.get('/')
async def read_results():
    results = await some_library()
    return results
```

/// note | Hinweis

Sie kÃ¶nnen `await` nur innerhalb von Funktionen verwenden, die mit `async def` erstellt wurden.

///

---

Wenn Sie eine Bibliothek eines Dritten verwenden, die mit etwas kommuniziert (einer Datenbank, einer API, dem Dateisystem, usw.) und welche die Verwendung von `await` nicht unterstÃ¼tzt (dies ist derzeit bei den meisten Datenbankbibliotheken der Fall), dann deklarieren Sie Ihre *Pfadoperation-Funktionen* ganz normal nur mit `def`, wie in:

```Python hl_lines="2"
@app.get('/')
def results():
    results = some_library()
    return results
```

---

Wenn Ihre Anwendung (irgendwie) nicht mit etwas anderem kommunizieren und auf dessen Antwort warten muss, verwenden Sie `async def`, auch wenn Sie `await` im Inneren nicht verwenden mÃ¼ssen.

---

Wenn Sie sich unsicher sind, verwenden Sie einfach `def`.

---

**Hinweis**: Sie kÃ¶nnen `def` und `async def` in Ihren *Pfadoperation-Funktionen* beliebig mischen, so wie Sie es benÃ¶tigen, und jede einzelne Funktion in der fÃ¼r Sie besten Variante erstellen. FastAPI wird damit das Richtige tun.

Wie dem auch sei, in jedem der oben genannten FÃ¤lle wird FastAPI immer noch asynchron arbeiten und extrem schnell sein.

Wenn Sie jedoch den oben genannten Schritten folgen, kÃ¶nnen einige Performanz-Optimierungen vorgenommen werden.

## Technische Details { #technical-details }

Moderne Versionen von Python unterstÃ¼tzen **â€asynchronen Codeâ€œ** unter Verwendung sogenannter **â€Coroutinenâ€œ** mithilfe der Syntax **`async` und `await`**.

Nehmen wir obigen Satz in den folgenden Abschnitten Schritt fÃ¼r Schritt unter die Lupe:

* **Asynchroner Code**
* **`async` und `await`**
* **Coroutinen**

## Asynchroner Code { #asynchronous-code }

Asynchroner Code bedeutet lediglich, dass die Sprache ğŸ’¬ eine MÃ¶glichkeit hat, dem Computer / Programm ğŸ¤– mitzuteilen, dass es ğŸ¤– an einem bestimmten Punkt im Code darauf warten muss, dass *etwas anderes* irgendwo anders fertig wird. Nehmen wir an, *etwas anderes* ist hier â€Langsam-Dateiâ€œ ğŸ“.

WÃ¤hrend der Zeit, die â€Langsam-Dateiâ€œ ğŸ“ benÃ¶tigt, kann das System also andere Aufgaben erledigen.

Dann kommt der Computer / das Programm ğŸ¤– bei jeder Gelegenheit zurÃ¼ck, weil es entweder wieder wartet oder wann immer es ğŸ¤– die ganze Arbeit erledigt hat, die zu diesem Zeitpunkt zu tun war. Und es ğŸ¤– wird nachschauen, ob eine der Aufgaben, auf die es gewartet hat, fertig ist.

Dann nimmt es ğŸ¤– die erste erledigte Aufgabe (sagen wir, unsere â€Langsam-Dateiâ€œ ğŸ“) und bearbeitet sie weiter.

Das â€Warten auf etwas anderesâ€œ bezieht sich normalerweise auf <abbr title="Input and Output â€“ Eingabe und Ausgabe">I/O</abbr>-Operationen, die relativ â€langsamâ€œ sind (im Vergleich zur Geschwindigkeit des Prozessors und des Arbeitsspeichers), wie etwa das Warten darauf, dass:

* die Daten des Clients Ã¼ber das Netzwerk empfangen wurden
* die von Ihrem Programm gesendeten Daten vom Client Ã¼ber das Netzwerk empfangen wurden
* der Inhalt einer Datei vom System von der Festplatte gelesen und an Ihr Programm Ã¼bergeben wurde
* der Inhalt, den Ihr Programm dem System Ã¼bergeben hat, auf die Festplatte geschrieben wurde
* eine Remote-API-Operation beendet wurde
* Eine Datenbankoperation abgeschlossen wurde
* eine Datenbankabfrage die Ergebnisse zurÃ¼ckgegeben hat
* usw.

Da die AusfÃ¼hrungszeit hier hauptsÃ¤chlich durch das Warten auf <abbr title="Input and Output â€“ Eingabe und Ausgabe">I/O</abbr>-Operationen verbraucht wird, nennt man dies auch â€I/O-lastigeâ€œ (â€I/O boundâ€œ) Operationen.

â€Asynchronâ€œ, sagt man, weil der Computer / das Programm nicht mit einer langsamen Aufgabe â€synchronisiertâ€œ werden muss und nicht auf den genauen Moment warten muss, in dem die Aufgabe beendet ist, ohne dabei etwas zu tun, um schlieÃŸlich das Ergebnis der Aufgabe zu Ã¼bernehmen und die Arbeit fortsetzen zu kÃ¶nnen.

Da es sich stattdessen um ein â€asynchronesâ€œ System handelt, kann die Aufgabe nach Abschluss ein wenig (einige Mikrosekunden) in der Schlange warten, bis der Computer / das Programm seine anderen Dinge erledigt hat und zurÃ¼ckkommt, um die Ergebnisse entgegenzunehmen und mit ihnen weiterzuarbeiten.

FÃ¼r â€synchronâ€œ (im Gegensatz zu â€asynchronâ€œ) wird auch oft der Begriff â€sequentiellâ€œ verwendet, da der Computer / das Programm alle Schritte in einer Sequenz (â€der Reihe nachâ€œ) ausfÃ¼hrt, bevor es zu einer anderen Aufgabe wechselt, auch wenn diese Schritte mit Warten verbunden sind.

### NebenlÃ¤ufigkeit und Hamburger { #concurrency-and-burgers }

Diese oben beschriebene Idee von **asynchronem** Code wird manchmal auch **â€NebenlÃ¤ufigkeitâ€œ** genannt. Sie unterscheidet sich von **â€ParallelitÃ¤tâ€œ**.

**NebenlÃ¤ufigkeit** und **ParallelitÃ¤t** beziehen sich beide auf â€verschiedene Dinge, die mehr oder weniger gleichzeitig passierenâ€œ.

Aber die Details zwischen *NebenlÃ¤ufigkeit* und *ParallelitÃ¤t* sind ziemlich unterschiedlich.

Um den Unterschied zu erkennen, stellen Sie sich die folgende Geschichte Ã¼ber Hamburger vor:

### NebenlÃ¤ufige Hamburger { #concurrent-burgers }

Sie gehen mit Ihrem Schwarm Fastfood holen, stehen in der Schlange, wÃ¤hrend der Kassierer die Bestellungen der Leute vor Ihnen entgegennimmt. ğŸ˜

<img src="/img/async/concurrent-burgers/concurrent-burgers-01.png" class="illustration">

Dann sind Sie an der Reihe und Sie bestellen zwei sehr schmackhafte Burger fÃ¼r Ihren Schwarm und Sie. ğŸ”ğŸ”

<img src="/img/async/concurrent-burgers/concurrent-burgers-02.png" class="illustration">

Der Kassierer sagt etwas zum Koch in der KÃ¼che, damit dieser weiÃŸ, dass er Ihre Burger zubereiten muss (obwohl er gerade die fÃ¼r die vorherigen Kunden zubereitet).

<img src="/img/async/concurrent-burgers/concurrent-burgers-03.png" class="illustration">

Sie bezahlen. ğŸ’¸

Der Kassierer gibt Ihnen die Nummer Ihrer Bestellung.

<img src="/img/async/concurrent-burgers/concurrent-burgers-04.png" class="illustration">

WÃ¤hrend Sie warten, suchen Sie sich mit Ihrem Schwarm einen Tisch aus, Sie sitzen da und reden lange mit Ihrem Schwarm (da Ihre Burger sehr aufwÃ¤ndig sind und die Zubereitung einige Zeit dauert).

WÃ¤hrend Sie mit Ihrem Schwarm am Tisch sitzen und auf die Burger warten, kÃ¶nnen Sie die Zeit damit verbringen, zu bewundern, wie groÃŸartig, sÃ¼ÃŸ und klug Ihr Schwarm ist âœ¨ğŸ˜âœ¨.

<img src="/img/async/concurrent-burgers/concurrent-burgers-05.png" class="illustration">

WÃ¤hrend Sie warten und mit Ihrem Schwarm sprechen, Ã¼berprÃ¼fen Sie von Zeit zu Zeit die auf dem ZÃ¤hler angezeigte Nummer, um zu sehen, ob Sie bereits an der Reihe sind.

Dann, irgendwann, sind Sie endlich an der Reihe. Sie gehen zur Theke, holen sich die Burger und kommen zurÃ¼ck an den Tisch.

<img src="/img/async/concurrent-burgers/concurrent-burgers-06.png" class="illustration">

Sie und Ihr Schwarm essen die Burger und haben eine schÃ¶ne Zeit. âœ¨

<img src="/img/async/concurrent-burgers/concurrent-burgers-07.png" class="illustration">

/// info | Info

Die wunderschÃ¶nen Illustrationen stammen von <a href="https://www.instagram.com/ketrinadrawsalot" class="external-link" target="_blank">Ketrina Thompson</a>. ğŸ¨

///

---

Stellen Sie sich vor, Sie wÃ¤ren der Computer / das Programm ğŸ¤– in dieser Geschichte.

WÃ¤hrend Sie an der Schlange stehen, sind Sie einfach untÃ¤tig ğŸ˜´, warten darauf, dass Sie an die Reihe kommen, und tun nichts sehr â€Produktivesâ€œ. Aber die Schlange ist schnell abgearbeitet, weil der Kassierer nur die Bestellungen entgegennimmt (und nicht zubereitet), also ist das vertretbar.

Wenn Sie dann an der Reihe sind, erledigen Sie tatsÃ¤chliche â€produktiveâ€œ Arbeit, Sie gehen das MenÃ¼ durch, entscheiden sich, was Sie mÃ¶chten, bekunden Ihre und die Wahl Ihres Schwarms, bezahlen, prÃ¼fen, ob Sie die richtige Menge Geld oder die richtige Karte geben, prÃ¼fen, ob die Rechnung korrekt ist, prÃ¼fen, dass die Bestellung die richtigen Artikel enthÃ¤lt, usw.

Aber dann, auch wenn Sie Ihre Burger noch nicht haben, ist Ihre Interaktion mit dem Kassierer erst mal â€auf Pauseâ€œ â¸, weil Sie warten mÃ¼ssen ğŸ•™, bis Ihre Burger fertig sind.

Aber wenn Sie sich von der Theke entfernt haben und mit der Nummer fÃ¼r die Bestellung an einem Tisch sitzen, kÃ¶nnen Sie Ihre Aufmerksamkeit auf Ihren Schwarm lenken und an dieser Aufgabe â€arbeitenâ€œ â¯ ğŸ¤“. Sie machen wieder etwas sehr â€Produktivesâ€œ und flirten mit Ihrem Schwarm ğŸ˜.

Dann sagt der Kassierer ğŸ’ â€Ich bin mit dem Burger fertigâ€œ, indem er Ihre Nummer auf dem Display Ã¼ber der Theke anzeigt, aber Sie springen nicht sofort wie verrÃ¼ckt auf, wenn das Display auf Ihre Nummer springt. Sie wissen, dass niemand Ihnen Ihre Burger wegnimmt, denn Sie haben die Nummer Ihrer Bestellung, und andere Leute haben andere Nummern.

Also warten Sie darauf, dass Ihr Schwarm ihre Geschichte zu Ende erzÃ¤hlt (die aktuelle Arbeit â¯ / bearbeitete Aufgabe beendet ğŸ¤“), lÃ¤cheln sanft und sagen, dass Sie die Burger holen â¸.

Dann gehen Sie zur Theke ğŸ”€, zur ursprÃ¼nglichen Aufgabe, die nun erledigt ist â¯, nehmen die Burger auf, sagen Danke, und bringen sie zum Tisch. Damit ist dieser Schritt / diese Aufgabe der Interaktion mit der Theke abgeschlossen â¹. Das wiederum schafft eine neue Aufgabe, â€Burger essenâ€œ ğŸ”€ â¯, aber die vorherige Aufgabe â€Burger holenâ€œ ist erledigt â¹.

### Parallele Hamburger { #parallel-burgers }

Stellen wir uns jetzt vor, dass es sich hierbei nicht um â€nebenlÃ¤ufige Hamburgerâ€œ, sondern um â€parallele Hamburgerâ€œ handelt.

Sie gehen los mit Ihrem Schwarm, um paralleles Fast Food zu bekommen.

Sie stehen in der Schlange, wÃ¤hrend mehrere (sagen wir acht) Kassierer, die gleichzeitig KÃ¶che sind, die Bestellungen der Leute vor Ihnen entgegennehmen.

Alle vor Ihnen warten darauf, dass ihre Burger fertig sind, bevor sie die Theke verlassen, denn jeder der 8 Kassierer geht los und bereitet den Burger sofort zu, bevor er die nÃ¤chste Bestellung entgegennimmt.

<img src="/img/async/parallel-burgers/parallel-burgers-01.png" class="illustration">

Dann sind Sie endlich an der Reihe und bestellen zwei sehr leckere Burger fÃ¼r Ihren Schwarm und Sie.

Sie zahlen ğŸ’¸.

<img src="/img/async/parallel-burgers/parallel-burgers-02.png" class="illustration">

Der Kassierer geht in die KÃ¼che.

Sie warten, vor der Theke stehend ğŸ•™, damit niemand auÃŸer Ihnen Ihre Burger entgegennimmt, da es keine Nummern fÃ¼r die Reihenfolge gibt.

<img src="/img/async/parallel-burgers/parallel-burgers-03.png" class="illustration">

Da Sie und Ihr Schwarm damit beschÃ¤ftigt sind, niemanden vor sich zu lassen, der Ihre Burger nimmt, wenn sie ankommen, kÃ¶nnen Sie Ihrem Schwarm keine Aufmerksamkeit schenken. ğŸ˜

Das ist â€synchroneâ€œ Arbeit, Sie sind mit dem Kassierer/Koch â€synchronisiertâ€œ ğŸ‘¨â€ğŸ³. Sie mÃ¼ssen warten ğŸ•™ und genau in dem Moment da sein, in dem der Kassierer/Koch ğŸ‘¨â€ğŸ³ die Burger zubereitet hat und Ihnen gibt, sonst kÃ¶nnte jemand anderes sie nehmen.

<img src="/img/async/parallel-burgers/parallel-burgers-04.png" class="illustration">

Dann kommt Ihr Kassierer/Koch ğŸ‘¨â€ğŸ³ endlich mit Ihren Burgern zurÃ¼ck, nachdem Sie lange vor der Theke gewartet ğŸ•™ haben.

<img src="/img/async/parallel-burgers/parallel-burgers-05.png" class="illustration">

Sie nehmen Ihre Burger und gehen mit Ihrem Schwarm an den Tisch.

Sie essen sie und sind fertig. â¹

<img src="/img/async/parallel-burgers/parallel-burgers-06.png" class="illustration">

Es wurde nicht viel geredet oder geflirtet, da die meiste Zeit mit Warten ğŸ•™ vor der Theke verbracht wurde. ğŸ˜

/// info | Info

Die wunderschÃ¶nen Illustrationen stammen von <a href="https://www.instagram.com/ketrinadrawsalot" class="external-link" target="_blank">Ketrina Thompson</a>. ğŸ¨

///

---

In diesem Szenario der parallelen Hamburger sind Sie ein Computersystem / Programm ğŸ¤– mit zwei Prozessoren (Sie und Ihr Schwarm), die beide warten ğŸ•™ und ihre Aufmerksamkeit darauf verwenden, â€lange Zeit vor der Theke zu wartenâ€œ ğŸ•™.

Der Fast-Food-Laden verfÃ¼gt Ã¼ber 8 Prozessoren (Kassierer/KÃ¶che). WÃ¤hrend der nebenlÃ¤ufige Burger-Laden nur zwei hatte (einen Kassierer und einen Koch).

Dennoch ist das schlussendliche Benutzererlebnis nicht das Beste. ğŸ˜

---

Dies wÃ¤re die parallele Ã¤quivalente Geschichte fÃ¼r Hamburger. ğŸ”

FÃ¼r ein â€realeresâ€œ Beispiel hierfÃ¼r, stellen Sie sich eine Bank vor.

Bis vor kurzem hatten die meisten Banken mehrere Kassierer ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ und eine groÃŸe Warteschlange ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™.

Alle Kassierer erledigen die ganze Arbeit mit einem Kunden nach dem anderen ğŸ‘¨â€ğŸ’¼â¯.

Und man muss lange in der Schlange warten ğŸ•™ sonst kommt man nicht an die Reihe.

Sie wÃ¼rden Ihren Schwarm ğŸ˜ wahrscheinlich nicht mitnehmen wollen, um Besorgungen bei der Bank zu erledigen ğŸ¦.

### Hamburger Schlussfolgerung { #burger-conclusion }

In diesem Szenario â€Fastfood-Burger mit Ihrem Schwarmâ€œ ist es viel sinnvoller, ein nebenlÃ¤ufiges System zu haben â¸ğŸ”€â¯, da viel gewartet wird ğŸ•™.

Das ist auch bei den meisten Webanwendungen der Fall.

Viele, viele Benutzer, aber Ihr Server wartet ğŸ•™ darauf, dass deren nicht so gute Internetverbindungen die <abbr title="Request â€“ Anfrage: Daten, die der Client zum Server sendet">Requests</abbr> Ã¼bermitteln.

Und dann wieder warten ğŸ•™, bis die <abbr title="Response â€“ Antwort: Daten, die der Server zum anfragenden Client zurÃ¼cksendet">Responses</abbr> zurÃ¼ckkommen.

Dieses â€Wartenâ€œ ğŸ•™ wird in Mikrosekunden gemessen, aber zusammenfassend lÃ¤sst sich sagen, dass am Ende eine Menge gewartet wird.

Deshalb ist es sehr sinnvoll, asynchronen â¸ğŸ”€â¯ Code fÃ¼r Web-APIs zu verwenden.

Diese Art der AsynchronitÃ¤t hat NodeJS populÃ¤r gemacht (auch wenn NodeJS nicht parallel ist) und darin liegt die StÃ¤rke von Go als Programmiersprache.

Und das ist das gleiche Leistungsniveau, das Sie mit **FastAPI** erhalten.

Und da Sie ParallelitÃ¤t und AsynchronitÃ¤t gleichzeitig haben kÃ¶nnen, erzielen Sie eine hÃ¶here Performanz als die meisten getesteten NodeJS-Frameworks und sind mit Go auf AugenhÃ¶he, einer kompilierten Sprache, die nÃ¤her an C liegt <a href="https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query&l=zijmkf-1" class="external-link" target="_blank">(alles dank Starlette)</a>.

### Ist NebenlÃ¤ufigkeit besser als ParallelitÃ¤t? { #is-concurrency-better-than-parallelism }

Nein! Das ist nicht die Moral der Geschichte.

NebenlÃ¤ufigkeit unterscheidet sich von ParallelitÃ¤t. Und sie ist besser bei **bestimmten** Szenarien, die viel Warten erfordern. Aus diesem Grund ist sie im Allgemeinen viel besser als ParallelitÃ¤t fÃ¼r die Entwicklung von Webanwendungen. Aber das stimmt nicht fÃ¼r alle Anwendungen.

Um die Dinge auszugleichen, stellen Sie sich die folgende Kurzgeschichte vor:

> Sie mÃ¼ssen ein groÃŸes, schmutziges Haus aufrÃ¤umen.

*Yup, das ist die ganze Geschichte*.

---

Es gibt kein Warten ğŸ•™, nur viel Arbeit an mehreren Stellen im Haus.

Sie kÃ¶nnten wie im Hamburger-Beispiel hin- und herspringen, zuerst das Wohnzimmer, dann die KÃ¼che, aber da Sie auf nichts warten ğŸ•™, sondern nur putzen und putzen, hÃ¤tte das Hin- und Herspringen keine Auswirkungen.

Es wÃ¼rde mit oder ohne Hin- und Herspringen (NebenlÃ¤ufigkeit) die gleiche Zeit in Anspruch nehmen, um fertig zu werden, und Sie hÃ¤tten die gleiche Menge an Arbeit erledigt.

Aber wenn Sie in diesem Fall die acht Ex-Kassierer/KÃ¶che/jetzt ReinigungskrÃ¤fte mitbringen wÃ¼rden und jeder von ihnen (plus Sie) wÃ¼rde einen Bereich des Hauses reinigen, kÃ¶nnten Sie die ganze Arbeit **parallel** erledigen, und wÃ¼rden mit dieser zusÃ¤tzlichen Hilfe viel schneller fertig werden.

In diesem Szenario wÃ¤re jede einzelne Reinigungskraft (einschlieÃŸlich Ihnen) ein Prozessor, der seinen Teil der Arbeit erledigt.

Und da die meiste AusfÃ¼hrungszeit durch tatsÃ¤chliche Arbeit (anstatt durch Warten) in Anspruch genommen wird und die Arbeit in einem Computer von einer <abbr title="Central Processing Unit â€“ Zentrale Recheneinheit">CPU</abbr> erledigt wird, werden diese Probleme als â€CPU-lastigâ€œ (â€CPU boundâ€œ) bezeichnet.

---

Typische Beispiele fÃ¼r CPU-lastige VorgÃ¤nge sind Dinge, die komplexe mathematische Berechnungen erfordern.

Zum Beispiel:

* **Audio-** oder **Bildbearbeitung**.
* **Computer Vision**: Ein Bild besteht aus Millionen von Pixeln, jedes Pixel hat 3 Werte / Farben, die Verarbeitung erfordert normalerweise, Berechnungen mit diesen Pixeln durchzufÃ¼hren, alles zur gleichen Zeit.
* **Maschinelles Lernen**: Normalerweise sind viele â€Matrixâ€œ- und â€Vektorâ€œ-Multiplikationen erforderlich. Stellen Sie sich eine riesige Tabelle mit Zahlen vor, in der Sie alle Zahlen gleichzeitig multiplizieren.
* **Deep Learning**: Dies ist ein Teilgebiet des maschinellen Lernens, daher gilt das Gleiche. Es ist nur so, dass es nicht eine einzige Tabelle mit Zahlen zum Multiplizieren gibt, sondern eine riesige Menge davon, und in vielen FÃ¤llen verwendet man einen speziellen Prozessor, um diese Modelle zu erstellen und / oder zu verwenden.

### NebenlÃ¤ufigkeit + ParallelitÃ¤t: Web + maschinelles Lernen { #concurrency-parallelism-web-machine-learning }

Mit **FastAPI** kÃ¶nnen Sie die Vorteile der NebenlÃ¤ufigkeit nutzen, die in der Webentwicklung weit verbreitet ist (derselbe Hauptvorteil von NodeJS).

Sie kÃ¶nnen aber auch die Vorteile von ParallelitÃ¤t und Multiprocessing (mehrere Prozesse werden parallel ausgefÃ¼hrt) fÃ¼r **CPU-lastige** Workloads wie in Systemen fÃ¼r maschinelles Lernen nutzen.

Dies und die einfache Tatsache, dass Python die Hauptsprache fÃ¼r **Data Science**, maschinelles Lernen und insbesondere Deep Learning ist, machen FastAPI zu einem sehr passenden Werkzeug fÃ¼r Web-APIs und Anwendungen fÃ¼r Data Science / maschinelles Lernen (neben vielen anderen).

Wie Sie diese ParallelitÃ¤t in der Produktion erreichen, erfahren Sie im Abschnitt Ã¼ber [Deployment](deployment/index.md){.internal-link target=_blank}.

## `async` und `await` { #async-and-await }

Moderne Versionen von Python verfÃ¼gen Ã¼ber eine sehr intuitive MÃ¶glichkeit, asynchronen Code zu schreiben. Dadurch sieht es wie normaler â€sequentiellerâ€œ Code aus und Ã¼bernimmt im richtigen Moment das â€Wartenâ€œ fÃ¼r Sie.

Wenn es einen Vorgang gibt, der erfordert, dass gewartet wird, bevor die Ergebnisse zurÃ¼ckgegeben werden, und der diese neue Python-FunktionalitÃ¤t unterstÃ¼tzt, kÃ¶nnen Sie ihn wie folgt schreiben:

```Python
burgers = await get_burgers(2)
```

Der SchlÃ¼ssel hier ist das `await`. Es teilt Python mit, dass es warten â¸ muss, bis `get_burgers(2)` seine Aufgabe erledigt hat ğŸ•™, bevor die Ergebnisse in `burgers` gespeichert werden. Damit weiÃŸ Python, dass es in der Zwischenzeit etwas anderes tun kann ğŸ”€ â¯ (z. B. einen weiteren Request empfangen).

Damit `await` funktioniert, muss es sich in einer Funktion befinden, die diese AsynchronitÃ¤t unterstÃ¼tzt. Dazu deklarieren Sie sie einfach mit `async def`:

```Python hl_lines="1"
async def get_burgers(number: int):
    # Mache hier etwas Asynchrones, um die Burger zu erstellen
    return burgers
```

... statt mit `def`:

```Python hl_lines="2"
# Dies ist nicht asynchron
def get_sequential_burgers(number: int):
    # Mache hier etwas Sequentielles, um die Burger zu erstellen
    return burgers
```

Mit `async def` weiÃŸ Python, dass es innerhalb dieser Funktion auf `await`-AusdrÃ¼cke achten muss und dass es die AusfÃ¼hrung dieser Funktion â€anhaltenâ€œ â¸ und etwas anderes tun kann ğŸ”€, bevor es zurÃ¼ckkommt.

Wenn Sie eine `async def`-Funktion aufrufen mÃ¶chten, mÃ¼ssen Sie sie â€erwartenâ€œ (â€awaitâ€œ). Das folgende wird also nicht funktionieren:

```Python
# Das funktioniert nicht, weil get_burgers definiert wurde mit: async def
burgers = get_burgers(2)
```

---

Wenn Sie also eine Bibliothek verwenden, die Ihnen sagt, dass Sie sie mit `await` aufrufen kÃ¶nnen, mÃ¼ssen Sie die *Pfadoperation-Funktionen*, die diese Bibliothek verwenden, mittels `async def` erstellen, wie in:

```Python hl_lines="2-3"
@app.get('/burgers')
async def read_burgers():
    burgers = await get_burgers(2)
    return burgers
```

### Weitere technische Details { #more-technical-details }

Ihnen ist wahrscheinlich aufgefallen, dass `await` nur innerhalb von Funktionen verwendet werden kann, die mit `async def` definiert sind.

Gleichzeitig mÃ¼ssen aber mit `async def` definierte Funktionen â€erwartetâ€œ (â€awaitedâ€œ) werden. Daher kÃ¶nnen Funktionen mit `async def` nur innerhalb von Funktionen aufgerufen werden, die auch mit `async def` definiert sind.

Daraus resultiert das Ei-und-Huhn-Problem: Wie ruft man die erste `async` Funktion auf?

Wenn Sie mit **FastAPI** arbeiten, mÃ¼ssen Sie sich darÃ¼ber keine Sorgen machen, da diese â€ersteâ€œ Funktion Ihre *Pfadoperation-Funktion* sein wird und FastAPI weiÃŸ, was zu tun ist.

Wenn Sie jedoch `async` / `await` ohne FastAPI verwenden mÃ¶chten, kÃ¶nnen Sie dies auch tun.

### Schreiben Sie Ihren eigenen asynchronen Code { #write-your-own-async-code }

Starlette (und **FastAPI**) basieren auf <a href="https://anyio.readthedocs.io/en/stable/" class="external-link" target="_blank">AnyIO</a>, was bedeutet, dass es sowohl kompatibel mit der Python-Standardbibliothek <a href="https://docs.python.org/3/library/asyncio-task.html" class="external-link" target="_blank">asyncio</a> als auch mit <a href="https://trio.readthedocs.io/en/stable/" class="external-link" target="_blank">Trio</a> ist.

Insbesondere kÃ¶nnen Sie <a href="https://anyio.readthedocs.io/en/stable/" class="external-link" target="_blank">AnyIO</a> direkt verwenden fÃ¼r Ihre fortgeschrittenen nebenlÃ¤ufigen AnwendungsfÃ¤lle, die fortgeschrittenere Muster in Ihrem eigenen Code erfordern.

Und auch wenn Sie FastAPI nicht verwenden wÃ¼rden, kÃ¶nnten Sie Ihre eigenen asynchronen Anwendungen mit <a href="https://anyio.readthedocs.io/en/stable/" class="external-link" target="_blank">AnyIO</a> schreiben, um hochkompatibel zu sein und dessen Vorteile zu nutzen (z. B. *strukturierte NebenlÃ¤ufigkeit*).

Ich habe eine weitere Bibliothek auf Basis von AnyIO erstellt, als dÃ¼nne Schicht obendrauf, um die Typannotationen etwas zu verbessern und bessere **AutovervollstÃ¤ndigung**, **Inline-Fehler** usw. zu erhalten. Sie hat auch eine freundliche EinfÃ¼hrung und ein Tutorial, um Ihnen zu helfen, **Ihren eigenen asynchronen Code zu verstehen** und zu schreiben: <a href="https://asyncer.tiangolo.com/" class="external-link" target="_blank">Asyncer</a>. Sie ist insbesondere nÃ¼tzlich, wenn Sie **asynchronen Code mit regulÃ¤rem** (blockierendem/synchronem) Code kombinieren mÃ¼ssen.

### Andere Formen von asynchronem Code { #other-forms-of-asynchronous-code }

Diese Art der Verwendung von `async` und `await` ist in der Sprache relativ neu.

Aber sie erleichtert die Arbeit mit asynchronem Code erheblich.

Die gleiche Syntax (oder fast identisch) wurde kÃ¼rzlich auch in moderne Versionen von JavaScript (im Browser und in NodeJS) aufgenommen.

Davor war der Umgang mit asynchronem Code jedoch deutlich komplexer und schwieriger.

In frÃ¼heren Versionen von Python hÃ¤tten Sie Threads oder <a href="https://www.gevent.org/" class="external-link" target="_blank">Gevent</a> verwenden kÃ¶nnen. Der Code ist jedoch viel komplexer zu verstehen, zu debuggen und nachzuvollziehen.

In frÃ¼heren Versionen von NodeJS / Browser JavaScript hÃ¤tten Sie â€Callbacksâ€œ verwendet. Was zur â€Callback-HÃ¶lleâ€œ fÃ¼hrt.

## Coroutinen { #coroutines }

**Coroutine** ist nur ein schicker Begriff fÃ¼r dasjenige, was von einer `async def`-Funktion zurÃ¼ckgegeben wird. Python weiÃŸ, dass es so etwas wie eine Funktion ist, die es starten kann und die irgendwann endet, aber auch dass sie pausiert â¸ werden kann, wann immer darin ein `await` steht.

Aber all diese FunktionalitÃ¤t der Verwendung von asynchronem Code mit `async` und `await` wird oft als Verwendung von â€Coroutinenâ€œ zusammengefasst. Es ist vergleichbar mit dem Hauptmerkmal von Go, den â€Goroutinenâ€œ.

## Fazit { #conclusion }

Sehen wir uns den gleichen Satz von oben noch mal an:

> Moderne Versionen von Python unterstÃ¼tzen **â€asynchronen Codeâ€œ** unter Verwendung sogenannter **â€Coroutinenâ€œ** mithilfe der Syntax **`async` und `await`**.

Das sollte jetzt mehr Sinn ergeben. âœ¨

All das ist es, was FastAPI (via Starlette) befeuert und es eine so beeindruckende Performanz haben lÃ¤sst.

## Sehr technische Details { #very-technical-details }

/// warning | Achtung

Das folgende kÃ¶nnen Sie wahrscheinlich Ã¼berspringen.

Dies sind sehr technische Details darÃ¼ber, wie **FastAPI** unter der Haube funktioniert.

Wenn Sie Ã¼ber gute technische Kenntnisse verfÃ¼gen (Coroutinen, Threads, Blocking, usw.) und neugierig sind, wie FastAPI mit `async def`s im Vergleich zu normalen `def`s umgeht, fahren Sie fort.

///

### Pfadoperation-Funktionen { #path-operation-functions }

Wenn Sie eine *Pfadoperation-Funktion* mit normalem `def` anstelle von `async def` deklarieren, wird sie in einem externen Threadpool ausgefÃ¼hrt, der dann `await`et wird, anstatt direkt aufgerufen zu werden (da dies den Server blockieren wÃ¼rde).

Wenn Sie von einem anderen asynchronen Framework kommen, das nicht auf die oben beschriebene Weise funktioniert, und Sie es gewohnt sind, triviale, nur-berechnende *Pfadoperation-Funktionen* mit einfachem `def` zu definieren, um einen geringfÃ¼gigen Geschwindigkeitsgewinn (etwa 100 Nanosekunden) zu erzielen, beachten Sie bitte, dass der Effekt in **FastAPI** genau gegenteilig wÃ¤re. In solchen FÃ¤llen ist es besser, `async def` zu verwenden, es sei denn, Ihre *Pfadoperation-Funktionen* verwenden Code, der blockierende <abbr title="Input/Output â€“ Eingabe/Ausgabe: Lesen oder Schreiben von/auf Festplatte, Netzwerkkommunikation.">I/O</abbr>-Operationen durchfÃ¼hrt.

Dennoch besteht in beiden FÃ¤llen eine gute Chance, dass **FastAPI** [immer noch schneller](index.md#performance){.internal-link target=_blank} als Ihr bisheriges Framework (oder zumindest damit vergleichbar) ist.

### AbhÃ¤ngigkeiten { #dependencies }

Das Gleiche gilt fÃ¼r [AbhÃ¤ngigkeiten](tutorial/dependencies/index.md){.internal-link target=_blank}. Wenn eine AbhÃ¤ngigkeit eine normale `def`-Funktion anstelle einer `async def` ist, wird sie im externen Threadpool ausgefÃ¼hrt.

### UnterabhÃ¤ngigkeiten { #sub-dependencies }

Sie kÃ¶nnen mehrere AbhÃ¤ngigkeiten und [UnterabhÃ¤ngigkeiten](tutorial/dependencies/sub-dependencies.md){.internal-link target=_blank} haben, die einander bedingen (als Parameter der Funktionsdefinitionen), einige davon kÃ¶nnten erstellt werden mit `async def` und einige mit normalem `def`. Es wÃ¼rde immer noch funktionieren, und diejenigen, die mit normalem `def` erstellt wurden, wÃ¼rden in einem externen Thread (vom Threadpool stammend) aufgerufen werden, anstatt `await`et zu werden.

### Andere Hilfsfunktionen { #other-utility-functions }

Jede andere Hilfsfunktion, die Sie direkt aufrufen, kann mit normalem `def` oder `async def` erstellt werden, und FastAPI beeinflusst nicht die Art und Weise, wie Sie sie aufrufen.

Dies steht im Gegensatz zu den Funktionen, die FastAPI fÃ¼r Sie aufruft: *Pfadoperation-Funktionen* und AbhÃ¤ngigkeiten.

Wenn Ihre Hilfsfunktion eine normale Funktion mit `def` ist, wird sie direkt aufgerufen (so wie Sie es in Ihrem Code schreiben), nicht in einem Threadpool. Wenn die Funktion mit `async def` erstellt wurde, sollten Sie sie `await`en, wenn Sie sie in Ihrem Code aufrufen.

---

Nochmal, es handelt sich hier um sehr technische Details, die Ihnen helfen, falls Sie danach gesucht haben.

Andernfalls liegen Sie richtig, wenn Sie sich an die Richtlinien aus dem obigen Abschnitt halten: <a href="#in-a-hurry">In Eile?</a>.
