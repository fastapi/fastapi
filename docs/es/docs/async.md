# Concurrencia y async / await

Detalles sobre la sintaxis `async def` para *path operation functions* y un poco de informaciÃ³n sobre cÃ³digo asÃ­ncrono, concurrencia y paralelismo.

## Â¿Tienes prisa?

<abbr title="too long; didn't read"><strong>TL;DR:</strong></abbr>

Si estÃ¡s utilizando libraries de terceros que te dicen que las llames con `await`, del tipo:

```Python
results = await some_library()
```

Entonces declara tus *path operation functions* con `async def` de la siguiente manera:

```Python hl_lines="2"
@app.get('/')
async def read_results():
    results = await some_library()
    return results
```

!!! note "Nota"
    Solo puedes usar `await` dentro de funciones creadas con `async def`.

---

Si estÃ¡s utilizando libraries de terceros que se comunican con algo (una base de datos, una API, el sistema de archivos, etc.) y no tienes soporte para `await` (este es el caso para la mayorÃ­a de las libraries de bases de datos), declara tus *path operation functions* de forma habitual, con solo `def`, de la siguiente manera:

```Python hl_lines="2"
@app.get('/')
def results():
    results = some_library()
    return results
```

---

Si tu aplicaciÃ³n (de alguna manera) no tiene que comunicarse con nada mÃ¡s y en consecuencia esperar a que responda, usa `async def`.

---

Si simplemente no lo sabes, usa `def` normal.

---

**Nota**: puedes mezclar `def` y `async def` en tus *path operation functions* tanto como lo necesites y definir cada una utilizando la mejor opciÃ³n para ti. FastAPI harÃ¡ lo correcto con ellos.

De todos modos, en cualquiera de los casos anteriores, FastAPI seguirÃ¡ funcionando de forma asÃ­ncrona y serÃ¡ extremadamente rÃ¡pido.

Pero siguiendo los pasos anteriores, FastAPI podrÃ¡ hacer algunas optimizaciones de rendimiento.

## Detalles TÃ©cnicos

Las versiones modernas de Python tienen soporte para **"cÃ³digo asÃ­ncrono"** usando algo llamado **"coroutines"**, usando la sintaxis **`async` y `await`**.

Veamos esa frase por partes en las secciones siguientes:

* **CÃ³digo AsÃ­ncrono**
* **`async` y `await`**
* **Coroutines**

## CÃ³digo AsÃ­ncrono

El cÃ³digo asÃ­ncrono sÃ³lo significa que el lenguaje ğŸ’¬ tiene una manera de decirle al sistema / programa ğŸ¤– que, en algÃºn momento del cÃ³digo, ğŸ¤– tendrÃ¡ que esperar a que *algo mÃ¡s* termine en otro sitio. Digamos que ese *algo mÃ¡s* se llama, por ejemplo, "archivo lento" ğŸ“.

Durante ese tiempo, el sistema puede hacer otras cosas, mientras "archivo lento" ğŸ“ termina.

Entonces el sistema / programa ğŸ¤– volverÃ¡ cada vez que pueda, sea porque estÃ¡ esperando otra vez, porque ğŸ¤– ha terminado todo el trabajo que tenÃ­a en ese momento. Y ğŸ¤– verÃ¡ si alguna de las tareas por las que estaba esperando ha terminado, haciendo lo que tenÃ­a que hacer.

Luego, ğŸ¤– cogerÃ¡ la primera tarea finalizada (digamos, nuestro "archivo lento" ğŸ“) y continuarÃ¡ con lo que tenÃ­a que hacer con esa tarea.

Esa "espera de otra cosa" normalmente se refiere a operaciones <abbr title = "Input and Output, en espaÃ±ol: Entrada y Salida.">I/O</abbr> que son relativamente "lentas" (en relaciÃ³n a la velocidad del procesador y memoria RAM), como por ejemplo esperar por:

* los datos de cliente que se envÃ­an a travÃ©s de la red
* los datos enviados por tu programa para ser recibidos por el cliente a travÃ©s de la red
* el contenido de un archivo en disco para ser leÃ­do por el sistema y entregado al programa
* los contenidos que tu programa da al sistema para ser escritos en disco
* una operaciÃ³n relacionada con una API remota
* una operaciÃ³n de base de datos
* el retorno de resultados de una consulta de base de datos
* etc.

Como el tiempo de ejecuciÃ³n se consume principalmente al esperar a operaciones de <abbr title = "Input and Output">I/O</abbr>, las llaman operaciones "<abbr title="atadas a Entrada y Salida">I/O bound</abbr>".

Se llama "asÃ­ncrono" porque el sistema / programa no tiene que estar "sincronizado" con la tarea lenta, esperando el momento exacto en que finaliza la tarea, sin hacer nada, para poder recoger el resultado de la tarea y continuar el trabajo.

En lugar de eso, al ser un sistema "asÃ­ncrono", una vez finalizada, la tarea puede esperar un poco en la cola (algunos microsegundos) para que la computadora / programa termine lo que estaba haciendo, y luego vuelva para recoger los resultados y seguir trabajando con ellos.

Por "sÃ­ncrono" (contrario a "asÃ­ncrono") tambiÃ©n se usa habitualmente el tÃ©rmino "secuencial", porque el sistema / programa sigue todos los pasos secuencialmente antes de cambiar a una tarea diferente, incluso si esos pasos implican esperas.

### Concurrencia y Hamburguesas

El concepto de cÃ³digo **asÃ­ncrono** descrito anteriormente a veces tambiÃ©n se llama **"concurrencia"**. Es diferente del **"paralelismo"**.

**Concurrencia** y **paralelismo** ambos se relacionan con "cosas diferentes que suceden mÃ¡s o menos al mismo tiempo".

Pero los detalles entre *concurrencia* y *paralelismo* son bastante diferentes.

Para entender las diferencias, imagina la siguiente historia sobre hamburguesas:

### Hamburguesas Concurrentes

Vas con la persona que te gusta ğŸ˜ a pedir comida rÃ¡pida ğŸ”, haces cola mientras el cajero ğŸ’ recoge los pedidos de las personas de delante tuyo.

Llega tu turno, haces tu pedido de 2 hamburguesas impresionantes para esa persona ğŸ˜ y para ti.

Pagas ğŸ’¸.

El cajero ğŸ’ le dice algo al chico de la cocina ğŸ‘¨â€ğŸ³ para que sepa que tiene que preparar tus hamburguesas ğŸ” (a pesar de que actualmente estÃ¡ preparando las de los clientes anteriores).

El cajero ğŸ’ te da el nÃºmero de tu turno.

Mientras esperas, vas con esa persona ğŸ˜ y eliges una mesa, se sientan y hablan durante un rato largo (ya que las hamburguesas son muy impresionantes y necesitan un rato para prepararse âœ¨ğŸ”âœ¨).

Mientras te sientas en la mesa con esa persona ğŸ˜, esperando las hamburguesas ğŸ”, puedes disfrutar ese tiempo admirando lo increÃ­ble, inteligente, y bien que se ve âœ¨ğŸ˜âœ¨.

Mientras esperas y hablas con esa persona ğŸ˜, de vez en cuando, verificas el nÃºmero del mostrador para ver si ya es tu turno.

Al final, en algÃºn momento, llega tu turno. Vas al mostrador, coges tus hamburguesas ğŸ” y vuelves a la mesa.

TÃº y esa persona ğŸ˜ se comen las hamburguesas ğŸ” y la pasan genial âœ¨.

---

Imagina que eres el sistema / programa ğŸ¤– en esa historia.

Mientras estÃ¡s en la cola, estÃ¡s quieto ğŸ˜´, esperando tu turno, sin hacer nada muy "productivo". Pero la lÃ­nea va rÃ¡pida porque el cajero ğŸ’ solo recibe los pedidos (no los prepara), asÃ­ que estÃ¡ bien.

Luego, cuando llega tu turno, haces un trabajo "productivo" real ğŸ¤“, procesas el menÃº, decides lo que quieres, lo que quiere esa persona ğŸ˜, pagas ğŸ’¸, verificas que das el billete o tarjeta correctos, verificas que te cobren correctamente, que el pedido tiene los artÃ­culos correctos, etc.

Pero entonces, aunque aÃºn no tienes tus hamburguesas ğŸ”, el trabajo hecho con el cajero ğŸ’ estÃ¡ "en pausa" â¸, porque debes esperar ğŸ•™ a que tus hamburguesas estÃ©n listas.

Pero como te alejas del mostrador y te sientas en la mesa con un nÃºmero para tu turno, puedes cambiar tu atenciÃ³n ğŸ”€ a esa persona ğŸ˜ y "trabajar" â¯ ğŸ¤“ en eso. Entonces nuevamente estÃ¡s haciendo algo muy "productivo" ğŸ¤“, como coquetear con esa persona ğŸ˜.

DespuÃ©s, el ğŸ’ cajero dice "he terminado de hacer las hamburguesas" ğŸ” poniendo tu nÃºmero en la pantalla del mostrador, pero no saltas al momento que el nÃºmero que se muestra es el tuyo. Sabes que nadie robarÃ¡ tus hamburguesas ğŸ” porque tienes el nÃºmero de tu turno y ellos tienen el suyo.

AsÃ­ que esperas a que esa persona ğŸ˜ termine la historia (terminas el trabajo actual â¯ / tarea actual que se estÃ¡ procesando ğŸ¤“), sonrÃ­es gentilmente y le dices que vas por las hamburguesas â¸.

Luego vas al mostrador ğŸ”€, a la tarea inicial que ya estÃ¡ terminada â¯, recoges las hamburguesas ğŸ”, les dices gracias y las llevas a la mesa. Eso termina esa fase / tarea de interacciÃ³n con el mostrador â¹. Eso a su vez, crea una nueva tarea, "comer hamburguesas" ğŸ”€ â¯, pero la anterior de "conseguir hamburguesas" estÃ¡ terminada â¹.

### Hamburguesas Paralelas

Ahora imagina que estas no son "Hamburguesas Concurrentes" sino "Hamburguesas Paralelas".

Vas con la persona que te gusta ğŸ˜ por comida rÃ¡pida paralela ğŸ”.

Haces la cola mientras varios cajeros (digamos 8) que a la vez son cocineros ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ toman los pedidos de las personas que estÃ¡n delante de ti.

Todos los que estÃ¡n antes de ti estÃ¡n esperando ğŸ•™ que sus hamburguesas ğŸ” estÃ©n listas antes de dejar el mostrador porque cada uno de los 8 cajeros prepara la hamburguesa de inmediato antes de recibir el siguiente pedido.

Entonces finalmente es tu turno, haces tu pedido de 2 hamburguesas ğŸ” impresionantes para esa persona ğŸ˜ y para ti.

Pagas ğŸ’¸.

El cajero va a la cocina ğŸ‘¨â€ğŸ³.

Esperas, de pie frente al mostrador ğŸ•™, para que nadie mÃ¡s recoja tus hamburguesas ğŸ”, ya que no hay nÃºmeros para los turnos.

Como tu y esa persona ğŸ˜ estÃ¡n ocupados en impedir que alguien se ponga delante y recoja tus hamburguesas apenas llegan ğŸ•™, tampoco puedes prestarle atenciÃ³n a esa persona ğŸ˜.

Este es un trabajo "sÃ­ncrono", estÃ¡s "sincronizado" con el cajero / cocinero ğŸ‘¨â€ğŸ³. Tienes que esperar y estar allÃ­ en el momento exacto en que el cajero / cocinero ğŸ‘¨â€ğŸ³ termina las hamburguesas ğŸ” y te las da, o de lo contrario, alguien mÃ¡s podrÃ­a cogerlas.

Luego, el cajero / cocinero ğŸ‘¨â€ğŸ³ finalmente regresa con tus hamburguesas ğŸ”, despuÃ©s de mucho tiempo esperando ğŸ•™ frente al mostrador.

Cojes tus hamburguesas ğŸ” y vas a la mesa con esa persona ğŸ˜.

SÃ³lo las comes y listo ğŸ” â¹.

No has hablado ni coqueteado mucho, ya que has pasado la mayor parte del tiempo esperando ğŸ•™ frente al mostrador ğŸ˜.

---

En este escenario de las hamburguesas paralelas, tÃº eres un sistema / programa ğŸ¤– con dos procesadores (tÃº y la persona que te gusta ğŸ˜), ambos esperando ğŸ•™ y dedicando su atenciÃ³n â¯ a estar "esperando en el mostrador" ğŸ•™ durante mucho tiempo.

La tienda de comida rÃ¡pida tiene 8 procesadores (cajeros / cocineros) ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³. Mientras que la tienda de hamburguesas concurrentes podrÃ­a haber tenido solo 2 (un cajero y un cocinero) ğŸ’ ğŸ‘¨â€ğŸ³.

Pero aÃºn asÃ­, la experiencia final no es la mejor ğŸ˜.

---

Esta serÃ­a la historia paralela equivalente de las hamburguesas ğŸ”.

Para un ejemplo mÃ¡s "real" de Ã©sto, imagina un banco.

Hasta hace poco, la mayorÃ­a de los bancos tenÃ­an varios cajeros ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ y una gran lÃ­nea ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™.

Todos los cajeros haciendo todo el trabajo con un cliente tras otro ğŸ‘¨â€ğŸ’¼â¯.

Y tienes que esperar ğŸ•™ en la fila durante mucho tiempo o perderÃ¡s tu turno.

Probablemente no querrÃ¡s llevar contigo a la persona que te gusta ğŸ˜ a hacer encargos al banco ğŸ¦.

### ConclusiÃ³n de las Hamburguesa

En este escenario de "hamburguesas de comida rÃ¡pida con tu pareja", debido a que hay mucha espera ğŸ•™, tiene mucho mÃ¡s sentido tener un sistema con concurrencia â¸ğŸ”€â¯.

Este es el caso de la mayorÃ­a de las aplicaciones web.

Muchos, muchos usuarios, pero el servidor estÃ¡ esperando ğŸ•™ el envÃ­o de las peticiones ya que su conexiÃ³n no es buena.

Y luego esperando ğŸ•™ nuevamente a que las respuestas retornen.

Esta "espera" ğŸ•™ se mide en microsegundos, pero aun asÃ­, sumando todo, al final es mucha espera.

Es por eso que tiene mucho sentido usar cÃ³digo asÃ­ncrono â¸ğŸ”€â¯ para las API web.

La mayorÃ­a de los framework populares de Python existentes (incluidos Flask y Django) se crearon antes de que existieran las nuevas funciones asÃ­ncronas en Python. Por lo tanto, las formas en que pueden implementarse admiten la ejecuciÃ³n paralela y una forma mÃ¡s antigua de ejecuciÃ³n asÃ­ncrona que no es tan potente como la actual.

A pesar de que la especificaciÃ³n principal para Python web asÃ­ncrono (ASGI) se desarrollÃ³ en Django, para agregar soporte para WebSockets.

Ese tipo de asincronÃ­a es lo que hizo popular a NodeJS (aunque NodeJS no es paralelo) y esa es la fortaleza de Go como lenguaje de programaciÃ³n.

Y ese es el mismo nivel de rendimiento que obtienes con **FastAPI**.

Y como puede tener paralelismo y asincronÃ­a al mismo tiempo, obtienes un mayor rendimiento que la mayorÃ­a de los frameworks de NodeJS probados y a la par con Go, que es un lenguaje compilado mÃ¡s cercano a C <a href="https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query&l=zijmkf-1" class="external-link" target="_blank">(todo gracias Starlette)</a>.

### Â¿Es la concurrencia mejor que el paralelismo?

Â¡No! Esa no es la moraleja de la historia.

La concurrencia es diferente al paralelismo. Y es mejor en escenarios **especÃ­ficos** que implican mucha espera. Debido a eso, generalmente es mucho mejor que el paralelismo para el desarrollo de aplicaciones web. Pero no para todo.

Entonces, para explicar eso, imagina la siguiente historia corta:

> Tienes que limpiar una casa grande y sucia.

*SÃ­, esa es toda la historia*.

---

No hay esperas ğŸ•™, solo hay mucho trabajo por hacer, en varios lugares de la casa.

PodrÃ­as tener turnos como en el ejemplo de las hamburguesas, primero la sala de estar, luego la cocina, pero como no estÃ¡s esperando nada, solo limpiando y limpiando, los turnos no afectarÃ­an nada.

TomarÃ­a la misma cantidad de tiempo terminar con o sin turnos (concurrencia) y habrÃ­as hecho la misma cantidad de trabajo.

Pero en este caso, si pudieras traer a los 8 ex cajeros / cocineros / ahora limpiadores ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ³, y cada uno de ellos (y tÃº) podrÃ­a tomar una zona de la casa para limpiarla, podrÃ­a hacer todo el trabajo en **paralelo**, con la ayuda adicional y terminar mucho antes.

En este escenario, cada uno de los limpiadores (incluido tÃº) serÃ­a un procesador, haciendo su parte del trabajo.

Y como la mayor parte del tiempo de ejecuciÃ³n lo coge el trabajo real (en lugar de esperar), y el trabajo en un sistema lo realiza una <abbr title = "Central Processing Unit. En espaÃ±ol: Unidad Central de Procesamiento."> CPU </abbr>, a estos problemas se les llama "<abbr title="En espaÃ±ol: atado a CPU.">CPU bond</abbr>".

---

Ejemplos tÃ­picos de operaciones dependientes de CPU son cosas que requieren un procesamiento matemÃ¡tico complejo.

Por ejemplo:

* **Audio** o **procesamiento de imÃ¡genes**.
* **VisiÃ³n por computadora**: una imagen estÃ¡ compuesta de millones de pÃ­xeles, cada pÃ­xel tiene 3 valores / colores, procesamiento que normalmente requiere calcular algo en esos pÃ­xeles, todo al mismo tiempo.
* **Machine Learning**: normalmente requiere muchas multiplicaciones de "matrices" y "vectores". Imagina en una enorme hoja de cÃ¡lculo con nÃºmeros y tener que multiplicarlos todos al mismo tiempo.
* **Deep Learning**: este es un subcampo de Machine Learning, por lo tanto, aplica lo mismo. Es solo que no hay una sola hoja de cÃ¡lculo de nÃºmeros para multiplicar, sino un gran conjunto de ellas, y en muchos casos, usa un procesador especial para construir y / o usar esos modelos.

### Concurrencia + Paralelismo: Web + Machine Learning

Con **FastAPI** puedes aprovechar la concurrencia que es muy comÃºn para el desarrollo web (atractivo principal de NodeJS).

Pero tambiÃ©n puedes aprovechar los beneficios del paralelismo y el multiprocesamiento (tener mÃºltiples procesos ejecutÃ¡ndose en paralelo) para cargas de trabajo **CPU bond** como las de los sistemas de Machine Learning.

Eso, mÃ¡s el simple hecho de que Python es el lenguaje principal para **Data Science**, Machine Learning y especialmente Deep Learning, hacen de FastAPI una muy buena combinaciÃ³n para las API y aplicaciones web de Data Science / Machine Learning (entre muchas otras).

Para ver cÃ³mo lograr este paralelismo en producciÃ³n, consulta la secciÃ³n sobre [Despliegue](deployment.md){.internal-link target=_blank}.

## `async` y `await`

Las versiones modernas de Python tienen una forma muy intuitiva de definir cÃ³digo asÃ­ncrono. Esto hace que se vea como un cÃ³digo "secuencial" normal y que haga la "espera" por ti en los momentos correctos.

Cuando hay una operaciÃ³n que requerirÃ¡ esperar antes de dar los resultados y tiene soporte para estas nuevas caracterÃ­sticas de Python, puedes programarlo como:

```Python
burgers = await get_burgers(2)
```

La clave aquÃ­ es `await`. Eso le dice a Python que tiene que esperar â¸ a que `get_burgers (2)` termine de hacer lo suyo ğŸ•™ antes de almacenar los resultados en `hamburguesas`. Con eso, Python sabrÃ¡ que puede ir y hacer otra cosa ğŸ”€ â¯ mientras tanto (como recibir otra solicitud).

Para que `await` funcione, tiene que estar dentro de una funciÃ³n que admita esta asincronÃ­a. Para hacer eso, simplemente lo declaras con `async def`:

```Python hl_lines="1"
async def get_burgers(number: int):
    # Do some asynchronous stuff to create the burgers
    return burgers
```

...en vez de `def`:

```Python hl_lines="2"
# This is not asynchronous
def get_sequential_burgers(number: int):
    # Do some sequential stuff to create the burgers
    return burgers
```

Con `async def`, Python sabe que, dentro de esa funciÃ³n, debe tener en cuenta las expresiones `wait` y que puede "pausar" â¸ la ejecuciÃ³n de esa funciÃ³n e ir a hacer otra cosa ğŸ”€ antes de regresar.

Cuando desees llamar a una funciÃ³n `async def`, debes "esperarla". Entonces, esto no funcionarÃ¡:

```Python
# Esto no funcionarÃ¡, porque get_burgers se definiÃ³ con: async def
hamburguesas = get_burgers (2)
```

---

Por lo tanto, si estÃ¡s utilizando una library que te dice que puedes llamarla con `await`, debes crear las *path operation functions* que la usan con `async def`, como en:

```Python hl_lines="2 3"
@app.get('/burgers')
async def read_burgers():
    burgers = await get_burgers(2)
    return burgers
```

### MÃ¡s detalles tÃ©cnicos

Es posible que hayas notado que `await` solo se puede usar dentro de las funciones definidas con `async def`.

Pero al mismo tiempo, las funciones definidas con `async def` deben ser "esperadas". Por lo tanto, las funciones con `async def` solo se pueden invocar dentro de las funciones definidas con `async def` tambiÃ©n.

Entonces, relacionado con la paradoja del huevo y la gallina, Â¿cÃ³mo se llama a la primera funciÃ³n `async`?

Si estÃ¡s trabajando con **FastAPI** no tienes que preocuparte por eso, porque esa "primera" funciÃ³n serÃ¡ tu *path operation function*, y FastAPI sabrÃ¡ cÃ³mo hacer lo pertinente.

En el caso de que desees usar `async` / `await` sin FastAPI, <a href="https://docs.python.org/3/library/asyncio-task.html#coroutine" class="external-link" target="_blank">revisa la documentaciÃ³n oficial de Python</a>.

### Otras formas de cÃ³digo asÃ­ncrono

Este estilo de usar `async` y `await` es relativamente nuevo en el lenguaje.

Pero hace que trabajar con cÃ³digo asÃ­ncrono sea mucho mÃ¡s fÃ¡cil.

Esta misma sintaxis (o casi idÃ©ntica) tambiÃ©n se incluyÃ³ recientemente en las versiones modernas de JavaScript (en Browser y NodeJS).

Pero antes de eso, manejar cÃ³digo asÃ­ncrono era bastante mÃ¡s complejo y difÃ­cil.

En versiones anteriores de Python, podrÃ­as haber utilizado <abbr title="En espaÃ±ol: hilos.">threads</abbr> o <a href="http://www.gevent.org/" class="external-link" target="_blank">Gevent</a>. Pero el cÃ³digo es mucho mÃ¡s complejo de entender, depurar y desarrollar.

En versiones anteriores de NodeJS / Browser JavaScript, habrÃ­as utilizado "callbacks". Lo que conduce a <a href="http://callbackhell.com/" class="external-link" target="_blank">callback hell</a>.

## Coroutines

**Coroutine** es un tÃ©rmino sofisticado para referirse a la cosa devuelta por una funciÃ³n `async def`. Python sabe que es algo asÃ­ como una funciÃ³n que puede iniciar y que terminarÃ¡ en algÃºn momento, pero que tambiÃ©n podrÃ­a pausarse â¸ internamente, siempre que haya un `await` dentro de ella.

Pero toda esta funcionalidad de usar cÃ³digo asincrÃ³nico con `async` y `await` se resume muchas veces como usar "coroutines". Es comparable a la caracterÃ­stica principal de Go, las "Goroutines".

## ConclusiÃ³n

Veamos la misma frase de arriba:

> Las versiones modernas de Python tienen soporte para **"cÃ³digo asÃ­ncrono"** usando algo llamado **"coroutines"**, con la sintaxis **`async` y `await`**.

Eso ya deberÃ­a tener mÃ¡s sentido ahora. âœ¨

Todo eso es lo que impulsa FastAPI (a travÃ©s de Starlette) y lo que hace que tenga un rendimiento tan impresionante.

## Detalles muy tÃ©cnicos

!!! warning "Advertencia"
    Probablemente puedas saltarte esto.

    Estos son detalles muy tÃ©cnicos de cÃ³mo **FastAPI** funciona a muy bajo nivel.

    Si tienes bastante conocimiento tÃ©cnico (coroutines, threads, bloqueos, etc.) y tienes curiosidad acerca de cÃ³mo FastAPI gestiona `async def` vs `def` normal, continÃºa.

### Path operation functions

Cuando declaras una *path operation function* con `def` normal en lugar de `async def`, se ejecuta en un threadpool externo que luego es "<abbr title="En espaÃ±ol: esperado. Usando await.">awaited</abbr>", en lugar de ser llamado directamente (ya que bloquearÃ­a el servidor).

Si vienes de otro framework asÃ­ncrono que no funciona de la manera descrita anteriormente y estÃ¡s acostumbrado a definir *path operation functions* del tipo sÃ³lo cÃ¡lculo con `def` simple para una pequeÃ±a ganancia de rendimiento (aproximadamente 100 nanosegundos), ten en cuenta que en **FastAPI** el efecto serÃ­a bastante opuesto. En estos casos, es mejor usar `async def` a menos que tus *path operation functions* usen un cÃ³digo que realice el bloqueo <abbr title="Input/Output: disk reading or writing, network communications.">I/O</abbr>.

AÃºn asÃ­, en ambas situaciones, es probable que **FastAPI** sea [aÃºn mÃ¡s rÃ¡pido](/#rendimiento){.Internal-link target=_blank} que (o al menos comparable) a tu framework anterior.

### Dependencias

Lo mismo se aplica para las dependencias. Si una dependencia es una funciÃ³n estÃ¡ndar `def` en lugar de `async def`, se ejecuta en el threadpool externo.

### Subdependencias

Puedes tener mÃºltiples dependencias y subdependencias que se requieren unas a otras (como parÃ¡metros de las definiciones de cada funciÃ³n), algunas de ellas pueden crearse con `async def` y otras con `def` normal. Igual todo seguirÃ­a funcionando correctamente, y las creadas con `def` normal se llamarÃ­an en un thread externo (del threadpool) en lugar de ser "awaited".

### Otras funciones de utilidades

Cualquier otra funciÃ³n de utilidad que llames directamente se puede crear con `def` o `async def` normales y FastAPI no afectarÃ¡ la manera en que la llames.

Esto contrasta con las funciones que FastAPI llama por ti: las *path operation functions* y dependencias.

Si tu funciÃ³n de utilidad es creada con `def` normal, se llamarÃ¡ directamente (tal cual la escribes en tu cÃ³digo), no en un threadpool, si la funciÃ³n se crea con `async def`, entonces debes usar `await` con esa funciÃ³n cuando la llamas en tu cÃ³digo.

---

Nuevamente, estos son detalles muy tÃ©cnicos que probablemente sÃ³lo son Ãºtiles si los viniste a buscar expresamente.

De lo contrario, la guÃ­a de la secciÃ³n anterior deberÃ­a ser suficiente: <a href="#in-a-hurry">Â¿Tienes prisa?</a>.
