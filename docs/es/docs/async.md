# Concurrencia y async / await

Detalles sobre la sintaxis `async def` para *path operation functions* y un poco de informaci칩n sobre c칩digo as칤ncrono, concurrencia y paralelismo.

## 쯊ienes prisa?

<abbr title="too long; didn't read"><strong>TL;DR:</strong></abbr>

Si est치s utilizando libraries de terceros que te dicen que las llames con `await`, del tipo:

```Python
results = await some_library()
```

Entonces declara tus *path operation functions* con `async def` de la siguiente manera:

```Python hl_lines="2"
@app.get('/')
async def read_results():
    results = await some_library()
    return results
```

!!! note "Nota"
    Solo puedes usar `await` dentro de funciones creadas con `async def`.

---

Si est치s utilizando libraries de terceros que se comunican con algo (una base de datos, una API, el sistema de archivos, etc.) y no tienes soporte para `await` (este es el caso para la mayor칤a de las libraries de bases de datos), declara tus *path operation functions* de forma habitual, con solo `def`, de la siguiente manera:

```Python hl_lines="2"
@app.get('/')
def results():
    results = some_library()
    return results
```

---

Si tu aplicaci칩n (de alguna manera) no tiene que comunicarse con nada m치s y en consecuencia esperar a que responda, usa `async def`.

---

Si simplemente no lo sabes, usa `def` normal.

---

**Nota**: puedes mezclar `def` y `async def` en tus *path operation functions* tanto como lo necesites y definir cada una utilizando la mejor opci칩n para ti. FastAPI har치 lo correcto con ellos.

De todos modos, en cualquiera de los casos anteriores, FastAPI seguir치 funcionando de forma as칤ncrona y ser치 extremadamente r치pido.

Pero siguiendo los pasos anteriores, FastAPI podr치 hacer algunas optimizaciones de rendimiento.

## Detalles T칠cnicos

Las versiones modernas de Python tienen soporte para **"c칩digo as칤ncrono"** usando algo llamado **"coroutines"**, usando la sintaxis **`async` y `await`**.

Veamos esa frase por partes en las secciones siguientes:

* **C칩digo As칤ncrono**
* **`async` y `await`**
* **Coroutines**

## C칩digo As칤ncrono

El c칩digo as칤ncrono s칩lo significa que el lenguaje tiene una manera de decirle al sistema / programa que, en alg칰n momento del c칩digo, tendr치 que esperar a que *algo m치s* termine en otro sitio. Digamos que ese *algo m치s* se llama, por ejemplo, "archivo lento".

Durante ese tiempo, el sistema puede hacer otras cosas, mientras "archivo lento" termina.

Entonces el sistema / programa volver치 cada vez que pueda, sea porque est치 esperando otra vez, porque ha terminado todo el trabajo que ten칤a en ese momento. Y ver치 si alguna de las tareas por las que estaba esperando ha terminado, haciendo lo que ten칤a que hacer.

Luego, coger치 la primera tarea finalizada (digamos, nuestro "archivo lento") y continuar치 con lo que ten칤a que hacer con esa tarea.

Esa "espera de otra cosa" normalmente se refiere a operaciones <abbr title = "Input and Output, en espa침ol: Entrada y Salida.">I/O</abbr> que son relativamente "lentas" (en relaci칩n a la velocidad del procesador y memoria RAM), como por ejemplo esperar por:

* los datos de cliente que se env칤an a trav칠s de la red
* los datos enviados por tu programa para ser recibidos por el cliente a trav칠s de la red
* el contenido de un archivo en disco para ser le칤do por el sistema y entregado al programa
* los contenidos que tu programa da al sistema para ser escritos en disco
* una operaci칩n relacionada con una API remota
* una operaci칩n de base de datos
* el retorno de resultados de una consulta de base de datos
* etc.

Como el tiempo de ejecuci칩n se consume principalmente al esperar a operaciones de <abbr title = "Input and Output">I/O</abbr>, las llaman operaciones "<abbr title="atadas a Entrada y Salida">I/O bound</abbr>".

Se llama "as칤ncrono" porque el sistema / programa no tiene que estar "sincronizado" con la tarea lenta, esperando el momento exacto en que finaliza la tarea, sin hacer nada, para poder recoger el resultado de la tarea y continuar el trabajo.

En lugar de eso, al ser un sistema "as칤ncrono", una vez finalizada, la tarea puede esperar un poco en la cola (algunos microsegundos) para que la computadora / programa termine lo que estaba haciendo, y luego vuelva para recoger los resultados y seguir trabajando con ellos.

Por "s칤ncrono" (contrario a "as칤ncrono") tambi칠n se usa habitualmente el t칠rmino "secuencial", porque el sistema / programa sigue todos los pasos secuencialmente antes de cambiar a una tarea diferente, incluso si esos pasos implican esperas.

### Concurrencia y Hamburguesas

El concepto de c칩digo **as칤ncrono** descrito anteriormente a veces tambi칠n se llama **"concurrencia"**. Es diferente del **"paralelismo"**.

**Concurrencia** y **paralelismo** ambos se relacionan con "cosas diferentes que suceden m치s o menos al mismo tiempo".

Pero los detalles entre *concurrencia* y *paralelismo* son bastante diferentes.

Para entender las diferencias, imagina la siguiente historia sobre hamburguesas:

### Hamburguesas Concurrentes

Vas con la persona que te gusta a pedir comida r치pida, haces cola mientras el cajero recoge los pedidos de las personas de delante tuyo.

Llega tu turno, haces tu pedido de 2 hamburguesas impresionantes para esa persona y para ti.

Pagas.

El cajero le dice algo al chico de la cocina para que sepa que tiene que preparar tus hamburguesas (a pesar de que actualmente est치 preparando las de los clientes anteriores).

El cajero te da el n칰mero de tu turno.

Mientras esperas, vas con esa persona y eliges una mesa, se sientan y hablan durante un rato largo (ya que las hamburguesas son muy impresionantes y necesitan un rato para prepararse).

Mientras te sientas en la mesa con esa persona, esperando las hamburguesas, puedes disfrutar ese tiempo admirando lo incre칤ble, inteligente, y bien que se ve.

Mientras esperas y hablas con esa persona, de vez en cuando, verificas el n칰mero del mostrador para ver si ya es tu turno.

Al final, en alg칰n momento, llega tu turno. Vas al mostrador, coges tus hamburguesas y vuelves a la mesa.

T칰 y esa persona se comen las hamburguesas y la pasan genial.

---

Imagina que eres el sistema / programa en esa historia.

Mientras est치s en la cola, est치s quieto, esperando tu turno, sin hacer nada muy "productivo". Pero la l칤nea va r치pida porque el cajero solo recibe los pedidos (no los prepara), as칤 que est치 bien.

Luego, cuando llega tu turno, haces un trabajo "productivo" real, procesas el men칰, decides lo que quieres, lo que quiere esa persona, pagas 游눶, verificas que das el billete o tarjeta correctos, verificas que te cobren correctamente, que el pedido tiene los art칤culos correctos, etc.

Pero entonces, aunque a칰n no tienes tus hamburguesas, el trabajo hecho con el cajero est치 "en pausa", porque debes esperar a que tus hamburguesas est칠n listas.

Pero como te alejas del mostrador y te sientas en la mesa con un n칰mero para tu turno, puedes cambiar tu atenci칩n a esa persona y "trabajar" en eso. Entonces nuevamente est치s haciendo algo muy "productivo", como coquetear con esa persona.

Despu칠s, el cajero dice "he terminado de hacer las hamburguesas" poniendo tu n칰mero en la pantalla del mostrador, pero no saltas al momento que el n칰mero que se muestra es el tuyo. Sabes que nadie robar치 tus hamburguesas porque tienes el n칰mero de tu turno y ellos tienen el suyo.

As칤 que esperas a que esa persona termine la historia (terminas el trabajo actual / tarea actual que se est치 procesando), sonr칤es gentilmente y le dices que vas por las hamburguesas.

Luego vas al mostrador, a la tarea inicial que ya est치 terminada, recoges las hamburguesas, les dices gracias y las llevas a la mesa. Eso termina esa fase / tarea de interacci칩n con el mostrador. Eso a su vez, crea una nueva tarea, "comer hamburguesas", pero la anterior de "conseguir hamburguesas" est치 terminada.

### Hamburguesas Paralelas

Ahora imagina que estas no son "Hamburguesas Concurrentes" sino "Hamburguesas Paralelas".

Vas con la persona que te gusta por comida r치pida paralela.

Haces la cola mientras varios cajeros (digamos 8) que a la vez son cocineros toman los pedidos de las personas que est치n delante de ti.

Todos los que est치n antes de ti est치n esperando que sus hamburguesas est칠n listas antes de dejar el mostrador porque cada uno de los 8 cajeros prepara la hamburguesa de inmediato antes de recibir el siguiente pedido.

Entonces finalmente es tu turno, haces tu pedido de 2 hamburguesas impresionantes para esa persona y para ti.

Pagas.

El cajero va a la cocina.

Esperas, de pie frente al mostrador, para que nadie m치s recoja tus hamburguesas, ya que no hay n칰meros para los turnos.

Como tu y esa persona est치n ocupados en impedir que alguien se ponga delante y recoja tus hamburguesas apenas llegan, tampoco puedes prestarle atenci칩n a esa persona.

Este es un trabajo "s칤ncrono", est치s "sincronizado" con el cajero / cocinero. Tienes que esperar y estar all칤 en el momento exacto en que el cajero / cocinero termina las hamburguesas y te las da, o de lo contrario, alguien m치s podr칤a cogerlas.

Luego, el cajero / cocinero finalmente regresa con tus hamburguesas, despu칠s de mucho tiempo esperando frente al mostrador.

Cojes tus hamburguesas y vas a la mesa con esa persona.

S칩lo las comes y listo.

No has hablado ni coqueteado mucho, ya que has pasado la mayor parte del tiempo esperando frente al mostrador.

---

En este escenario de las hamburguesas paralelas, t칰 eres un sistema / programa con dos procesadores (t칰 y la persona que te gusta), ambos esperando y dedicando su atenci칩n a estar "esperando en el mostrador" durante mucho tiempo.

La tienda de comida r치pida tiene 8 procesadores (cajeros / cocineros). Mientras que la tienda de hamburguesas concurrentes podr칤a haber tenido solo 2 (un cajero y un cocinero).

Pero a칰n as칤, la experiencia final no es la mejor.

---

Esta ser칤a la historia paralela equivalente de las hamburguesas.

Para un ejemplo m치s "real" de 칠sto, imagina un banco.

Hasta hace poco, la mayor칤a de los bancos ten칤an varios cajeros y una gran l칤nea.

Todos los cajeros haciendo todo el trabajo con un cliente tras otro.

Y tienes que esperar en la fila durante mucho tiempo o perder치s tu turno.

Probablemente no querr치s llevar contigo a la persona que te gusta a hacer encargos al banco.

### Conclusi칩n de las Hamburguesa

En este escenario de "hamburguesas de comida r치pida con tu pareja", debido a que hay mucha espera, tiene mucho m치s sentido tener un sistema con concurrencia.

Este es el caso de la mayor칤a de las aplicaciones web.

Muchos, muchos usuarios, pero el servidor est치 esperando el env칤o de las peticiones ya que su conexi칩n no es buena.

Y luego esperando nuevamente a que las respuestas retornen.

Esta "espera" se mide en microsegundos, pero aun as칤, sumando todo, al final es mucha espera.

Es por eso que tiene mucho sentido usar c칩digo as칤ncrono para las API web.

La mayor칤a de los framework populares de Python existentes (incluidos Flask y Django) se crearon antes de que existieran las nuevas funciones as칤ncronas en Python. Por lo tanto, las formas en que pueden implementarse admiten la ejecuci칩n paralela y una forma m치s antigua de ejecuci칩n as칤ncrona que no es tan potente como la actual.

A pesar de que la especificaci칩n principal para Python web as칤ncrono (ASGI) se desarroll칩 en Django, para agregar soporte para WebSockets.

Ese tipo de asincron칤a es lo que hizo popular a NodeJS (aunque NodeJS no es paralelo) y esa es la fortaleza de Go como lenguaje de programaci칩n.

Y ese es el mismo nivel de rendimiento que obtienes con **FastAPI**.

Y como puede tener paralelismo y asincron칤a al mismo tiempo, obtienes un mayor rendimiento que la mayor칤a de los frameworks de NodeJS probados y a la par con Go, que es un lenguaje compilado m치s cercano a C <a href="https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query&l=zijmkf-1" class="external-link" target="_blank">(todo gracias Starlette)</a>.

### 쮼s la concurrencia mejor que el paralelismo?

춰No! Esa no es la moraleja de la historia.

La concurrencia es diferente al paralelismo. Y es mejor en escenarios **espec칤ficos** que implican mucha espera. Debido a eso, generalmente es mucho mejor que el paralelismo para el desarrollo de aplicaciones web. Pero no para todo.

Entonces, para explicar eso, imagina la siguiente historia corta:

> Tienes que limpiar una casa grande y sucia.

*S칤, esa es toda la historia*.

---

No hay esperas, solo hay mucho trabajo por hacer, en varios lugares de la casa.

Podr칤as tener turnos como en el ejemplo de las hamburguesas, primero la sala de estar, luego la cocina, pero como no est치s esperando nada, solo limpiando y limpiando, los turnos no afectar칤an nada.

Tomar칤a la misma cantidad de tiempo terminar con o sin turnos (concurrencia) y habr칤as hecho la misma cantidad de trabajo.

Pero en este caso, si pudieras traer a los 8 ex cajeros / cocineros / ahora limpiadores, y cada uno de ellos (y t칰) podr칤a tomar una zona de la casa para limpiarla, podr칤a hacer todo el trabajo en **paralelo**, con la ayuda adicional y terminar mucho antes.

En este escenario, cada uno de los limpiadores (incluido t칰) ser칤a un procesador, haciendo su parte del trabajo.

Y como la mayor parte del tiempo de ejecuci칩n lo coge el trabajo real (en lugar de esperar), y el trabajo en un sistema lo realiza una <abbr title = "Central Processing Unit. En espa침ol: Unidad Central de Procesamiento."> CPU </abbr>, a estos problemas se les llama "<abbr title="En espa침ol: atado a CPU.">CPU bond</abbr>".

---

Ejemplos t칤picos de operaciones dependientes de CPU son cosas que requieren un procesamiento matem치tico complejo.

Por ejemplo:

* **Audio** o **procesamiento de im치genes**.
* **Visi칩n por computadora**: una imagen est치 compuesta de millones de p칤xeles, cada p칤xel tiene 3 valores / colores, procesamiento que normalmente requiere calcular algo en esos p칤xeles, todo al mismo tiempo.
* **Machine Learning**: normalmente requiere muchas multiplicaciones de "matrices" y "vectores". Imagina en una enorme hoja de c치lculo con n칰meros y tener que multiplicarlos todos al mismo tiempo.
* **Deep Learning**: este es un subcampo de Machine Learning, por lo tanto, aplica lo mismo. Es solo que no hay una sola hoja de c치lculo de n칰meros para multiplicar, sino un gran conjunto de ellas, y en muchos casos, usa un procesador especial para construir y / o usar esos modelos.

### Concurrencia + Paralelismo: Web + Machine Learning

Con **FastAPI** puedes aprovechar la concurrencia que es muy com칰n para el desarrollo web (atractivo principal de NodeJS).

Pero tambi칠n puedes aprovechar los beneficios del paralelismo y el multiprocesamiento (tener m칰ltiples procesos ejecut치ndose en paralelo) para cargas de trabajo **CPU bond** como las de los sistemas de Machine Learning.

Eso, m치s el simple hecho de que Python es el lenguaje principal para **Data Science**, Machine Learning y especialmente Deep Learning, hacen de FastAPI una muy buena combinaci칩n para las API y aplicaciones web de Data Science / Machine Learning (entre muchas otras).

Para ver c칩mo lograr este paralelismo en producci칩n, consulta la secci칩n sobre [Despliegue](deployment/index.md){.internal-link target=_blank}.

## `async` y `await`

Las versiones modernas de Python tienen una forma muy intuitiva de definir c칩digo as칤ncrono. Esto hace que se vea como un c칩digo "secuencial" normal y que haga la "espera" por ti en los momentos correctos.

Cuando hay una operaci칩n que requerir치 esperar antes de dar los resultados y tiene soporte para estas nuevas caracter칤sticas de Python, puedes programarlo como:

```Python
burgers = await get_burgers(2)
```

La clave aqu칤 es `await`. Eso le dice a Python que tiene que esperar a que `get_burgers (2)` termine de hacer lo suyo antes de almacenar los resultados en `hamburguesas`. Con eso, Python sabr치 que puede ir y hacer otra cosa mientras tanto (como recibir otra solicitud).

Para que `await` funcione, tiene que estar dentro de una funci칩n que admita esta asincron칤a. Para hacer eso, simplemente lo declaras con `async def`:

```Python hl_lines="1"
async def get_burgers(number: int):
    # Do some asynchronous stuff to create the burgers
    return burgers
```

...en vez de `def`:

```Python hl_lines="2"
# This is not asynchronous
def get_sequential_burgers(number: int):
    # Do some sequential stuff to create the burgers
    return burgers
```

Con `async def`, Python sabe que, dentro de esa funci칩n, debe tener en cuenta las expresiones `wait` y que puede "pausar" la ejecuci칩n de esa funci칩n e ir a hacer otra cosa antes de regresar.

Cuando desees llamar a una funci칩n `async def`, debes "esperarla". Entonces, esto no funcionar치:

```Python
# Esto no funcionar치, porque get_burgers se defini칩 con: async def
hamburguesas = get_burgers (2)
```

---

Por lo tanto, si est치s utilizando una library que te dice que puedes llamarla con `await`, debes crear las *path operation functions* que la usan con `async def`, como en:

```Python hl_lines="2-3"
@app.get('/burgers')
async def read_burgers():
    burgers = await get_burgers(2)
    return burgers
```

### M치s detalles t칠cnicos

Es posible que hayas notado que `await` solo se puede usar dentro de las funciones definidas con `async def`.

Pero al mismo tiempo, las funciones definidas con `async def` deben ser "esperadas". Por lo tanto, las funciones con `async def` solo se pueden invocar dentro de las funciones definidas con `async def` tambi칠n.

Entonces, relacionado con la paradoja del huevo y la gallina, 쯖칩mo se llama a la primera funci칩n `async`?

Si est치s trabajando con **FastAPI** no tienes que preocuparte por eso, porque esa "primera" funci칩n ser치 tu *path operation function*, y FastAPI sabr치 c칩mo hacer lo pertinente.

En el caso de que desees usar `async` / `await` sin FastAPI, <a href="https://docs.python.org/3/library/asyncio-task.html#coroutine" class="external-link" target="_blank">revisa la documentaci칩n oficial de Python</a>.

### Otras formas de c칩digo as칤ncrono

Este estilo de usar `async` y `await` es relativamente nuevo en el lenguaje.

Pero hace que trabajar con c칩digo as칤ncrono sea mucho m치s f치cil.

Esta misma sintaxis (o casi id칠ntica) tambi칠n se incluy칩 recientemente en las versiones modernas de JavaScript (en Browser y NodeJS).

Pero antes de eso, manejar c칩digo as칤ncrono era bastante m치s complejo y dif칤cil.

En versiones anteriores de Python, podr칤as haber utilizado <abbr title="En espa침ol: hilos.">threads</abbr> o <a href="https://www.gevent.org/" class="external-link" target="_blank">Gevent</a>. Pero el c칩digo es mucho m치s complejo de entender, depurar y desarrollar.

En versiones anteriores de NodeJS / Browser JavaScript, habr칤as utilizado "callbacks". Lo que conduce a <a href="http://callbackhell.com/" class="external-link" target="_blank">callback hell</a>.

## Coroutines

**Coroutine** es un t칠rmino sofisticado para referirse a la cosa devuelta por una funci칩n `async def`. Python sabe que es algo as칤 como una funci칩n que puede iniciar y que terminar치 en alg칰n momento, pero que tambi칠n podr칤a pausarse internamente, siempre que haya un `await` dentro de ella.

Pero toda esta funcionalidad de usar c칩digo asincr칩nico con `async` y `await` se resume muchas veces como usar "coroutines". Es comparable a la caracter칤stica principal de Go, las "Goroutines".

## Conclusi칩n

Veamos la misma frase de arriba:

> Las versiones modernas de Python tienen soporte para **"c칩digo as칤ncrono"** usando algo llamado **"coroutines"**, con la sintaxis **`async` y `await`**.

Eso ya deber칤a tener m치s sentido ahora.

Todo eso es lo que impulsa FastAPI (a trav칠s de Starlette) y lo que hace que tenga un rendimiento tan impresionante.

## Detalles muy t칠cnicos

!!! warning "Advertencia"
    Probablemente puedas saltarte esto.

    Estos son detalles muy t칠cnicos de c칩mo **FastAPI** funciona a muy bajo nivel.

    Si tienes bastante conocimiento t칠cnico (coroutines, threads, bloqueos, etc.) y tienes curiosidad acerca de c칩mo FastAPI gestiona `async def` vs `def` normal, contin칰a.

### Path operation functions

Cuando declaras una *path operation function* con `def` normal en lugar de `async def`, se ejecuta en un threadpool externo que luego es "<abbr title="En espa침ol: esperado. Usando await.">awaited</abbr>", en lugar de ser llamado directamente (ya que bloquear칤a el servidor).

Si vienes de otro framework as칤ncrono que no funciona de la manera descrita anteriormente y est치s acostumbrado a definir *path operation functions* del tipo s칩lo c치lculo con `def` simple para una peque침a ganancia de rendimiento (aproximadamente 100 nanosegundos), ten en cuenta que en **FastAPI** el efecto ser칤a bastante opuesto. En estos casos, es mejor usar `async def` a menos que tus *path operation functions* usen un c칩digo que realice el bloqueo <abbr title="Input/Output: disk reading or writing, network communications.">I/O</abbr>.

A칰n as칤, en ambas situaciones, es probable que **FastAPI** sea [a칰n m치s r치pido](/#rendimiento){.Internal-link target=_blank} que (o al menos comparable) a tu framework anterior.

### Dependencias

Lo mismo se aplica para las dependencias. Si una dependencia es una funci칩n est치ndar `def` en lugar de `async def`, se ejecuta en el threadpool externo.

### Subdependencias

Puedes tener m칰ltiples dependencias y subdependencias que se requieren unas a otras (como par치metros de las definiciones de cada funci칩n), algunas de ellas pueden crearse con `async def` y otras con `def` normal. Igual todo seguir칤a funcionando correctamente, y las creadas con `def` normal se llamar칤an en un thread externo (del threadpool) en lugar de ser "awaited".

### Otras funciones de utilidades

Cualquier otra funci칩n de utilidad que llames directamente se puede crear con `def` o `async def` normales y FastAPI no afectar치 la manera en que la llames.

Esto contrasta con las funciones que FastAPI llama por ti: las *path operation functions* y dependencias.

Si tu funci칩n de utilidad es creada con `def` normal, se llamar치 directamente (tal cual la escribes en tu c칩digo), no en un threadpool, si la funci칩n se crea con `async def`, entonces debes usar `await` con esa funci칩n cuando la llamas en tu c칩digo.

---

Nuevamente, estos son detalles muy t칠cnicos que probablemente s칩lo son 칰tiles si los viniste a buscar expresamente.

De lo contrario, la gu칤a de la secci칩n anterior deber칤a ser suficiente: <a href="#in-a-hurry">쯊ienes prisa?</a>.
