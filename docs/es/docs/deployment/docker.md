# FastAPI en Contenedores - Docker

Al desplegar aplicaciones de FastAPI, un enfoque com√∫n es construir una **imagen de contenedor de Linux**. Normalmente se realiza usando <a href="https://www.docker.com/" class="external-link" target="_blank">**Docker**</a>. Luego puedes desplegar esa imagen de contenedor de varias formas.

Usar contenedores de Linux tiene varias ventajas, incluyendo **seguridad**, **replicabilidad**, **simplicidad**, y otras.

/// tip | Consejo

¬øTienes prisa y ya conoces esto? Salta al [`Dockerfile` m√°s abajo üëá](#construir-una-imagen-de-docker-para-fastapi).

///

<details>
<summary>Vista previa del Dockerfile üëÄ</summary>

```Dockerfile
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

CMD ["fastapi", "run", "app/main.py", "--port", "80"]

# Si est√°s detr√°s de un proxy como Nginx o Traefik a√±ade --proxy-headers
# CMD ["fastapi", "run", "app/main.py", "--port", "80", "--proxy-headers"]
```

</details>

## Qu√© es un Contenedor

Los contenedores (principalmente contenedores de Linux) son una forma muy **ligera** de empaquetar aplicaciones incluyendo todas sus dependencias y archivos necesarios, manteni√©ndolos aislados de otros contenedores (otras aplicaciones o componentes) en el mismo sistema.

Los contenedores de Linux se ejecutan utilizando el mismo n√∫cleo de Linux del host (m√°quina, m√°quina virtual, servidor en la nube, etc.). Esto significa que son muy ligeros (en comparaci√≥n con las m√°quinas virtuales completas que emulan un sistema operativo completo).

De esta forma, los contenedores consumen **pocos recursos**, una cantidad comparable a ejecutar los procesos directamente (una m√°quina virtual consumir√≠a mucho m√°s).

Los contenedores tambi√©n tienen sus propios procesos de ejecuci√≥n **aislados** (normalmente solo un proceso), sistema de archivos y red, simplificando el despliegue, la seguridad, el desarrollo, etc.

## Qu√© es una Imagen de Contenedor

Un **contenedor** se ejecuta desde una **imagen de contenedor**.

Una imagen de contenedor es una versi√≥n **est√°tica** de todos los archivos, variables de entorno y el comando/programa por defecto que deber√≠a estar presente en un contenedor. **Est√°tico** aqu√≠ significa que la imagen de contenedor **no se est√° ejecutando**, no est√° siendo ejecutada, son solo los archivos empaquetados y los metadatos.

En contraste con una "**imagen de contenedor**" que son los contenidos est√°ticos almacenados, un "**contenedor**" normalmente se refiere a la instance en ejecuci√≥n, lo que est√° siendo **ejecutado**.

Cuando el **contenedor** se inicia y est√° en funcionamiento (iniciado a partir de una **imagen de contenedor**), puede crear o cambiar archivos, variables de entorno, etc. Esos cambios existir√°n solo en ese contenedor, pero no persistir√°n en la imagen de contenedor subyacente (no se guardar√°n en disco).

Una imagen de contenedor es comparable al archivo de **programa** y sus contenidos, por ejemplo, `python` y alg√∫n archivo `main.py`.

Y el **contenedor** en s√≠ (en contraste con la **imagen de contenedor**) es la instance real en ejecuci√≥n de la imagen, comparable a un **proceso**. De hecho, un contenedor solo se est√° ejecutando cuando tiene un **proceso en ejecuci√≥n** (y normalmente es solo un proceso). El contenedor se detiene cuando no hay un proceso en ejecuci√≥n en √©l.

## Im√°genes de Contenedor

Docker ha sido una de las herramientas principales para crear y gestionar **im√°genes de contenedor** y **contenedores**.

Y hay un <a href="https://hub.docker.com/" class="external-link" target="_blank">Docker Hub</a> p√∫blico con **im√°genes de contenedores oficiales** pre-hechas para muchas herramientas, entornos, bases de datos y aplicaciones.

Por ejemplo, hay una <a href="https://hub.docker.com/_/python" class="external-link" target="_blank">Imagen de Python</a> oficial.

Y hay muchas otras im√°genes para diferentes cosas como bases de datos, por ejemplo para:

* <a href="https://hub.docker.com/_/postgres" class="external-link" target="_blank">PostgreSQL</a>
* <a href="https://hub.docker.com/_/mysql" class="external-link" target="_blank">MySQL</a>
* <a href="https://hub.docker.com/_/mongo" class="external-link" target="_blank">MongoDB</a>
* <a href="https://hub.docker.com/_/redis" class="external-link" target="_blank">Redis</a>, etc.

Usando una imagen de contenedor pre-hecha es muy f√°cil **combinar** y utilizar diferentes herramientas. Por ejemplo, para probar una nueva base de datos. En la mayor√≠a de los casos, puedes usar las **im√°genes oficiales**, y simplemente configurarlas con variables de entorno.

De esta manera, en muchos casos puedes aprender sobre contenedores y Docker y reutilizar ese conocimiento con muchas herramientas y componentes diferentes.

As√≠, ejecutar√≠as **m√∫ltiples contenedores** con diferentes cosas, como una base de datos, una aplicaci√≥n de Python, un servidor web con una aplicaci√≥n frontend en React, y conectarlos entre s√≠ a trav√©s de su red interna.

Todos los sistemas de gesti√≥n de contenedores (como Docker o Kubernetes) tienen estas caracter√≠sticas de redes integradas en ellos.

## Contenedores y Procesos

Una **imagen de contenedor** normalmente incluye en sus metadatos el programa o comando por defecto que deber√≠a ser ejecutado cuando el **contenedor** se inicie y los par√°metros que deben pasar a ese programa. Muy similar a lo que ser√≠a si estuviera en la l√≠nea de comandos.

Cuando un **contenedor** se inicia, ejecutar√° ese comando/programa (aunque puedes sobrescribirlo y hacer que ejecute un comando/programa diferente).

Un contenedor est√° en ejecuci√≥n mientras el **proceso principal** (comando o programa) est√© en ejecuci√≥n.

Un contenedor normalmente tiene un **proceso √∫nico**, pero tambi√©n es posible iniciar subprocesos desde el proceso principal, y de esa manera tendr√°s **m√∫ltiples procesos** en el mismo contenedor.

Pero no es posible tener un contenedor en ejecuci√≥n sin **al menos un proceso en ejecuci√≥n**. Si el proceso principal se detiene, el contenedor se detiene.

## Construir una Imagen de Docker para FastAPI

¬°Bien, construyamos algo ahora! üöÄ

Te mostrar√© c√≥mo construir una **imagen de Docker** para FastAPI **desde cero**, basada en la imagen **oficial de Python**.

Esto es lo que querr√≠as hacer en **la mayor√≠a de los casos**, por ejemplo:

* Usando **Kubernetes** o herramientas similares
* Al ejecutar en un **Raspberry Pi**
* Usando un servicio en la nube que ejecutar√≠a una imagen de contenedor por ti, etc.

### Requisitos del Paquete

Normalmente tendr√≠as los **requisitos del paquete** para tu aplicaci√≥n en alg√∫n archivo.

Depender√≠a principalmente de la herramienta que uses para **instalar** esos requisitos.

La forma m√°s com√∫n de hacerlo es tener un archivo `requirements.txt` con los nombres de los paquetes y sus versiones, uno por l√≠nea.

Por supuesto, usar√≠as las mismas ideas que le√≠ste en [Acerca de las versiones de FastAPI](versions.md){.internal-link target=_blank} para establecer los rangos de versiones.

Por ejemplo, tu `requirements.txt` podr√≠a verse as√≠:

```
fastapi[standard]>=0.113.0,<0.114.0
pydantic>=2.7.0,<3.0.0
```

Y normalmente instalar√≠as esas dependencias de los paquetes con `pip`, por ejemplo:

<div class="termy">

```console
$ pip install -r requirements.txt
---> 100%
Successfully installed fastapi pydantic
```

</div>

/// info | Informaci√≥n

Existen otros formatos y herramientas para definir e instalar dependencias de paquetes.

///

### Crear el C√≥digo de **FastAPI**

* Crea un directorio `app` y entra en √©l.
* Crea un archivo vac√≠o `__init__.py`.
* Crea un archivo `main.py` con:

```Python
from typing import Union

from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}
```

### Dockerfile

Ahora, en el mismo directorio del proyecto, crea un archivo `Dockerfile` con:

```{ .dockerfile .annotate }
# (1)!
FROM python:3.9

# (2)!
WORKDIR /code

# (3)!
COPY ./requirements.txt /code/requirements.txt

# (4)!
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (5)!
COPY ./app /code/app

# (6)!
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

1. Comenzar desde la imagen base oficial de Python.

2. Establecer el directorio de trabajo actual a `/code`.

    Aqu√≠ es donde pondremos el archivo `requirements.txt` y el directorio `app`.

3. Copiar el archivo con los requisitos al directorio `/code`.

    Copiar **solo** el archivo con los requisitos primero, no el resto del c√≥digo.

    Como este archivo **no cambia a menudo**, Docker lo detectar√° y usar√° la **cach√©** para este paso, habilitando la cach√© para el siguiente paso tambi√©n.

4. Instalar las dependencias de los paquetes en el archivo de requisitos.

    La opci√≥n `--no-cache-dir` le dice a `pip` que no guarde los paquetes descargados localmente, ya que eso solo ser√≠a si `pip` fuese a ejecutarse de nuevo para instalar los mismos paquetes, pero ese no es el caso al trabajar con contenedores.

    /// note | Nota

    El `--no-cache-dir` est√° relacionado solo con `pip`, no tiene nada que ver con Docker o contenedores.

    ///

    La opci√≥n `--upgrade` le dice a `pip` que actualice los paquetes si ya est√°n instalados.

    Debido a que el paso anterior de copiar el archivo podr√≠a ser detectado por la **cach√© de Docker**, este paso tambi√©n **usar√° la cach√© de Docker** cuando est√© disponible.

    Usar la cach√© en este paso te **ahorrar√°** mucho **tiempo** al construir la imagen una y otra vez durante el desarrollo, en lugar de **descargar e instalar** todas las dependencias **cada vez**.

5. Copiar el directorio `./app` dentro del directorio `/code`.

    Como esto contiene todo el c√≥digo, que es lo que **cambia con m√°s frecuencia**, la **cach√© de Docker** no se utilizar√° para este u otros **pasos siguientes** f√°cilmente.

    As√≠ que es importante poner esto **cerca del final** del `Dockerfile`, para optimizar los tiempos de construcci√≥n de la imagen del contenedor.

6. Establecer el **comando** para usar `fastapi run`, que utiliza Uvicorn debajo.

    `CMD` toma una lista de cadenas, cada una de estas cadenas es lo que escribir√≠as en la l√≠nea de comandos separado por espacios.

    Este comando se ejecutar√° desde el **directorio de trabajo actual**, el mismo directorio `/code` que estableciste antes con `WORKDIR /code`.

/// tip | Consejo

Revisa qu√© hace cada l√≠nea haciendo clic en cada n√∫mero en la burbuja del c√≥digo. üëÜ

///

/// warning | Advertencia

Aseg√∫rate de **siempre** usar la **forma exec** de la instrucci√≥n `CMD`, como se explica a continuaci√≥n.

///

#### Usar `CMD` - Forma Exec

La instrucci√≥n Docker <a href="https://docs.docker.com/reference/dockerfile/#cmd" class="external-link" target="_blank">`CMD`</a> se puede escribir usando dos formas:

‚úÖ **Forma Exec**:

```Dockerfile
# ‚úÖ Haz esto
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

‚õîÔ∏è **Forma Shell**:

```Dockerfile
# ‚õîÔ∏è No hagas esto
CMD fastapi run app/main.py --port 80
```

Aseg√∫rate de siempre usar la **forma exec** para garantizar que FastAPI pueda cerrarse de manera adecuada y que [los eventos de lifespan](../advanced/events.md){.internal-link target=_blank} sean disparados.

Puedes leer m√°s sobre esto en las <a href="https://docs.docker.com/reference/dockerfile/#shell-and-exec-form" class="external-link" target="_blank">documentaci√≥n de Docker para formas de shell y exec</a>.

Esto puede ser bastante notorio al usar `docker compose`. Consulta esta secci√≥n de preguntas frecuentes de Docker Compose para m√°s detalles t√©cnicos: <a href="https://docs.docker.com/compose/faq/#why-do-my-services-take-10-seconds-to-recreate-or-stop" class="external-link" target="_blank">¬øPor qu√© mis servicios tardan 10 segundos en recrearse o detenerse?</a>.

#### Estructura de Directorios

Ahora deber√≠as tener una estructura de directorios como:

```
.
‚îú‚îÄ‚îÄ app
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ requirements.txt
```

#### Detr√°s de un Proxy de Terminaci√≥n TLS

Si est√°s ejecutando tu contenedor detr√°s de un Proxy de Terminaci√≥n TLS (load balancer) como Nginx o Traefik, a√±ade la opci√≥n `--proxy-headers`, esto le dir√° a Uvicorn (a trav√©s de la CLI de FastAPI) que conf√≠e en los headers enviados por ese proxy indicando que la aplicaci√≥n se est√° ejecutando detr√°s de HTTPS, etc.

```Dockerfile
CMD ["fastapi", "run", "app/main.py", "--proxy-headers", "--port", "80"]
```

#### Cache de Docker

Hay un truco importante en este `Dockerfile`, primero copiamos **el archivo con las dependencias solo**, no el resto del c√≥digo. D√©jame decirte por qu√© es as√≠.

```Dockerfile
COPY ./requirements.txt /code/requirements.txt
```

Docker y otras herramientas **construyen** estas im√°genes de contenedor **incrementalmente**, a√±adiendo **una capa sobre la otra**, empezando desde la parte superior del `Dockerfile` y a√±adiendo cualquier archivo creado por cada una de las instrucciones del `Dockerfile`.

Docker y herramientas similares tambi√©n usan una **cach√© interna** al construir la imagen, si un archivo no ha cambiado desde la √∫ltima vez que se construy√≥ la imagen del contenedor, entonces reutilizar√° la misma capa creada la √∫ltima vez, en lugar de copiar el archivo de nuevo y crear una nueva capa desde cero.

Solo evitar copiar archivos no mejora necesariamente las cosas mucho, pero porque se us√≥ la cach√© para ese paso, puede **usar la cach√© para el siguiente paso**. Por ejemplo, podr√≠a usar la cach√© para la instrucci√≥n que instala las dependencias con:

```Dockerfile
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt
```

El archivo con los requisitos de los paquetes **no cambiar√° con frecuencia**. As√≠ que, al copiar solo ese archivo, Docker podr√° **usar la cach√©** para ese paso.

Y luego, Docker podr√° **usar la cach√© para el siguiente paso** que descarga e instala esas dependencias. Y aqu√≠ es donde **ahorramos mucho tiempo**. ‚ú® ...y evitamos el aburrimiento de esperar. üò™üòÜ

Descargar e instalar las dependencias de los paquetes **podr√≠a llevar minutos**, pero usando la **cach√©** tomar√≠a **segundos** como m√°ximo.

Y como estar√≠as construyendo la imagen del contenedor una y otra vez durante el desarrollo para comprobar que los cambios en tu c√≥digo funcionan, hay una gran cantidad de tiempo acumulado que te ahorrar√≠as.

Luego, cerca del final del `Dockerfile`, copiamos todo el c√≥digo. Como esto es lo que **cambia con m√°s frecuencia**, lo ponemos cerca del final, porque casi siempre, cualquier cosa despu√©s de este paso no podr√° usar la cach√©.

```Dockerfile
COPY ./app /code/app
```

### Construir la Imagen de Docker

Ahora que todos los archivos est√°n en su lugar, vamos a construir la imagen del contenedor.

* Ve al directorio del proyecto (donde est√° tu `Dockerfile`, conteniendo tu directorio `app`).
* Construye tu imagen de FastAPI:

<div class="termy">

```console
$ docker build -t myimage .

---> 100%
```

</div>

/// tip | Consejo

F√≠jate en el `.` al final, es equivalente a `./`, le indica a Docker el directorio a usar para construir la imagen del contenedor.

En este caso, es el mismo directorio actual (`.`).

///

### Iniciar el Contenedor Docker

* Ejecuta un contenedor basado en tu imagen:

<div class="termy">

```console
$ docker run -d --name mycontainer -p 80:80 myimage
```

</div>

## Rev√≠salo

Deber√≠as poder revisarlo en la URL de tu contenedor de Docker, por ejemplo: <a href="http://192.168.99.100/items/5?q=somequery" class="external-link" target="_blank">http://192.168.99.100/items/5?q=somequery</a> o <a href="http://127.0.0.1/items/5?q=somequery" class="external-link" target="_blank">http://127.0.0.1/items/5?q=somequery</a> (o equivalente, usando tu host de Docker).

Ver√°s algo como:

```JSON
{"item_id": 5, "q": "somequery"}
```

## Documentaci√≥n Interactiva de la API

Ahora puedes ir a <a href="http://192.168.99.100/docs" class="external-link" target="_blank">http://192.168.99.100/docs</a> o <a href="http://127.0.0.1/docs" class="external-link" target="_blank">http://127.0.0.1/docs</a> (o equivalente, usando tu host de Docker).

Ver√°s la documentaci√≥n interactiva autom√°tica de la API (proporcionada por <a href="https://github.com/swagger-api/swagger-ui" class="external-link" target="_blank">Swagger UI</a>):

![Swagger UI](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)

## Documentaci√≥n Alternativa de la API

Y tambi√©n puedes ir a <a href="http://192.168.99.100/redoc" class="external-link" target="_blank">http://192.168.99.100/redoc</a> o <a href="http://127.0.0.1/redoc" class="external-link" target="_blank">http://127.0.0.1/redoc</a> (o equivalente, usando tu host de Docker).

Ver√°s la documentaci√≥n alternativa autom√°tica (proporcionada por <a href="https://github.com/Rebilly/ReDoc" class="external-link" target="_blank">ReDoc</a>):

![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)

## Construir una Imagen de Docker con un FastAPI de Un Solo Archivo

Si tu FastAPI es un solo archivo, por ejemplo, `main.py` sin un directorio `./app`, tu estructura de archivos podr√≠a verse as√≠:

```
.
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ requirements.txt
```

Entonces solo tendr√≠as que cambiar las rutas correspondientes para copiar el archivo dentro del `Dockerfile`:

```{ .dockerfile .annotate hl_lines="10  13" }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (1)!
COPY ./main.py /code/

# (2)!
CMD ["fastapi", "run", "main.py", "--port", "80"]
```

1. Copia el archivo `main.py` directamente al directorio `/code` (sin ning√∫n directorio `./app`).

2. Usa `fastapi run` para servir tu aplicaci√≥n en el archivo √∫nico `main.py`.

Cuando pasas el archivo a `fastapi run`, detectar√° autom√°ticamente que es un archivo √∫nico y no parte de un paquete y sabr√° c√≥mo importarlo y servir tu aplicaci√≥n FastAPI. üòé

## Conceptos de Despliegue

Hablemos nuevamente de algunos de los mismos [Conceptos de Despliegue](concepts.md){.internal-link target=_blank} en t√©rminos de contenedores.

Los contenedores son principalmente una herramienta para simplificar el proceso de **construcci√≥n y despliegue** de una aplicaci√≥n, pero no imponen un enfoque particular para manejar estos **conceptos de despliegue**, y hay varias estrategias posibles.

La **buena noticia** es que con cada estrategia diferente hay una forma de cubrir todos los conceptos de despliegue. üéâ

Revisemos estos **conceptos de despliegue** en t√©rminos de contenedores:

* HTTPS
* Ejecutar en el inicio
* Reinicios
* Replicaci√≥n (el n√∫mero de procesos en ejecuci√≥n)
* Memoria
* Pasos previos antes de comenzar

## HTTPS

Si nos enfocamos solo en la **imagen de contenedor** para una aplicaci√≥n FastAPI (y luego el **contenedor** en ejecuci√≥n), HTTPS normalmente ser√≠a manejado **externamente** por otra herramienta.

Podr√≠a ser otro contenedor, por ejemplo, con <a href="https://traefik.io/" class="external-link" target="_blank">Traefik</a>, manejando **HTTPS** y la adquisici√≥n **autom√°tica** de **certificados**.

/// tip | Consejo

Traefik tiene integraciones con Docker, Kubernetes, y otros, por lo que es muy f√°cil configurar y configurar HTTPS para tus contenedores con √©l.

///

Alternativamente, HTTPS podr√≠a ser manejado por un proveedor de la nube como uno de sus servicios (mientras que la aplicaci√≥n a√∫n se ejecuta en un contenedor).

## Ejecutar en el Inicio y Reinicios

Normalmente hay otra herramienta encargada de **iniciar y ejecutar** tu contenedor.

Podr√≠a ser **Docker** directamente, **Docker Compose**, **Kubernetes**, un **servicio en la nube**, etc.

En la mayor√≠a (o todas) de las casos, hay una opci√≥n sencilla para habilitar la ejecuci√≥n del contenedor al inicio y habilitar los reinicios en caso de fallos. Por ejemplo, en Docker, es la opci√≥n de l√≠nea de comandos `--restart`.

Sin usar contenedores, hacer que las aplicaciones se ejecuten al inicio y con reinicios puede ser engorroso y dif√≠cil. Pero al **trabajar con contenedores** en la mayor√≠a de los casos, esa funcionalidad se incluye por defecto. ‚ú®

## Replicaci√≥n - N√∫mero de Procesos

Si tienes un <abbr title="Un grupo de m√°quinas que est√°n configuradas para estar conectadas y trabajar juntas de alguna manera.">cluster</abbr> de m√°quinas con **Kubernetes**, Docker Swarm Mode, Nomad, u otro sistema complejo similar para gestionar contenedores distribuidos en varias m√°quinas, entonces probablemente querr√°s manejar la **replicaci√≥n** a nivel de **cluster** en lugar de usar un **gestor de procesos** (como Uvicorn con workers) en cada contenedor.

Uno de esos sistemas de gesti√≥n de contenedores distribuidos como Kubernetes normalmente tiene alguna forma integrada de manejar la **replicaci√≥n de contenedores** mientras a√∫n soporta el **load balancing** para las requests entrantes. Todo a nivel de **cluster**.

En esos casos, probablemente desear√≠as construir una **imagen de Docker desde cero** como se [explica arriba](#dockerfile), instalando tus dependencias, y ejecutando **un solo proceso de Uvicorn** en lugar de usar m√∫ltiples workers de Uvicorn.

### Load Balancer

Al usar contenedores, normalmente tendr√≠as alg√∫n componente **escuchando en el puerto principal**. Podr√≠a posiblemente ser otro contenedor que es tambi√©n un **Proxy de Terminaci√≥n TLS** para manejar **HTTPS** o alguna herramienta similar.

Como este componente tomar√≠a la **carga** de las requests y las distribuir√≠a entre los workers de una manera (esperablemente) **balanceada**, tambi√©n se le llama com√∫nmente **Load Balancer**.

/// tip | Consejo

El mismo componente **Proxy de Terminaci√≥n TLS** usado para HTTPS probablemente tambi√©n ser√≠a un **Load Balancer**.

///

Y al trabajar con contenedores, el mismo sistema que usas para iniciarlos y gestionarlos ya tendr√≠a herramientas internas para transmitir la **comunicaci√≥n en red** (e.g., requests HTTP) desde ese **load balancer** (que tambi√©n podr√≠a ser un **Proxy de Terminaci√≥n TLS**) a los contenedores con tu aplicaci√≥n.

### Un Load Balancer - M√∫ltiples Contenedores Worker

Al trabajar con **Kubernetes** u otros sistemas de gesti√≥n de contenedores distribuidos similares, usar sus mecanismos de red internos permitir√≠a que el √∫nico **load balancer** que est√° escuchando en el **puerto** principal transmita la comunicaci√≥n (requests) a posiblemente **m√∫ltiples contenedores** ejecutando tu aplicaci√≥n.

Cada uno de estos contenedores ejecutando tu aplicaci√≥n normalmente tendr√≠a **solo un proceso** (e.g., un proceso Uvicorn ejecutando tu aplicaci√≥n FastAPI). Todos ser√≠an **contenedores id√©nticos**, ejecutando lo mismo, pero cada uno con su propio proceso, memoria, etc. De esa forma, aprovechar√≠as la **paralelizaci√≥n** en **diferentes n√∫cleos** de la CPU, o incluso en **diferentes m√°quinas**.

Y el sistema de contenedores distribuido con el **load balancer** **distribuir√≠a las requests** a cada uno de los contenedores **replicados** que ejecutan tu aplicaci√≥n **en turnos**. As√≠, cada request podr√≠a ser manejado por uno de los m√∫ltiples **contenedores replicados** ejecutando tu aplicaci√≥n.

Y normalmente este **load balancer** podr√≠a manejar requests que vayan a *otras* aplicaciones en tu cluster (p. ej., a un dominio diferente, o bajo un prefijo de ruta de URL diferente), y transmitir√≠a esa comunicaci√≥n a los contenedores correctos para *esa otra* aplicaci√≥n ejecut√°ndose en tu cluster.

### Un Proceso por Contenedor

En este tipo de escenario, probablemente querr√≠as tener **un solo proceso (Uvicorn) por contenedor**, ya que ya estar√≠as manejando la replicaci√≥n a nivel de cluster.

As√≠ que, en este caso, **no** querr√≠as tener m√∫ltiples workers en el contenedor, por ejemplo, con la opci√≥n de l√≠nea de comandos `--workers`. Querr√≠as tener solo un **proceso Uvicorn por contenedor** (pero probablemente m√∫ltiples contenedores).

Tener otro gestor de procesos dentro del contenedor (como ser√≠a con m√∫ltiples workers) solo a√±adir√≠a **complejidad innecesaria** que probablemente ya est√©s manejando con tu sistema de cluster.

### Contenedores con M√∫ltiples Procesos y Casos Especiales

Por supuesto, hay **casos especiales** donde podr√≠as querer tener **un contenedor** con varios **worker processes de Uvicorn** dentro.

En esos casos, puedes usar la opci√≥n de l√≠nea de comandos `--workers` para establecer el n√∫mero de workers que deseas ejecutar:

```{ .dockerfile .annotate }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

# (1)!
CMD ["fastapi", "run", "app/main.py", "--port", "80", "--workers", "4"]
```

1. Aqu√≠ usamos la opci√≥n de l√≠nea de comandos `--workers` para establecer el n√∫mero de workers a 4.

Aqu√≠ hay algunos ejemplos de cu√°ndo eso podr√≠a tener sentido:

#### Una Aplicaci√≥n Simple

Podr√≠as querer un gestor de procesos en el contenedor si tu aplicaci√≥n es **lo suficientemente simple** que pueda ejecutarse en un **servidor √∫nico**, no un cluster.

#### Docker Compose

Podr√≠as estar desplegando en un **servidor √∫nico** (no un cluster) con **Docker Compose**, por lo que no tendr√≠as una forma f√°cil de gestionar la replicaci√≥n de contenedores (con Docker Compose) mientras se preserva la red compartida y el **load balancing**.

Entonces podr√≠as querer tener **un solo contenedor** con un **gestor de procesos** iniciando **varios worker processes** dentro.

---

El punto principal es que, **ninguna** de estas son **reglas escritas en piedra** que debas seguir a ciegas. Puedes usar estas ideas para **evaluar tu propio caso de uso** y decidir cu√°l es el mejor enfoque para tu sistema, verificando c√≥mo gestionar los conceptos de:

* Seguridad - HTTPS
* Ejecutar en el inicio
* Reinicios
* Replicaci√≥n (el n√∫mero de procesos en ejecuci√≥n)
* Memoria
* Pasos previos antes de comenzar

## Memoria

Si ejecutas **un solo proceso por contenedor**, tendr√°s una cantidad de memoria m√°s o menos bien definida, estable y limitada consumida por cada uno de esos contenedores (m√°s de uno si est√°n replicados).

Y luego puedes establecer esos mismos l√≠mites de memoria y requisitos en tus configuraciones para tu sistema de gesti√≥n de contenedores (por ejemplo, en **Kubernetes**). De esa manera, podr√° **replicar los contenedores** en las **m√°quinas disponibles** teniendo en cuenta la cantidad de memoria necesaria por ellos, y la cantidad disponible en las m√°quinas en el cluster.

Si tu aplicaci√≥n es **simple**, probablemente esto **no ser√° un problema**, y puede que no necesites especificar l√≠mites de memoria estrictos. Pero si est√°s **usando mucha memoria** (por ejemplo, con modelos de **Machine Learning**), deber√≠as verificar cu√°nta memoria est√°s consumiendo y ajustar el **n√∫mero de contenedores** que se ejecutan en **cada m√°quina** (y tal vez agregar m√°s m√°quinas a tu cluster).

Si ejecutas **m√∫ltiples procesos por contenedor**, tendr√°s que asegurarte de que el n√∫mero de procesos iniciados no **consuma m√°s memoria** de la que est√° disponible.

## Pasos Previos Antes de Comenzar y Contenedores

Si est√°s usando contenedores (por ejemplo, Docker, Kubernetes), entonces hay dos enfoques principales que puedes usar.

### M√∫ltiples Contenedores

Si tienes **m√∫ltiples contenedores**, probablemente cada uno ejecutando un **proceso √∫nico** (por ejemplo, en un cluster de **Kubernetes**), entonces probablemente querr√≠as tener un **contenedor separado** realizando el trabajo de los **pasos previos** en un solo contenedor, ejecutando un solo proceso, **antes** de ejecutar los contenedores worker replicados.

/// info | Informaci√≥n

Si est√°s usando Kubernetes, probablemente ser√≠a un <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" class="external-link" target="_blank">Contenedor de Inicializaci√≥n</a>.

///

Si en tu caso de uso no hay problema en ejecutar esos pasos previos **m√∫ltiples veces en paralelo** (por ejemplo, si no est√°s ejecutando migraciones de base de datos, sino simplemente verificando si la base de datos est√° lista), entonces tambi√©n podr√≠as simplemente ponerlos en cada contenedor justo antes de iniciar el proceso principal.

### Un Contenedor √önico

Si tienes una configuraci√≥n simple, con un **contenedor √∫nico** que luego inicia m√∫ltiples **worker processes** (o tambi√©n solo un proceso), entonces podr√≠as ejecutar esos pasos previos en el mismo contenedor, justo antes de iniciar el proceso con la aplicaci√≥n.

### Imagen Base de Docker

Sol√≠a haber una imagen official de Docker de FastAPI: <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>. Pero ahora est√° obsoleta. ‚õîÔ∏è

Probablemente **no** deber√≠as usar esta imagen base de Docker (o cualquier otra similar).

Si est√°s usando **Kubernetes** (u otros) y ya est√°s configurando la **replicaci√≥n** a nivel de cluster, con m√∫ltiples **contenedores**. En esos casos, es mejor que **construyas una imagen desde cero** como se describe arriba: [Construir una Imagen de Docker para FastAPI](#build-a-docker-image-for-fastapi).

Y si necesitas tener m√∫ltiples workers, puedes simplemente utilizar la opci√≥n de l√≠nea de comandos `--workers`.

/// note | Detalles T√©cnicos

La imagen de Docker se cre√≥ cuando Uvicorn no soportaba gestionar y reiniciar workers muertos, por lo que era necesario usar Gunicorn con Uvicorn, lo que a√±ad√≠a bastante complejidad, solo para que Gunicorn gestionara y reiniciara los worker processes de Uvicorn.

Pero ahora que Uvicorn (y el comando `fastapi`) soportan el uso de `--workers`, no hay raz√≥n para utilizar una imagen base de Docker en lugar de construir la tuya propia (es pr√°cticamente la misma cantidad de c√≥digo üòÖ).

///

## Desplegar la Imagen del Contenedor

Despu√©s de tener una Imagen de Contenedor (Docker) hay varias maneras de desplegarla.

Por ejemplo:

* Con **Docker Compose** en un servidor √∫nico
* Con un cluster de **Kubernetes**
* Con un cluster de Docker Swarm Mode
* Con otra herramienta como Nomad
* Con un servicio en la nube que tome tu imagen de contenedor y la despliegue

## Imagen de Docker con `uv`

Si est√°s usando <a href="https://github.com/astral-sh/uv" class="external-link" target="_blank">uv</a> para instalar y gestionar tu proyecto, puedes seguir su <a href="https://docs.astral.sh/uv/guides/integration/docker/" class="external-link" target="_blank">gu√≠a de Docker de uv</a>.

## Resumen

Usando sistemas de contenedores (por ejemplo, con **Docker** y **Kubernetes**) se vuelve bastante sencillo manejar todos los **conceptos de despliegue**:

* HTTPS
* Ejecutar en el inicio
* Reinicios
* Replicaci√≥n (el n√∫mero de procesos en ejecuci√≥n)
* Memoria
* Pasos previos antes de comenzar

En la mayor√≠a de los casos, probablemente no querr√°s usar ninguna imagen base, y en su lugar **construir una imagen de contenedor desde cero** basada en la imagen oficial de Docker de Python.

Teniendo en cuenta el **orden** de las instrucciones en el `Dockerfile` y la **cach√© de Docker** puedes **minimizar los tiempos de construcci√≥n**, para maximizar tu productividad (y evitar el aburrimiento). üòé
