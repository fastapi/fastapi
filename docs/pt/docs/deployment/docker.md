# FastAPI em contÃªineres - Docker { #fastapi-in-containers-docker }

Ao fazer o deploy de aplicaÃ§Ãµes FastAPI uma abordagem comum Ã© construir uma **imagem de contÃªiner Linux**. Isso normalmente Ã© feito usando o <a href="https://www.docker.com/" class="external-link" target="_blank">**Docker**</a>. VocÃª pode a partir disso fazer o deploy dessa imagem de algumas maneiras.

Usando contÃªineres Linux vocÃª tem diversas vantagens incluindo **seguranÃ§a**, **replicabilidade**, **simplicidade**, entre outras.

/// tip | Dica

EstÃ¡ com pressa e jÃ¡ sabe dessas coisas? Pode ir direto para o [`Dockerfile` abaixo ğŸ‘‡](#build-a-docker-image-for-fastapi).

///

<details>
<summary>VisualizaÃ§Ã£o do Dockerfile ğŸ‘€</summary>

```Dockerfile
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

CMD ["fastapi", "run", "app/main.py", "--port", "80"]

# Se estiver executando atrÃ¡s de um proxy como Nginx ou Traefik, adicione --proxy-headers
# CMD ["fastapi", "run", "app/main.py", "--port", "80", "--proxy-headers"]
```

</details>

## O que Ã© um ContÃªiner { #what-is-a-container }

ContÃªineres (principalmente contÃªineres Linux) sÃ£o um jeito muito **leve** de empacotar aplicaÃ§Ãµes contendo todas as dependÃªncias e arquivos necessÃ¡rios enquanto os mantÃ©m isolados de outros contÃªineres (outras aplicaÃ§Ãµes ou componentes) no mesmo sistema.

ContÃªineres Linux rodam usando o mesmo kernel Linux do hospedeiro (mÃ¡quina, mÃ¡quina virtual, servidor na nuvem, etc). Isso simplesmente significa que eles sÃ£o muito leves (comparados com mÃ¡quinas virtuais emulando um sistema operacional completo).

Dessa forma, contÃªineres consomem **poucos recursos**, uma quantidade comparÃ¡vel com rodar os processos diretamente (uma mÃ¡quina virtual consumiria muito mais).

ContÃªineres tambÃ©m possuem seus prÃ³prios processos em execuÃ§Ã£o (comumente **um Ãºnico processo**), sistema de arquivos e rede **isolados**, simplificando deploy, seguranÃ§a, desenvolvimento, etc.

## O que Ã© uma Imagem de ContÃªiner { #what-is-a-container-image }

Um **contÃªiner** roda a partir de uma **imagem de contÃªiner**.

Uma imagem de contÃªiner Ã© uma versÃ£o **estÃ¡tica** de todos os arquivos, variÃ¡veis de ambiente e do comando/programa padrÃ£o que deve estar presente num contÃªiner. **EstÃ¡tica** aqui significa que a **imagem** de contÃªiner nÃ£o estÃ¡ rodando, nÃ£o estÃ¡ sendo executada, somente contÃ©m os arquivos e metadados empacotados.

Em contraste com a "**imagem de contÃªiner**" que contÃ©m os conteÃºdos estÃ¡ticos armazenados, um "**contÃªiner**" normalmente se refere Ã  instÃ¢ncia rodando, a coisa que estÃ¡ sendo **executada**.

Quando o **contÃªiner** Ã© iniciado e estÃ¡ rodando (iniciado a partir de uma **imagem de contÃªiner**), ele pode criar ou modificar arquivos, variÃ¡veis de ambiente, etc. Essas mudanÃ§as vÃ£o existir somente nesse contÃªiner, mas nÃ£o persistirÃ£o na imagem subjacente do container (nÃ£o serÃ£o salvas no disco).

Uma imagem de contÃªiner Ã© comparÃ¡vel ao arquivo de **programa** e seus conteÃºdos, ex.: `python` e algum arquivo `main.py`.

E o **contÃªiner** em si (em contraste Ã  **imagem de contÃªiner**) Ã© a prÃ³pria instÃ¢ncia da imagem rodando, comparÃ¡vel a um **processo**. Na verdade, um contÃªiner estÃ¡ rodando somente quando hÃ¡ um **processo rodando** (e normalmente Ã© somente um processo). O contÃªiner finaliza quando nÃ£o hÃ¡ um processo rodando nele.

## Imagens de contÃªiner { #container-images }

Docker tem sido uma das principais ferramentas para criar e gerenciar **imagens de contÃªiner** e **contÃªineres**.

E existe um <a href="https://hub.docker.com/" class="external-link" target="_blank">Docker Hub</a> pÃºblico com **imagens de contÃªiner oficiais** prÃ©-prontas para diversas ferramentas, ambientes, bancos de dados e aplicaÃ§Ãµes.

Por exemplo, hÃ¡ uma <a href="https://hub.docker.com/_/python" class="external-link" target="_blank">Imagem Python</a> oficial.

E existe muitas outras imagens para diferentes coisas, como bancos de dados, por exemplo:

* <a href="https://hub.docker.com/_/postgres" class="external-link" target="_blank">PostgreSQL</a>
* <a href="https://hub.docker.com/_/mysql" class="external-link" target="_blank">MySQL</a>
* <a href="https://hub.docker.com/_/mongo" class="external-link" target="_blank">MongoDB</a>
* <a href="https://hub.docker.com/_/redis" class="external-link" target="_blank">Redis</a>, etc.

Usando imagens de contÃªiner prÃ©-prontas Ã© muito fÃ¡cil **combinar** e usar diferentes ferramentas. Por exemplo, para testar um novo banco de dados. Em muitos casos, vocÃª pode usar as **imagens oficiais**, precisando somente de variÃ¡veis de ambiente para configurÃ¡-las.

Dessa forma, em muitos casos vocÃª pode aprender sobre contÃªineres e Docker e reusar essa experiÃªncia com diversos componentes e ferramentas.

EntÃ£o, vocÃª rodaria **vÃ¡rios contÃªineres** com coisas diferentes, como um banco de dados, uma aplicaÃ§Ã£o Python, um servidor web com uma aplicaÃ§Ã£o frontend React, e conectÃ¡-los juntos via sua rede interna.

Todos os sistemas de gerenciamento de contÃªineres (como Docker ou Kubernetes) possuem essas funcionalidades de rede integradas a eles.

## ContÃªineres e Processos { #containers-and-processes }

Uma **imagem de contÃªiner** normalmente inclui em seus metadados o programa padrÃ£o ou comando que deve ser executado quando o **contÃªiner** Ã© iniciado e os parÃ¢metros a serem passados para esse programa. Muito similar ao que seria se estivesse na linha de comando.

Quando um **contÃªiner** Ã© iniciado, ele irÃ¡ rodar esse comando/programa (embora vocÃª possa sobrescrevÃª-lo e fazer com que ele rode um comando/programa diferente).

Um contÃªiner estÃ¡ rodando enquanto o **processo principal** (comando ou programa) estiver rodando.

Um contÃªiner normalmente tem um **Ãºnico processo**, mas tambÃ©m Ã© possÃ­vel iniciar sub-processos a partir do processo principal, e dessa forma vocÃª terÃ¡ **vÃ¡rios processos** no mesmo contÃªiner.

Mas nÃ£o Ã© possÃ­vel ter um contÃªiner rodando sem **pelo menos um processo rodando**. Se o processo principal parar, o contÃªiner tambÃ©m para.

## Construir uma Imagem Docker para FastAPI { #build-a-docker-image-for-fastapi }

Okay, vamos construir algo agora! ğŸš€

Eu vou mostrar como construir uma **imagem Docker** para FastAPI **do zero**, baseada na imagem **oficial do Python**.

Isso Ã© o que vocÃª quer fazer na **maioria dos casos**, por exemplo:

* Usando **Kubernetes** ou ferramentas similares
* Quando rodando em uma **Raspberry Pi**
* Usando um serviÃ§o em nuvem que irÃ¡ rodar uma imagem de contÃªiner para vocÃª, etc.

### Requisitos de Pacotes { #package-requirements }

VocÃª normalmente teria os **requisitos de pacotes** da sua aplicaÃ§Ã£o em algum arquivo.

Isso pode depender principalmente da ferramenta que vocÃª usa para **instalar** esses requisitos.

A forma mais comum de fazer isso Ã© ter um arquivo `requirements.txt` com os nomes dos pacotes e suas versÃµes, um por linha.

VocÃª, naturalmente, usaria as mesmas ideias que vocÃª leu em [Sobre versÃµes do FastAPI](versions.md){.internal-link target=_blank} para definir os intervalos de versÃµes.

Por exemplo, seu `requirements.txt` poderia parecer com:

```
fastapi[standard]>=0.113.0,<0.114.0
pydantic>=2.7.0,<3.0.0
```

E vocÃª normalmente instalaria essas dependÃªncias de pacote com `pip`, por exemplo:

<div class="termy">

```console
$ pip install -r requirements.txt
---> 100%
Successfully installed fastapi pydantic
```

</div>

/// info | InformaÃ§Ã£o

HÃ¡ outros formatos e ferramentas para definir e instalar dependÃªncias de pacotes.

///

### Crie o cÃ³digo do **FastAPI** { #create-the-fastapi-code }

* Crie um diretÃ³rio `app` e entre nele.
* Crie um arquivo vazio `__init__.py`.
* Crie um arquivo `main.py` com:

```Python
from typing import Union

from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}
```

### Dockerfile { #dockerfile }

Agora, no mesmo diretÃ³rio do projeto, crie um arquivo `Dockerfile` com:

```{ .dockerfile .annotate }
# (1)!
FROM python:3.9

# (2)!
WORKDIR /code

# (3)!
COPY ./requirements.txt /code/requirements.txt

# (4)!
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (5)!
COPY ./app /code/app

# (6)!
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

1. Inicie a partir da imagem base oficial do Python.

2. Defina o diretÃ³rio de trabalho atual para `/code`.

    Esse Ã© o diretÃ³rio onde colocaremos o arquivo `requirements.txt` e o diretÃ³rio `app`.

3. Copie o arquivo com os requisitos para o diretÃ³rio `/code`.

    Copie **somente** o arquivo com os requisitos primeiro, nÃ£o o resto do cÃ³digo.

    Como esse arquivo **nÃ£o muda com frequÃªncia**, o Docker irÃ¡ detectÃ¡-lo e usar o **cache** para esse passo, habilitando o cache para o prÃ³ximo passo tambÃ©m.

4. Instale as dependÃªncias de pacote vindas do arquivo de requisitos.

    A opÃ§Ã£o `--no-cache-dir` diz ao `pip` para nÃ£o salvar os pacotes baixados localmente, pois isso sÃ³ aconteceria se `pip` fosse executado novamente para instalar os mesmos pacotes, mas esse nÃ£o Ã© o caso quando trabalhamos com contÃªineres.

    /// note | Nota

    `--no-cache-dir` Ã© apenas relacionado ao `pip`, nÃ£o tem nada a ver com Docker ou contÃªineres.

    ///

    A opÃ§Ã£o `--upgrade` diz ao `pip` para atualizar os pacotes se eles jÃ¡ estiverem instalados.

    Por causa do passo anterior de copiar o arquivo, ele pode ser detectado pelo **cache do Docker**, esse passo tambÃ©m **usarÃ¡ o cache do Docker** quando disponÃ­vel.

    Usando o cache nesse passo irÃ¡ **salvar** muito **tempo** quando vocÃª for construir a imagem repetidas vezes durante o desenvolvimento, ao invÃ©s de **baixar e instalar** todas as dependÃªncias **toda vez**.

5. Copie o diretÃ³rio `./app` dentro do diretÃ³rio `/code`.

    Como isso tem todo o cÃ³digo contendo o que **muda com mais frequÃªncia**, o **cache do Docker** nÃ£o serÃ¡ usado para esse passo ou para **qualquer passo seguinte** facilmente.

    EntÃ£o, Ã© importante colocar isso **perto do final** do `Dockerfile`, para otimizar o tempo de construÃ§Ã£o da imagem do contÃªiner.

6. Defina o **comando** para usar `fastapi run`, que utiliza o Uvicorn por baixo dos panos.

    `CMD` recebe uma lista de strings, cada uma dessas strings Ã© o que vocÃª digitaria na linha de comando separado por espaÃ§os.

    Esse comando serÃ¡ executado a partir do **diretÃ³rio de trabalho atual**, o mesmo diretÃ³rio `/code` que vocÃª definiu acima com `WORKDIR /code`.

/// tip | Dica

Revise o que cada linha faz clicando em cada bolha com o nÃºmero no cÃ³digo. ğŸ‘†

///

/// warning | AtenÃ§Ã£o

Certifique-se de **sempre** usar a **forma exec** da instruÃ§Ã£o `CMD`, como explicado abaixo.

///

#### Use `CMD` - Forma Exec { #use-cmd-exec-form }

A instruÃ§Ã£o <a href="https://docs.docker.com/reference/dockerfile/#cmd" class="external-link" target="_blank">`CMD`</a> no Docker pode ser escrita de duas formas:

âœ… Forma **Exec**:

```Dockerfile
# âœ… FaÃ§a assim
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

â›”ï¸ Forma **Shell**:

```Dockerfile
# â›”ï¸ NÃ£o faÃ§a assim
CMD fastapi run app/main.py --port 80
```

Garanta que vocÃª sempre use a forma **exec** para assegurar que o FastAPI consiga encerrar graciosamente e que os [eventos de lifespan](../advanced/events.md){.internal-link target=_blank} sejam disparados.

VocÃª pode ler mais na <a href="https://docs.docker.com/reference/dockerfile/#shell-and-exec-form" class="external-link" target="_blank">documentaÃ§Ã£o do Docker sobre as formas shell e exec</a>.

Isso pode ser bem perceptÃ­vel ao usar `docker compose`. Veja esta seÃ§Ã£o de FAQ do Docker Compose para mais detalhes tÃ©cnicos: <a href="https://docs.docker.com/compose/faq/#why-do-my-services-take-10-seconds-to-recreate-or-stop" class="external-link" target="_blank">Por que meus serviÃ§os demoram 10 segundos para recriar ou parar?</a>.

#### Estrutura de diretÃ³rios { #directory-structure }

Agora vocÃª deve haver uma estrutura de diretÃ³rio como:

```
.
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

#### Por trÃ¡s de um Proxy de TerminaÃ§Ã£o TLS { #behind-a-tls-termination-proxy }

Se vocÃª estÃ¡ executando seu contÃªiner atrÃ¡s de um Proxy de TerminaÃ§Ã£o TLS (load balancer) como Nginx ou Traefik, adicione a opÃ§Ã£o `--proxy-headers`, isso farÃ¡ com que o Uvicorn (pela CLI do FastAPI) confie nos cabeÃ§alhos enviados por esse proxy, informando que o aplicativo estÃ¡ sendo executado atrÃ¡s do HTTPS, etc.

```Dockerfile
CMD ["fastapi", "run", "app/main.py", "--proxy-headers", "--port", "80"]
```

#### Cache Docker { #docker-cache }

Existe um truque importante nesse `Dockerfile`, primeiro copiamos o **arquivo com as dependÃªncias sozinho**, nÃ£o o resto do cÃ³digo. Deixe-me te contar o porquÃª disso.

```Dockerfile
COPY ./requirements.txt /code/requirements.txt
```

Docker e outras ferramentas **constrÃ³em** essas imagens de contÃªiner **incrementalmente**, adicionando **uma camada em cima da outra**, comeÃ§ando do topo do `Dockerfile` e adicionando qualquer arquivo criado por cada uma das instruÃ§Ãµes do `Dockerfile`.

Docker e ferramentas similares tambÃ©m usam um **cache interno** ao construir a imagem, se um arquivo nÃ£o mudou desde a Ãºltima vez que a imagem do contÃªiner foi construÃ­da, entÃ£o ele irÃ¡ **reutilizar a mesma camada** criada na Ãºltima vez, ao invÃ©s de copiar o arquivo novamente e criar uma nova camada do zero.

Somente evitar a cÃ³pia de arquivos nÃ£o melhora muito as coisas, mas porque ele usou o cache para esse passo, ele pode **usar o cache para o prÃ³ximo passo**. Por exemplo, ele pode usar o cache para a instruÃ§Ã£o que instala as dependÃªncias com:

```Dockerfile
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt
```

O arquivo com os requisitos de pacote **nÃ£o muda com frequÃªncia**. EntÃ£o, ao copiar apenas esse arquivo, o Docker serÃ¡ capaz de **usar o cache** para esse passo.

E entÃ£o, o Docker serÃ¡ capaz de **usar o cache para o prÃ³ximo passo** que baixa e instala essas dependÃªncias. E Ã© aqui que **salvamos muito tempo**. âœ¨ ...e evitamos tÃ©dio esperando. ğŸ˜ªğŸ˜†

Baixar e instalar as dependÃªncias do pacote **pode levar minutos**, mas usando o **cache** leva **segundos** no mÃ¡ximo.

E como vocÃª estaria construindo a imagem do contÃªiner novamente e novamente durante o desenvolvimento para verificar se suas alteraÃ§Ãµes de cÃ³digo estÃ£o funcionando, hÃ¡ muito tempo acumulado que isso economizaria.

A partir daÃ­, perto do final do `Dockerfile`, copiamos todo o cÃ³digo. Como isso Ã© o que **muda com mais frequÃªncia**, colocamos perto do final, porque quase sempre, qualquer coisa depois desse passo nÃ£o serÃ¡ capaz de usar o cache.

```Dockerfile
COPY ./app /code/app
```

### Construa a Imagem Docker { #build-the-docker-image }

Agora que todos os arquivos estÃ£o no lugar, vamos construir a imagem do contÃªiner.

* VÃ¡ para o diretÃ³rio do projeto (onde estÃ¡ o seu `Dockerfile`, contendo o diretÃ³rio `app`).
* Construa sua imagem FastAPI:

<div class="termy">

```console
$ docker build -t myimage .

---> 100%
```

</div>

/// tip | Dica

Note o `.` no final, Ã© equivalente a `./`, ele diz ao Docker o diretÃ³rio a ser usado para construir a imagem do contÃªiner.

Nesse caso, Ã© o mesmo diretÃ³rio atual (`.`).

///

### Inicie o ContÃªiner Docker { #start-the-docker-container }

* Execute um contÃªiner baseado na sua imagem:

<div class="termy">

```console
$ docker run -d --name mycontainer -p 80:80 myimage
```

</div>

## Verifique { #check-it }

VocÃª deve ser capaz de verificar isso no URL do seu contÃªiner Docker, por exemplo: <a href="http://192.168.99.100/items/5?q=somequery" class="external-link" target="_blank">http://192.168.99.100/items/5?q=somequery</a> ou <a href="http://127.0.0.1/items/5?q=somequery" class="external-link" target="_blank">http://127.0.0.1/items/5?q=somequery</a> (ou equivalente, usando seu host Docker).

VocÃª verÃ¡ algo como:

```JSON
{"item_id": 5, "q": "somequery"}
```

## DocumentaÃ§Ã£o interativa da API { #interactive-api-docs }

Agora vocÃª pode ir para <a href="http://192.168.99.100/docs" class="external-link" target="_blank">http://192.168.99.100/docs</a> ou <a href="http://127.0.0.1/docs" class="external-link" target="_blank">http://127.0.0.1/docs</a> (ou equivalente, usando seu host Docker).

VocÃª verÃ¡ a documentaÃ§Ã£o interativa automÃ¡tica da API (fornecida pelo <a href="https://github.com/swagger-api/swagger-ui" class="external-link" target="_blank">Swagger UI</a>):

![Swagger UI](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)

## DocumentaÃ§Ã£o alternativa da API { #alternative-api-docs }

E vocÃª tambÃ©m pode ir para <a href="http://192.168.99.100/redoc" class="external-link" target="_blank">http://192.168.99.100/redoc</a> ou <a href="http://127.0.0.1/redoc" class="external-link" target="_blank">http://127.0.0.1/redoc</a> (ou equivalente, usando seu host Docker).

VocÃª verÃ¡ a documentaÃ§Ã£o alternativa automÃ¡tica (fornecida pela <a href="https://github.com/Rebilly/ReDoc" class="external-link" target="_blank">ReDoc</a>):

![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)

## Construa uma Imagem Docker com um FastAPI de Arquivo Ãšnico { #build-a-docker-image-with-a-single-file-fastapi }

Se seu FastAPI for um Ãºnico arquivo, por exemplo, `main.py` sem um diretÃ³rio `./app`, sua estrutura de arquivos poderia ser assim:

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt
```

EntÃ£o vocÃª sÃ³ teria que alterar os caminhos correspondentes para copiar o arquivo dentro do `Dockerfile`:

```{ .dockerfile .annotate hl_lines="10  13" }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (1)!
COPY ./main.py /code/

# (2)!
CMD ["fastapi", "run", "main.py", "--port", "80"]
```

1. Copie o arquivo `main.py` para o diretÃ³rio `/code` diretamente (sem nenhum diretÃ³rio `./app`).

2. Use `fastapi run` para servir sua aplicaÃ§Ã£o no arquivo Ãºnico `main.py`.

Quando vocÃª passa o arquivo para `fastapi run` ele detecta automaticamente que Ã© um arquivo Ãºnico e nÃ£o parte de um pacote e sabe como importÃ¡-lo e servir sua aplicaÃ§Ã£o FastAPI. ğŸ˜

## Conceitos de ImplantaÃ§Ã£o { #deployment-concepts }

Vamos falar novamente sobre alguns dos mesmos [Conceitos de ImplantaÃ§Ã£o](concepts.md){.internal-link target=_blank} em termos de contÃªineres.

ContÃªineres sÃ£o principalmente uma ferramenta para simplificar o processo de **construÃ§Ã£o e implantaÃ§Ã£o** de um aplicativo, mas eles nÃ£o impÃµem uma abordagem particular para lidar com esses **conceitos de implantaÃ§Ã£o** e existem vÃ¡rias estratÃ©gias possÃ­veis.

A **boa notÃ­cia** Ã© que com cada estratÃ©gia diferente hÃ¡ uma maneira de cobrir todos os conceitos de implantaÃ§Ã£o. ğŸ‰

Vamos revisar esses **conceitos de implantaÃ§Ã£o** em termos de contÃªineres:

* HTTPS
* Executando na inicializaÃ§Ã£o
* ReinicializaÃ§Ãµes
* ReplicaÃ§Ã£o (nÃºmero de processos rodando)
* MemÃ³ria
* Passos anteriores antes de comeÃ§ar

## HTTPS { #https }

Se nos concentrarmos apenas na **imagem do contÃªiner** para um aplicativo FastAPI (e posteriormente no **contÃªiner** em execuÃ§Ã£o), o HTTPS normalmente seria tratado **externamente** por outra ferramenta.

Isso poderia ser outro contÃªiner, por exemplo, com <a href="https://traefik.io/" class="external-link" target="_blank">Traefik</a>, lidando com **HTTPS** e aquisiÃ§Ã£o **automÃ¡tica** de **certificados**.

/// tip | Dica

Traefik tem integraÃ§Ãµes com Docker, Kubernetes e outros, portanto, Ã© muito fÃ¡cil configurar o HTTPS para seus contÃªineres com ele.

///

Alternativamente, o HTTPS poderia ser tratado por um provedor de nuvem como um de seus serviÃ§os (enquanto ainda executasse o aplicativo em um contÃªiner).

## Executando na inicializaÃ§Ã£o e reinicializaÃ§Ãµes { #running-on-startup-and-restarts }

Normalmente, outra ferramenta Ã© responsÃ¡vel por **iniciar e executar** seu contÃªiner.

Ela poderia ser o **Docker** diretamente, **Docker Compose**, **Kubernetes**, um **serviÃ§o de nuvem**, etc.

Na maioria (ou em todos) os casos, hÃ¡ uma opÃ§Ã£o simples para habilitar a execuÃ§Ã£o do contÃªiner na inicializaÃ§Ã£o e habilitar reinicializaÃ§Ãµes em falhas. Por exemplo, no Docker, Ã© a opÃ§Ã£o de linha de comando `--restart`.

Sem usar contÃªineres, fazer aplicativos executarem na inicializaÃ§Ã£o e com reinicializaÃ§Ãµes pode ser trabalhoso e difÃ­cil. Mas quando **trabalhando com contÃªineres** em muitos casos essa funcionalidade Ã© incluÃ­da por padrÃ£o. âœ¨

## ReplicaÃ§Ã£o - NÃºmero de Processos { #replication-number-of-processes }

Se vocÃª tiver um <abbr title="Um grupo de mÃ¡quinas que sÃ£o configuradas para estarem conectadas e trabalharem juntas de alguma forma.">cluster</abbr> de mÃ¡quinas com **Kubernetes**, Docker Swarm Mode, Nomad ou outro sistema complexo semelhante para gerenciar contÃªineres distribuÃ­dos em vÃ¡rias mÃ¡quinas, entÃ£o provavelmente desejarÃ¡ **lidar com a replicaÃ§Ã£o** no **nÃ­vel do cluster** em vez de usar um **gerenciador de processos** (como Uvicorn com workers) em cada contÃªiner.

Um desses sistemas de gerenciamento de contÃªineres distribuÃ­dos como o Kubernetes normalmente tem alguma maneira integrada de lidar com a **replicaÃ§Ã£o de contÃªineres** enquanto ainda oferece **balanceamento de carga** para as solicitaÃ§Ãµes recebidas. Tudo no **nÃ­vel do cluster**.

Nesses casos, vocÃª provavelmente desejarÃ¡ criar uma **imagem Docker do zero** como [explicado acima](#dockerfile), instalando suas dependÃªncias e executando **um Ãºnico processo Uvicorn** em vez de usar mÃºltiplos workers do Uvicorn.

### Balanceador de Carga { #load-balancer }

Quando usando contÃªineres, normalmente vocÃª terÃ¡ algum componente **escutando na porta principal**. Poderia ser outro contÃªiner que tambÃ©m Ã© um **Proxy de TerminaÃ§Ã£o TLS** para lidar com **HTTPS** ou alguma ferramenta semelhante.

Como esse componente assumiria a **carga** de solicitaÃ§Ãµes e distribuiria isso entre os workers de uma maneira (esperanÃ§osamente) **balanceada**, ele tambÃ©m Ã© comumente chamado de **Balanceador de Carga**.

/// tip | Dica

O mesmo componente **Proxy de TerminaÃ§Ã£o TLS** usado para HTTPS provavelmente tambÃ©m seria um **Balanceador de Carga**.

///

E quando trabalhar com contÃªineres, o mesmo sistema que vocÃª usa para iniciar e gerenciÃ¡-los jÃ¡ terÃ¡ ferramentas internas para transmitir a **comunicaÃ§Ã£o de rede** (por exemplo, solicitaÃ§Ãµes HTTP) do **balanceador de carga** (que tambÃ©m pode ser um **Proxy de TerminaÃ§Ã£o TLS**) para o(s) contÃªiner(es) com seu aplicativo.

### Um Balanceador de Carga - MÃºltiplos ContÃªineres de Workers { #one-load-balancer-multiple-worker-containers }

Quando trabalhando com **Kubernetes** ou sistemas similares de gerenciamento de contÃªiner distribuÃ­do, usar seus mecanismos de rede internos permite que o Ãºnico **balanceador de carga** que estÃ¡ escutando na **porta principal** transmita a comunicaÃ§Ã£o (solicitaÃ§Ãµes) para possivelmente **mÃºltiplos contÃªineres** executando seu aplicativo.

Cada um desses contÃªineres executando seu aplicativo normalmente teria **apenas um processo** (ex.: um processo Uvicorn executando seu aplicativo FastAPI). Todos seriam **contÃªineres idÃªnticos**, executando a mesma coisa, mas cada um com seu prÃ³prio processo, memÃ³ria, etc. Dessa forma, vocÃª aproveitaria a **paralelizaÃ§Ã£o** em **nÃºcleos diferentes** da CPU, ou atÃ© mesmo em **mÃ¡quinas diferentes**.

E o sistema de contÃªiner com o **balanceador de carga** iria **distribuir as solicitaÃ§Ãµes** para cada um dos contÃªineres com seu aplicativo **em turnos**. Portanto, cada solicitaÃ§Ã£o poderia ser tratada por um dos mÃºltiplos **contÃªineres replicados** executando seu aplicativo.

E normalmente esse **balanceador de carga** seria capaz de lidar com solicitaÃ§Ãµes que vÃ£o para *outros* aplicativos em seu cluster (por exemplo, para um domÃ­nio diferente, ou sob um prefixo de URL diferente), e transmitiria essa comunicaÃ§Ã£o para os contÃªineres certos para *esse outro* aplicativo em execuÃ§Ã£o em seu cluster.

### Um Processo por ContÃªiner { #one-process-per-container }

Nesse tipo de cenÃ¡rio, provavelmente vocÃª desejarÃ¡ ter **um Ãºnico processo (Uvicorn) por contÃªiner**, pois jÃ¡ estaria lidando com a replicaÃ§Ã£o no nÃ­vel do cluster.

EntÃ£o, nesse caso, vocÃª **nÃ£o** desejarÃ¡ ter mÃºltiplos workers no contÃªiner, por exemplo com a opÃ§Ã£o de linha de comando `--workers`. VocÃª desejarÃ¡ ter apenas um **Ãºnico processo Uvicorn** por contÃªiner (mas provavelmente vÃ¡rios contÃªineres).

Ter outro gerenciador de processos dentro do contÃªiner (como seria com mÃºltiplos workers) sÃ³ adicionaria **complexidade desnecessÃ¡ria** que vocÃª provavelmente jÃ¡ estÃ¡ cuidando com seu sistema de cluster.

### ContÃªineres com MÃºltiplos Processos e Casos Especiais { #containers-with-multiple-processes-and-special-cases }

Claro, existem **casos especiais** em que vocÃª pode querer ter **um contÃªiner** com vÃ¡rios **processos workers do Uvicorn** dentro.

Nesses casos, vocÃª pode usar a opÃ§Ã£o de linha de comando `--workers` para definir o nÃºmero de workers que deseja executar:

```{ .dockerfile .annotate }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

# (1)!
CMD ["fastapi", "run", "app/main.py", "--port", "80", "--workers", "4"]
```

1. Aqui usamos a opÃ§Ã£o de linha de comando `--workers` para definir o nÃºmero de workers como 4.

Aqui estÃ£o alguns exemplos de quando isso pode fazer sentido:

#### Um Aplicativo Simples { #a-simple-app }

VocÃª pode querer um gerenciador de processos no contÃªiner se seu aplicativo for **simples o suficiente** para rodar em um **Ãºnico servidor**, nÃ£o em um cluster.

#### Docker Compose { #docker-compose }

VocÃª pode estar implantando em um **Ãºnico servidor** (nÃ£o em um cluster) com o **Docker Compose**, entÃ£o vocÃª nÃ£o teria uma maneira fÃ¡cil de gerenciar a replicaÃ§Ã£o de contÃªineres (com o Docker Compose) enquanto preserva a rede compartilhada e o **balanceamento de carga**.

EntÃ£o vocÃª pode querer ter **um Ãºnico contÃªiner** com um **gerenciador de processos** iniciando **vÃ¡rios processos workers** dentro.

---

O ponto principal Ã© que **nenhum** desses sÃ£o **regras escritas em pedra** que vocÃª deve seguir cegamente. VocÃª pode usar essas ideias para **avaliar seu prÃ³prio caso de uso** e decidir qual Ã© a melhor abordagem para seu sistema, verificando como gerenciar os conceitos de:

* SeguranÃ§a - HTTPS
* Executando na inicializaÃ§Ã£o
* ReinicializaÃ§Ãµes
* ReplicaÃ§Ã£o (o nÃºmero de processos em execuÃ§Ã£o)
* MemÃ³ria
* Passos anteriores antes de iniciar

## MemÃ³ria { #memory }

Se vocÃª executar **um Ãºnico processo por contÃªiner**, terÃ¡ uma quantidade mais ou menos bem definida, estÃ¡vel e limitada de memÃ³ria consumida por cada um desses contÃªineres (mais de um se eles forem replicados).

E entÃ£o vocÃª pode definir esses mesmos limites e requisitos de memÃ³ria em suas configuraÃ§Ãµes para seu sistema de gerenciamento de contÃªineres (por exemplo, no **Kubernetes**). Dessa forma, ele poderÃ¡ **replicar os contÃªineres** nas **mÃ¡quinas disponÃ­veis** levando em consideraÃ§Ã£o a quantidade de memÃ³ria necessÃ¡ria por eles e a quantidade disponÃ­vel nas mÃ¡quinas no cluster.

Se sua aplicaÃ§Ã£o for **simples**, isso provavelmente **nÃ£o serÃ¡ um problema**, e vocÃª pode nÃ£o precisar especificar limites de memÃ³ria rÃ­gidos. Mas se vocÃª estiver **usando muita memÃ³ria** (por exemplo, com **modelos de aprendizado de mÃ¡quina**), deve verificar quanta memÃ³ria estÃ¡ consumindo e ajustar o **nÃºmero de contÃªineres** que executa em **cada mÃ¡quina** (e talvez adicionar mais mÃ¡quinas ao seu cluster).

Se vocÃª executar **mÃºltiplos processos por contÃªiner**, deve garantir que o nÃºmero de processos iniciados nÃ£o **consuma mais memÃ³ria** do que o disponÃ­vel.

## Passos anteriores antes de iniciar e contÃªineres { #previous-steps-before-starting-and-containers }

Se vocÃª estiver usando contÃªineres (por exemplo, Docker, Kubernetes), existem duas abordagens principais que vocÃª pode usar.

### ContÃªineres MÃºltiplos { #multiple-containers }

Se vocÃª tiver **mÃºltiplos contÃªineres**, provavelmente cada um executando um **Ãºnico processo** (por exemplo, em um cluster do **Kubernetes**), entÃ£o provavelmente vocÃª gostaria de ter um **contÃªiner separado** fazendo o trabalho dos **passos anteriores** em um Ãºnico contÃªiner, executando um Ãºnico processo, **antes** de executar os contÃªineres workers replicados.

/// info | InformaÃ§Ã£o

Se vocÃª estiver usando o Kubernetes, provavelmente serÃ¡ um <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" class="external-link" target="_blank">Init Container</a>.

///

Se no seu caso de uso nÃ£o houver problema em executar esses passos anteriores **em paralelo vÃ¡rias vezes** (por exemplo, se vocÃª nÃ£o estiver executando migraÃ§Ãµes de banco de dados, mas apenas verificando se o banco de dados estÃ¡ pronto), entÃ£o vocÃª tambÃ©m pode colocÃ¡-los em cada contÃªiner logo antes de iniciar o processo principal.

### ContÃªiner Ãšnico { #single-container }

Se vocÃª tiver uma configuraÃ§Ã£o simples, com um **Ãºnico contÃªiner** que entÃ£o inicia vÃ¡rios **processos workers** (ou tambÃ©m apenas um processo), entÃ£o poderia executar esses passos anteriores no mesmo contÃªiner, logo antes de iniciar o processo com o aplicativo.

### Imagem Docker base { #base-docker-image }

Antes havia uma imagem oficial do FastAPI para Docker: <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>. Mas agora ela estÃ¡ descontinuada. â›”ï¸

VocÃª provavelmente **nÃ£o** deve usar essa imagem base do Docker (ou qualquer outra semelhante).

Se vocÃª estÃ¡ usando **Kubernetes** (ou outros) e jÃ¡ estÃ¡ definindo a **replicaÃ§Ã£o** no nÃ­vel do cluster, com vÃ¡rios **contÃªineres**. Nesses casos, Ã© melhor **construir uma imagem do zero** como descrito acima: [Construir uma Imagem Docker para FastAPI](#build-a-docker-image-for-fastapi).

E se vocÃª precisar ter mÃºltiplos workers, vocÃª pode simplesmente usar a opÃ§Ã£o de linha de comando `--workers`.

/// note | Detalhes TÃ©cnicos

A imagem Docker foi criada quando o Uvicorn nÃ£o suportava gerenciar e reiniciar workers mortos, entÃ£o era necessÃ¡rio usar o Gunicorn com o Uvicorn, o que adicionava bastante complexidade, apenas para que o Gunicorn gerenciasse e reiniciasse os processos workers do Uvicorn.

Mas agora que o Uvicorn (e o comando `fastapi`) suportam o uso de `--workers`, nÃ£o hÃ¡ razÃ£o para usar uma imagem base do Docker em vez de construir a sua prÃ³pria (Ã© praticamente a mesma quantidade de cÃ³digo ğŸ˜…).

///

## Deploy da Imagem do ContÃªiner { #deploy-the-container-image }

Depois de ter uma imagem de contÃªiner (Docker), existem vÃ¡rias maneiras de implantÃ¡-la.

Por exemplo:

* Com **Docker Compose** em um Ãºnico servidor
* Com um cluster **Kubernetes**
* Com um cluster Docker Swarm Mode
* Com outra ferramenta como o Nomad
* Com um serviÃ§o de nuvem que pega sua imagem de contÃªiner e a implanta

## Imagem Docker com `uv` { #docker-image-with-uv }

Se vocÃª estÃ¡ usando o <a href="https://github.com/astral-sh/uv" class="external-link" target="_blank">uv</a> para instalar e gerenciar seu projeto, vocÃª pode seguir o <a href="https://docs.astral.sh/uv/guides/integration/docker/" class="external-link" target="_blank">guia de Docker do uv</a>.

## Recapitulando { #recap }

Usando sistemas de contÃªiner (por exemplo, com **Docker** e **Kubernetes**), torna-se bastante simples lidar com todos os **conceitos de implantaÃ§Ã£o**:

* HTTPS
* Executando na inicializaÃ§Ã£o
* ReinÃ­cios
* ReplicaÃ§Ã£o (o nÃºmero de processos rodando)
* MemÃ³ria
* Passos anteriores antes de iniciar

Na maioria dos casos, vocÃª provavelmente nÃ£o desejarÃ¡ usar nenhuma imagem base e, em vez disso, **construir uma imagem de contÃªiner do zero** baseada na imagem oficial do Docker Python.

Tendo cuidado com a **ordem** das instruÃ§Ãµes no `Dockerfile` e o **cache do Docker**, vocÃª pode **minimizar os tempos de construÃ§Ã£o**, para maximizar sua produtividade (e evitar o tÃ©dio). ğŸ˜
