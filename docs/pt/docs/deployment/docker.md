# FastAPI em contÃªineres - Docker

Ao fazer o deploy de aplicaÃ§Ãµes FastAPI uma abordagem comum Ã© construir uma **imagem de contÃªiner Linux**. Isso normalmente Ã© feito usando o <a href="https://www.docker.com/" class="external-link" target="_blank">**Docker**</a>. VocÃª pode a partir disso fazer o deploy dessa imagem de algumas maneiras.

Usando contÃªineres Linux vocÃª tem diversas vantagens incluindo **seguranÃ§a**, **replicabilidade**, **simplicidade**, entre outras.

!!! Dica
    EstÃ¡ com pressa e jÃ¡ sabe dessas coisas? Pode ir direto para [`Dockerfile` abaixo ğŸ‘‡](#build-a-docker-image-for-fastapi).


<details>
<summary>VisualizaÃ§Ã£o do Dockerfile ğŸ‘€</summary>

```Dockerfile
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80"]

# If running behind a proxy like Nginx or Traefik add --proxy-headers
# CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80", "--proxy-headers"]
```

</details>

## O que Ã© um ContÃªiner

ContÃªineres (especificamente contÃªineres Linux) sÃ£o um jeito muito **leve** de empacotar aplicaÃ§Ãµes contendo todas as dependÃªncias e arquivos necessÃ¡rios enquanto os mantÃ©m isolados de outros contÃªineres (outras aplicaÃ§Ãµes ou componentes) no mesmo sistema.

ContÃªineres Linux rodam usando o mesmo kernel Linux do hospedeiro (mÃ¡quina, mÃ¡quina virtual, servidor na nuvem, etc). Isso simplesmente significa que eles sÃ£o muito leves (comparados com mÃ¡quinas virtuais emulando um sistema operacional completo).

Dessa forma, contÃªineres consomem **poucos recursos**, uma quantidade comparÃ¡vel com rodar os processos diretamente (uma mÃ¡quina virtual consumiria muito mais).

ContÃªineres tambÃ©m possuem seus prÃ³prios processos (comumente um Ãºnico processo), sistema de arquivos e rede **isolados** simplificando deploy, seguranÃ§a, desenvolvimento, etc.

## O que Ã© uma Imagem de ContÃªiner

Um **contÃªiner** roda a partir de uma **imagem de contÃªiner**.

Uma imagem de contÃªiner Ã© uma versÃ£o **estÃ¡tica** de todos os arquivos, variÃ¡veis de ambiente e do comando/programa padrÃ£o que deve estar presente num contÃªiner. **EstÃ¡tica** aqui significa que a **imagem** de contÃªiner nÃ£o estÃ¡ rodando, nÃ£o estÃ¡ sendo executada, somente contÃ©m os arquivos e metadados empacotados.

Em contraste com a "**imagem de contÃªiner**" que contÃ©m os conteÃºdos estÃ¡ticos armazenados, um "**contÃªiner**" normalmente se refere Ã  instÃ¢ncia rodando, a coisa que estÃ¡ sendo **executada**.

Quando o **contÃªiner** Ã© iniciado e estÃ¡ rodando (iniciado a partir de uma **imagem de contÃªiner**), ele pode criar ou modificar arquivos, variÃ¡veis de ambiente, etc. Essas mudanÃ§as vÃ£o existir somente nesse contÃªiner, mas nÃ£o persistirÃ£o na imagem subjacente do container (nÃ£o serÃ£o salvas no disco).

Uma imagem de contÃªiner Ã© comparÃ¡vel ao arquivo de **programa** e seus conteÃºdos, ex.: `python` e algum arquivo `main.py`.

E o **contÃªiner** em si (em contraste Ã  **imagem de contÃªiner**) Ã© a prÃ³pria instÃ¢ncia da imagem rodando, comparÃ¡vel a um **processo**. Na verdade, um contÃªiner estÃ¡ rodando somente quando hÃ¡ um **processo rodando** (e normalmente Ã© somente um processo). O contÃªiner finaliza quando nÃ£o hÃ¡ um processo rodando nele.

## Imagens de contÃªiner

Docker tem sido uma das principais ferramentas para criar e gerenciar **imagens de contÃªiner** e **contÃªineres**.

E existe um <a href="https://hub.docker.com/" class="external-link" target="_blank">Docker Hub</a> pÃºblico com **imagens de contÃªiner oficiais** prÃ©-prontas para diversas ferramentas, ambientes, bancos de dados e aplicaÃ§Ãµes.

Por exemplo, hÃ¡ uma <a href="https://hub.docker.com/_/python" class="external-link" target="_blank">Imagem Python</a> oficial.

E existe muitas outras imagens para diferentes coisas, como bancos de dados, por exemplo:

* <a href="https://hub.docker.com/_/postgres" class="external-link" target="_blank">PostgreSQL</a>
* <a href="https://hub.docker.com/_/mysql" class="external-link" target="_blank">MySQL</a>
* <a href="https://hub.docker.com/_/mongo" class="external-link" target="_blank">MongoDB</a>
* <a href="https://hub.docker.com/_/redis" class="external-link" target="_blank">Redis</a>, etc.

Usando imagens de contÃªiner prÃ©-prontas Ã© muito fÃ¡cil **combinar** e usar diferentes ferramentas. Por exemplo, para testar um novo banco de dados. Em muitos casos, vocÃª pode usar as **imagens oficiais** precisando somente de variÃ¡veis de ambiente para configurÃ¡-las.

Dessa forma, em muitos casos vocÃª pode aprender sobre contÃªineres e Docker e re-usar essa experiÃªncia com diversos componentes e ferramentas.

EntÃ£o, vocÃª rodaria **vÃ¡rios contÃªineres** com coisas diferentes, como um banco de dados, uma aplicaÃ§Ã£o Python, um servidor web com uma aplicaÃ§Ã£o frontend React, e conectÃ¡-los juntos via sua rede interna.

Todos os sistemas de gerenciamento de contÃªineres (como Docker ou Kubernetes) possuem essas funcionalidades de rede integradas a eles.

## ContÃªineres e Processos

Uma **imagem de contÃªiner** normalmente inclui em seus metadados o programa padrÃ£o ou comando que deve ser executado quando o **contÃªiner** Ã© iniciado e os parÃ¢metros a serem passados para esse programa. Muito similar ao que seria se estivesse na linha de comando.

Quando um **contÃªiner** Ã© iniciado, ele irÃ¡ rodar esse comando/programa (embora vocÃª possa sobrescrevÃª-lo e fazer com que ele rode um comando/programa diferente).

Um contÃªiner estÃ¡ rodando enquanto o **processo principal** (comando ou programa) estiver rodando.

Um contÃªiner normalmente tem um **Ãºnico processo**, mas tambÃ©m Ã© possÃ­vel iniciar sub-processos a partir do processo principal, e dessa forma vocÃª terÃ¡ **vÃ¡rios processos** no mesmo contÃªiner.

Mas nÃ£o Ã© possÃ­vel ter um contÃªiner rodando sem **pelo menos um processo rodando**. Se o processo principal parar, o contÃªiner tambÃ©m para.

## Construindo uma Imagem Docker para FastAPI

Okay, vamos construir algo agora! ğŸš€

Eu vou mostrar como construir uma **imagem Docker** para FastAPI **do zero**, baseado na **imagem oficial do Python**.

Isso Ã© o que vocÃª quer fazer na **maioria dos casos**, por exemplo:

* Usando **Kubernetes** ou ferramentas similares
* Quando rodando em uma **Raspberry Pi**
* Usando um serviÃ§o em nuvem que irÃ¡ rodar uma imagem de contÃªiner para vocÃª, etc.

### O Pacote Requirements

VocÃª normalmente teria os **requisitos do pacote** para sua aplicaÃ§Ã£o em algum arquivo.

Isso pode depender principalmente da ferramenta que vocÃª usa para **instalar** esses requisitos.

O caminho mais comum de fazer isso Ã© ter um arquivo `requirements.txt` com os nomes dos pacotes e suas versÃµes, um por linha.

VocÃª, naturalmente, usaria as mesmas ideias que vocÃª leu em [Sobre VersÃµes do FastAPI](./versions.md){.internal-link target=_blank} para definir os intervalos de versÃµes.

Por exemplo, seu `requirements.txt` poderia parecer com:

```
fastapi>=0.68.0,<0.69.0
pydantic>=1.8.0,<2.0.0
uvicorn>=0.15.0,<0.16.0
```

E vocÃª normalmente instalaria essas dependÃªncias de pacote com `pip`, por exemplo:

<div class="termy">

```console
$ pip install -r requirements.txt
---> 100%
Successfully installed fastapi pydantic uvicorn
```

</div>

!!! info
    HÃ¡ outros formatos e ferramentas para definir e instalar dependÃªncias de pacote.

    Eu vou mostrar um exemplo depois usando Poetry em uma seÃ§Ã£o abaixo. ğŸ‘‡

### Criando o CÃ³digo do **FastAPI**

* Crie um diretÃ³rio `app` e entre nele.
* Crie um arquivo vazio `__init__.py`.
* Crie um arquivo `main.py` com:

```Python
from typing import Optional

from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}
```

### Dockerfile

Agora, no mesmo diretÃ³rio do projeto, crie um arquivo `Dockerfile` com:

```{ .dockerfile .annotate }
# (1)
FROM python:3.9

# (2)
WORKDIR /code

# (3)
COPY ./requirements.txt /code/requirements.txt

# (4)
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (5)
COPY ./app /code/app

# (6)
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80"]
```

1. Inicie a partir da imagem base oficial do Python.

2. Defina o diretÃ³rio de trabalho atual para `/code`.

    Esse Ã© o diretÃ³rio onde colocaremos o arquivo `requirements.txt` e o diretÃ³rio `app`.

3. Copie o arquivo com os requisitos para o diretÃ³rio `/code`.

    Copie **somente** o arquivo com os requisitos primeiro, nÃ£o o resto do cÃ³digo.

    Como esse arquivo **nÃ£o muda com frequÃªncia**, o Docker irÃ¡ detectÃ¡-lo e usar o **cache** para esse passo, habilitando o cache para o prÃ³ximo passo tambÃ©m.

4. Instale as dependÃªncias de pacote vindas do arquivo de requisitos.

    A opÃ§Ã£o `--no-cache-dir` diz ao `pip` para nÃ£o salvar os pacotes baixados localmente, pois isso sÃ³ aconteceria se `pip` fosse executado novamente para instalar os mesmos pacotes, mas esse nÃ£o Ã© o caso quando trabalhamos com contÃªineres.

    !!! note
        `--no-cache-dir` Ã© apenas relacionado ao `pip`, nÃ£o tem nada a ver com Docker ou contÃªineres.

    A opÃ§Ã£o `--upgrade` diz ao `pip` para atualizar os pacotes se eles jÃ¡ estiverem instalados.

    Por causa do passo anterior de copiar o arquivo, ele pode ser detectado pelo **cache do Docker**, esse passo tambÃ©m **usarÃ¡ o cache do Docker** quando disponÃ­vel.

    Usando o cache nesse passo irÃ¡ **salvar** muito **tempo** quando vocÃª for construir a imagem repetidas vezes durante o desenvolvimento, ao invÃ©s de **baixar e instalar** todas as dependÃªncias **toda vez**.

5. Copie o diretÃ³rio `./app` dentro do diretÃ³rio `/code`.

    Como isso tem todo o cÃ³digo contendo o que **muda com mais frequÃªncia**, o **cache do Docker** nÃ£o serÃ¡ usado para esse passo ou para **qualquer passo seguinte** facilmente.

    EntÃ£o, Ã© importante colocar isso **perto do final** do `Dockerfile`, para otimizar o tempo de construÃ§Ã£o da imagem do contÃªiner.

6. Defina o **comando** para rodar o servidor `uvicorn`.

    `CMD` recebe uma lista de strings, cada uma dessas strings Ã© o que vocÃª digitaria na linha de comando separado por espaÃ§os.

    Esse comando serÃ¡ executado a partir do **diretÃ³rio de trabalho atual**, o mesmo diretÃ³rio `/code` que vocÃª definiu acima com `WORKDIR /code`.

    Porque o programa serÃ¡ iniciado em `/code` e dentro dele estÃ¡ o diretÃ³rio `./app` com seu cÃ³digo, o **Uvicorn** serÃ¡ capaz de ver e **importar** `app` de `app.main`.

!!! tip
    Revise o que cada linha faz clicando em cada bolha com o nÃºmero no cÃ³digo. ğŸ‘†

Agora vocÃª deve ter uma estrutura de diretÃ³rio como:

```
.
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

#### Por TrÃ¡s de um Proxy de TerminaÃ§Ã£o TLS

Se vocÃª estÃ¡ executando seu contÃªiner atrÃ¡s de um Proxy de TerminaÃ§Ã£o TLS (load balancer) como Nginx ou Traefik, adicione a opÃ§Ã£o `--proxy-headers`, isso farÃ¡ com que o Uvicorn confie nos cabeÃ§alhos enviados por esse proxy, informando que o aplicativo estÃ¡ sendo executado atrÃ¡s do HTTPS, etc.

```Dockerfile
CMD ["uvicorn", "app.main:app", "--proxy-headers", "--host", "0.0.0.0", "--port", "80"]
```

#### Cache Docker

Existe um truque importante nesse `Dockerfile`, primeiro copiamos o **arquivo com as dependÃªncias sozinho**, nÃ£o o resto do cÃ³digo. Deixe-me te contar o porquÃª disso.

```Dockerfile
COPY ./requirements.txt /code/requirements.txt
```

Docker e outras ferramentas **constrÃ³em** essas imagens de contÃªiner **incrementalmente**, adicionando **uma camada em cima da outra**, comeÃ§ando do topo do `Dockerfile` e adicionando qualquer arquivo criado por cada uma das instruÃ§Ãµes do `Dockerfile`.

Docker e ferramentas similares tambÃ©m usam um **cache interno** ao construir a imagem, se um arquivo nÃ£o mudou desde a Ãºltima vez que a imagem do contÃªiner foi construÃ­da, entÃ£o ele irÃ¡ **reutilizar a mesma camada** criada na Ãºltima vez, ao invÃ©s de copiar o arquivo novamente e criar uma nova camada do zero.

Somente evitar a cÃ³pia de arquivos nÃ£o melhora muito as coisas, mas porque ele usou o cache para esse passo, ele pode **usar o cache para o prÃ³ximo passo**. Por exemplo, ele pode usar o cache para a instruÃ§Ã£o que instala as dependÃªncias com:

```Dockerfile
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt
```

O arquivo com os requisitos de pacote **nÃ£o muda com frequÃªncia**. EntÃ£o, ao copiar apenas esse arquivo, o Docker serÃ¡ capaz de **usar o cache** para esse passo.

E entÃ£o, o Docker serÃ¡ capaz de **usar o cache para o prÃ³ximo passo** que baixa e instala essas dependÃªncias. E Ã© aqui que **salvamos muito tempo**. âœ¨ ...e evitamos tÃ©dio esperando. ğŸ˜ªğŸ˜†

Baixar e instalar as dependÃªncias do pacote **pode levar minutos**, mas usando o **cache** leva **segundos** no mÃ¡ximo.

E como vocÃª estaria construindo a imagem do contÃªiner novamente e novamente durante o desenvolvimento para verificar se suas alteraÃ§Ãµes de cÃ³digo estÃ£o funcionando, hÃ¡ muito tempo acumulado que isso economizaria.

A partir daÃ­, perto do final do `Dockerfile`, copiamos todo o cÃ³digo. Como isso Ã© o que **muda com mais frequÃªncia**, colocamos perto do final, porque quase sempre, qualquer coisa depois desse passo nÃ£o serÃ¡ capaz de usar o cache.

```Dockerfile
COPY ./app /code/app
```

### Construindo a Imagem Docker

Agora que todos os arquivos estÃ£o no lugar, vamos construir a imagem do contÃªiner.

* VÃ¡ para o diretÃ³rio do projeto (onde estÃ¡ o seu `Dockerfile`, contendo o diretÃ³rio `app`).
* Construa sua imagem FastAPI:

<div class="termy">

```console
$ docker build -t myimage .

---> 100%
```

</div>

!!! tip
    Note o `.` no final, Ã© equivalente a `./`, ele diz ao Docker o diretÃ³rio a ser usado para construir a imagem do contÃªiner.

    Nesse caso, Ã© o mesmo diretÃ³rio atual (`.`).

### Inicie o contÃªiner Docker

* Execute um contÃªiner baseado na sua imagem:

<div class="termy">

```console
$ docker run -d --name mycontÃªiner -p 80:80 myimage
```

</div>

## Verifique

VocÃª deve ser capaz de verificar isso no URL do seu contÃªiner Docker, por exemplo: <a href="http://192.168.99.100/items/5?q=somequery" class="external-link" target="_blank">http://192.168.99.100/items/5?q=somequery</a> ou <a href="http://127.0.0.1/items/5?q=somequery" class="external-link" target="_blank">http://127.0.0.1/items/5?q=somequery</a> (ou equivalente, usando seu host Docker).

VocÃª verÃ¡ algo como:

```JSON
{"item_id": 5, "q": "somequery"}
```

## DocumentaÃ§Ã£o interativa da API

Agora vocÃª pode ir para <a href="http://192.168.99.100/docs" class="external-link" target="_blank">http://192.168.99.100/docs</a> ou <a href="http://127.0.0.1/docs" class="external-link" target="_blank">http://127.0.0.1/docs</a> (ou equivalente, usando seu host Docker).

VocÃª verÃ¡ a documentaÃ§Ã£o interativa automÃ¡tica da API (fornecida pelo <a href="https://github.com/swagger-api/swagger-ui" class="external-link" target="_blank">Swagger UI</a>):

![Swagger UI](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)

## DocumentaÃ§Ã£o alternativa da API

E vocÃª tambÃ©m pode ir para <a href="http://192.168.99.100/redoc" class="external-link" target="_blank">http://192.168.99.100/redoc</a> ou <a href="http://127.0.0.1/redoc" class="external-link" target="_blank">http://127.0.0.1/redoc</a> (ou equivalente, usando seu host Docker).

VocÃª verÃ¡ a documentaÃ§Ã£o alternativa automÃ¡tica (fornecida pela <a href="https://github.com/Rebilly/ReDoc" class="external-link" target="_blank">ReDoc</a>):

![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)

## Construindo uma Imagem Docker com um Arquivo Ãšnico FastAPI

Se seu FastAPI for um Ãºnico arquivo, por exemplo, `main.py` sem um diretÃ³rio `./app`, sua estrutura de arquivos poderia ser assim:

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt
```

EntÃ£o vocÃª sÃ³ teria que alterar os caminhos correspondentes para copiar o arquivo dentro do `Dockerfile`:

```{ .dockerfile .annotate hl_lines="10  13" }
FROM python:3.9

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (1)
COPY ./main.py /code/

# (2)
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "80"]
```

1. Copie o arquivo `main.py` para o diretÃ³rio `/code` diretamente (sem nenhum diretÃ³rio `./app`).

2. Execute o Uvicorn e diga a ele para importar o objeto `app` de `main` (em vez de importar de `app.main`).

EntÃ£o ajuste o comando Uvicorn para usar o novo mÃ³dulo `main` em vez de `app.main` para importar o objeto FastAPI `app`.

## Conceitos de ImplantaÃ§Ã£o

Vamos falar novamente sobre alguns dos mesmos [Conceitos de ImplantaÃ§Ã£o](./concepts.md){.internal-link target=_blank} em termos de contÃªineres.

ContÃªineres sÃ£o principalmente uma ferramenta para simplificar o processo de **construÃ§Ã£o e implantaÃ§Ã£o** de um aplicativo, mas eles nÃ£o impÃµem uma abordagem particular para lidar com esses **conceitos de implantaÃ§Ã£o** e existem vÃ¡rias estratÃ©gias possÃ­veis.

A **boa notÃ­cia** Ã© que com cada estratÃ©gia diferente hÃ¡ uma maneira de cobrir todos os conceitos de implantaÃ§Ã£o. ğŸ‰

Vamos revisar esses **conceitos de implantaÃ§Ã£o** em termos de contÃªineres:

* HTTPS
* Executando na inicializaÃ§Ã£o
* ReinicializaÃ§Ãµes
* ReplicaÃ§Ã£o (nÃºmero de processos rodando)
* MemÃ³ria
* Passos anteriores antes de comeÃ§ar

## HTTPS

Se nos concentrarmos apenas na **imagem do contÃªiner** para um aplicativo FastAPI (e posteriormente no **contÃªiner** em execuÃ§Ã£o), o HTTPS normalmente seria tratado **externamente** por outra ferramenta.

Isso poderia ser outro contÃªiner, por exemplo, com <a href="https://traefik.io/" class="external-link" target="_blank">Traefik</a>, lidando com **HTTPS** e aquisiÃ§Ã£o **automÃ¡tica** de **certificados**.

!!! tip
    Traefik tem integraÃ§Ãµes com Docker, Kubernetes e outros, portanto, Ã© muito fÃ¡cil configurar e configurar o HTTPS para seus contÃªineres com ele.

Alternativamente, o HTTPS poderia ser tratado por um provedor de nuvem como um de seus serviÃ§os (enquanto ainda executasse o aplicativo em um contÃªiner).

## Executando na inicializaÃ§Ã£o e reinicializaÃ§Ãµes

Normalmente, outra ferramenta Ã© responsÃ¡vel por **iniciar e executar** seu contÃªiner.

Ela poderia ser o **Docker** diretamente, **Docker Compose**, **Kubernetes**, um **serviÃ§o de nuvem**, etc.

Na maioria (ou em todos) os casos, hÃ¡ uma opÃ§Ã£o simples para habilitar a execuÃ§Ã£o do contÃªiner na inicializaÃ§Ã£o e habilitar reinicializaÃ§Ãµes em falhas. Por exemplo, no Docker, Ã© a opÃ§Ã£o de linha de comando `--restart`.

Sem usar contÃªineres, fazer aplicativos executarem na inicializaÃ§Ã£o e com reinicializaÃ§Ãµes pode ser trabalhoso e difÃ­cil. Mas quando **trabalhando com contÃªineres** em muitos casos essa funcionalidade Ã© incluÃ­da por padrÃ£o. âœ¨

## ReplicaÃ§Ã£o - NÃºmero de Processos

Se vocÃª tiver um <abbr title="Um grupo de mÃ¡quinas que sÃ£o configuradas para estarem conectadas e trabalharem juntas de alguma forma">cluster</abbr> de mÃ¡quinas com **Kubernetes**, Docker Swarm Mode, Nomad ou outro sistema complexo semelhante para gerenciar contÃªineres distribuÃ­dos em vÃ¡rias mÃ¡quinas, entÃ£o provavelmente desejarÃ¡ **lidar com a replicaÃ§Ã£o** no **nÃ­vel do cluster** em vez de usar um **gerenciador de processos** (como o Gunicorn com workers) em cada contÃªiner.

Um desses sistemas de gerenciamento de contÃªineres distribuÃ­dos como o Kubernetes normalmente tem alguma maneira integrada de lidar com a **replicaÃ§Ã£o de contÃªineres** enquanto ainda oferece **balanceamento de carga** para as solicitaÃ§Ãµes recebidas. Tudo no **nÃ­vel do cluster**.

Nesses casos, vocÃª provavelmente desejarÃ¡ criar uma **imagem do contÃªiner do zero** como [explicado acima](#dockerfile), instalando suas dependÃªncias e executando **um Ãºnico processo Uvicorn** em vez de executar algo como Gunicorn com trabalhadores Uvicorn.

### Balanceamento de Carga

Quando usando contÃªineres, normalmente vocÃª terÃ¡ algum componente **escutando na porta principal**. Poderia ser outro contÃªiner que tambÃ©m Ã© um **Proxy de TerminaÃ§Ã£o TLS** para lidar com **HTTPS** ou alguma ferramenta semelhante.

Como esse componente assumiria a **carga** de solicitaÃ§Ãµes e distribuiria isso entre os trabalhadores de uma maneira (esperanÃ§osamente) **balanceada**, ele tambÃ©m Ã© comumente chamado de **Balanceador de Carga**.

!!! tip
    O mesmo componente **Proxy de TerminaÃ§Ã£o TLS** usado para HTTPS provavelmente tambÃ©m seria um **Balanceador de Carga**.

E quando trabalhar com contÃªineres, o mesmo sistema que vocÃª usa para iniciar e gerenciÃ¡-los jÃ¡ terÃ¡ ferramentas internas para transmitir a **comunicaÃ§Ã£o de rede** (por exemplo, solicitaÃ§Ãµes HTTP) do **balanceador de carga** (que tambÃ©m pode ser um **Proxy de TerminaÃ§Ã£o TLS**) para o(s) contÃªiner(es) com seu aplicativo.

### Um Balanceador de Carga - MÃºltiplos ContÃªineres de Workers

Quando trabalhando com **Kubernetes** ou sistemas similares de gerenciamento de contÃªiner distribuÃ­do, usando seus mecanismos de rede internos permitiria que o Ãºnico **balanceador de carga** que estivesse escutando na **porta principal** transmitisse comunicaÃ§Ã£o (solicitaÃ§Ãµes) para possivelmente **mÃºltiplos contÃªineres** executando seu aplicativo.

Cada um desses contÃªineres executando seu aplicativo normalmente teria **apenas um processo** (ex.: um processo Uvicorn executando seu aplicativo FastAPI). Todos seriam **contÃªineres idÃªnticos**, executando a mesma coisa, mas cada um com seu prÃ³prio processo, memÃ³ria, etc. Dessa forma, vocÃª aproveitaria a **paralelizaÃ§Ã£o** em **nÃºcleos diferentes** da CPU, ou atÃ© mesmo em **mÃ¡quinas diferentes**.

E o sistema de contÃªiner com o **balanceador de carga** iria **distribuir as solicitaÃ§Ãµes** para cada um dos contÃªineres com seu aplicativo **em turnos**. Portanto, cada solicitaÃ§Ã£o poderia ser tratada por um dos mÃºltiplos **contÃªineres replicados** executando seu aplicativo.

E normalmente esse **balanceador de carga** seria capaz de lidar com solicitaÃ§Ãµes que vÃ£o para *outros* aplicativos em seu cluster (por exemplo, para um domÃ­nio diferente, ou sob um prefixo de URL diferente), e transmitiria essa comunicaÃ§Ã£o para os contÃªineres certos para *esse outro* aplicativo em execuÃ§Ã£o em seu cluster.

### Um Processo por ContÃªiner

Nesse tipo de cenÃ¡rio, provavelmente vocÃª desejarÃ¡ ter **um Ãºnico processo (Uvicorn) por contÃªiner**, pois jÃ¡ estaria lidando com a replicaÃ§Ã£o no nÃ­vel do cluster.

EntÃ£o, nesse caso, vocÃª **nÃ£o** desejarÃ¡ ter um gerenciador de processos como o Gunicorn com trabalhadores Uvicorn, ou o Uvicorn usando seus prÃ³prios trabalhadores Uvicorn. VocÃª desejarÃ¡ ter apenas um **Ãºnico processo Uvicorn** por contÃªiner (mas provavelmente vÃ¡rios contÃªineres).

Tendo outro gerenciador de processos dentro do contÃªiner (como seria com o Gunicorn ou o Uvicorn gerenciando trabalhadores Uvicorn) sÃ³ adicionaria **complexidade desnecessÃ¡ria** que vocÃª provavelmente jÃ¡ estÃ¡ cuidando com seu sistema de cluster.

### ContÃªineres com MÃºltiplos Processos e Casos Especiais

Claro, existem **casos especiais** em que vocÃª pode querer ter um **contÃªiner** com um **gerenciador de processos Gunicorn** iniciando vÃ¡rios **processos trabalhadores Uvicorn** dentro.

Nesses casos, vocÃª pode usar a **imagem oficial do Docker** que inclui o **Gunicorn** como um gerenciador de processos executando vÃ¡rios **processos trabalhadores Uvicorn**, e algumas configuraÃ§Ãµes padrÃ£o para ajustar o nÃºmero de trabalhadores com base nos atuais nÃºcleos da CPU automaticamente. Eu vou te contar mais sobre isso abaixo em [Imagem Oficial do Docker com Gunicorn - Uvicorn](#imagem-oficial-do-docker-com-gunicorn-uvicorn).

Aqui estÃ£o alguns exemplos de quando isso pode fazer sentido:

#### Um Aplicativo Simples

VocÃª pode querer um gerenciador de processos no contÃªiner se seu aplicativo for **simples o suficiente** para que vocÃª nÃ£o precise (pelo menos nÃ£o agora) ajustar muito o nÃºmero de processos, e vocÃª pode simplesmente usar um padrÃ£o automatizado (com a imagem oficial do Docker), e vocÃª estÃ¡ executando em um **Ãºnico servidor**, nÃ£o em um cluster.

#### Docker Compose

VocÃª pode estar implantando em um **Ãºnico servidor** (nÃ£o em um cluster) com o **Docker Compose**, entÃ£o vocÃª nÃ£o teria uma maneira fÃ¡cil de gerenciar a replicaÃ§Ã£o de contÃªineres (com o Docker Compose) enquanto preserva a rede compartilhada e o **balanceamento de carga**.

EntÃ£o vocÃª pode querer ter **um Ãºnico contÃªiner** com um **gerenciador de processos** iniciando **vÃ¡rios processos trabalhadores** dentro.

#### Prometheus and Outros Motivos

VocÃª tambÃ©m pode ter **outros motivos** que tornariam mais fÃ¡cil ter um **Ãºnico contÃªiner** com **mÃºltiplos processos** em vez de ter **mÃºltiplos contÃªineres** com **um Ãºnico processo** em cada um deles.

Por exemplo (dependendo de sua configuraÃ§Ã£o), vocÃª poderia ter alguma ferramenta como um exportador do Prometheus no mesmo contÃªiner que deve ter acesso a **cada uma das solicitaÃ§Ãµes** que chegam.

Nesse caso, se vocÃª tivesse **mÃºltiplos contÃªineres**, por padrÃ£o, quando o Prometheus fosse **ler as mÃ©tricas**, ele receberia as mÃ©tricas de **um Ãºnico contÃªiner cada vez** (para o contÃªiner que tratou essa solicitaÃ§Ã£o especÃ­fica), em vez de receber as **mÃ©tricas acumuladas** de todos os contÃªineres replicados.

EntÃ£o, nesse caso, poderia ser mais simples ter **um Ãºnico contÃªiner** com **mÃºltiplos processos**, e uma ferramenta local (por exemplo, um exportador do Prometheus) no mesmo contÃªiner coletando mÃ©tricas do Prometheus para todos os processos internos e expor essas mÃ©tricas no Ãºnico contÃªiner.

---

O ponto principal Ã© que **nenhum** desses sÃ£o **regras escritas em pedra** que vocÃª deve seguir cegamente. VocÃª pode usar essas idÃ©ias para **avaliar seu prÃ³prio caso de uso** e decidir qual Ã© a melhor abordagem para seu sistema, verificando como gerenciar os conceitos de:

* SeguranÃ§a - HTTPS
* Executando na inicializaÃ§Ã£o
* ReinicializaÃ§Ãµes
* ReplicaÃ§Ã£o (o nÃºmero de processos em execuÃ§Ã£o)
* MemÃ³ria
* Passos anteriores antes de inicializar

## MemÃ³ria

Se vocÃª executar **um Ãºnico processo por contÃªiner**, terÃ¡ uma quantidade mais ou menos bem definida, estÃ¡vel e limitada de memÃ³ria consumida por cada um desses contÃªineres (mais de um se eles forem replicados).

E entÃ£o vocÃª pode definir esses mesmos limites e requisitos de memÃ³ria em suas configuraÃ§Ãµes para seu sistema de gerenciamento de contÃªineres (por exemplo, no **Kubernetes**). Dessa forma, ele poderÃ¡ **replicar os contÃªineres** nas **mÃ¡quinas disponÃ­veis** levando em consideraÃ§Ã£o a quantidade de memÃ³ria necessÃ¡ria por eles e a quantidade disponÃ­vel nas mÃ¡quinas no cluster.

Se sua aplicaÃ§Ã£o for **simples**, isso provavelmente **nÃ£o serÃ¡ um problema**, e vocÃª pode nÃ£o precisar especificar limites de memÃ³ria rÃ­gidos. Mas se vocÃª estiver **usando muita memÃ³ria** (por exemplo, com **modelos de aprendizado de mÃ¡quina**), deve verificar quanta memÃ³ria estÃ¡ consumindo e ajustar o **nÃºmero de contÃªineres** que executa em **cada mÃ¡quina** (e talvez adicionar mais mÃ¡quinas ao seu cluster).

Se vocÃª executar **mÃºltiplos processos por contÃªiner** (por exemplo, com a imagem oficial do Docker), deve garantir que o nÃºmero de processos iniciados nÃ£o **consuma mais memÃ³ria** do que o disponÃ­vel.

## Passos anteriores antes de inicializar e contÃªineres

Se vocÃª estiver usando contÃªineres (por exemplo, Docker, Kubernetes), existem duas abordagens principais que vocÃª pode usar.

### ContÃªineres MÃºltiplos

Se vocÃª tiver **mÃºltiplos contÃªineres**, provavelmente cada um executando um **Ãºnico processo** (por exemplo, em um cluster do **Kubernetes**), entÃ£o provavelmente vocÃª gostaria de ter um **contÃªiner separado** fazendo o trabalho dos **passos anteriores** em um Ãºnico contÃªiner, executando um Ãºnico processo, **antes** de executar os contÃªineres trabalhadores replicados.

!!! info
    Se vocÃª estiver usando o Kubernetes, provavelmente serÃ¡ um <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" class="external-link" target="_blank">Init Container</a>.

Se no seu caso de uso nÃ£o houver problema em executar esses passos anteriores **em paralelo vÃ¡rias vezes** (por exemplo, se vocÃª nÃ£o estiver executando migraÃ§Ãµes de banco de dados, mas apenas verificando se o banco de dados estÃ¡ pronto), entÃ£o vocÃª tambÃ©m pode colocÃ¡-los em cada contÃªiner logo antes de iniciar o processo principal.

### ContÃªiner Ãšnico

Se vocÃª tiver uma configuraÃ§Ã£o simples, com um **Ãºnico contÃªiner** que entÃ£o inicia vÃ¡rios **processos trabalhadores** (ou tambÃ©m apenas um processo), entÃ£o poderia executar esses passos anteriores no mesmo contÃªiner, logo antes de iniciar o processo com o aplicativo. A imagem oficial do Docker suporta isso internamente.

## Imagem Oficial do Docker com Gunicorn - Uvicorn

HÃ¡ uma imagem oficial do Docker que inclui o Gunicorn executando com trabalhadores Uvicorn, conforme detalhado em um capÃ­tulo anterior: [Server Workers - Gunicorn com Uvicorn](./server-workers.md){.internal-link target=_blank}.

Essa imagem seria Ãºtil principalmente nas situaÃ§Ãµes descritas acima em: [ContÃªineres com MÃºltiplos Processos e Casos Especiais](#contÃªineres-com-mÃºltiplos-processos-e-casos-Especiais).

* <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>.

!!! warning
    Existe uma grande chance de que vocÃª **nÃ£o** precise dessa imagem base ou de qualquer outra semelhante, e seria melhor construir a imagem do zero, como [descrito acima em: Construa uma Imagem Docker para o FastAPI](#construa-uma-imagem-docker-para-o-fastapi).

Essa imagem tem um mecanismo de **auto-ajuste** incluÃ­do para definir o **nÃºmero de processos trabalhadores** com base nos nÃºcleos de CPU disponÃ­veis.

Isso tem **padrÃµes sensÃ­veis**, mas vocÃª ainda pode alterar e atualizar todas as configuraÃ§Ãµes com **variÃ¡veis de ambiente** ou arquivos de configuraÃ§Ã£o.

HÃ¡ tambÃ©m suporte para executar <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker#pre_start_path" class="external-link" target="_blank">**passos anteriores antes de iniciar**</a> com um script.

!!! tip
    Para ver todas as configuraÃ§Ãµes e opÃ§Ãµes, vÃ¡ para a pÃ¡gina da imagem Docker:  <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>.

### NÃºmero de Processos na Imagem Oficial do Docker

O **nÃºmero de processos** nesta imagem Ã© **calculado automaticamente** a partir dos **nÃºcleos de CPU** disponÃ­veis.

Isso significa que ele tentarÃ¡ **aproveitar** o mÃ¡ximo de **desempenho** da CPU possÃ­vel.

VocÃª tambÃ©m pode ajustÃ¡-lo com as configuraÃ§Ãµes usando **variÃ¡veis de ambiente**, etc.

Mas isso tambÃ©m significa que, como o nÃºmero de processos depende da CPU do contÃªiner em execuÃ§Ã£o, a **quantidade de memÃ³ria consumida** tambÃ©m dependerÃ¡ disso.

EntÃ£o, se seu aplicativo consumir muito memÃ³ria (por exemplo, com modelos de aprendizado de mÃ¡quina), e seu servidor tiver muitos nÃºcleos de CPU **mas pouca memÃ³ria**, entÃ£o seu contÃªiner pode acabar tentando usar mais memÃ³ria do que estÃ¡ disponÃ­vel e degradar o desempenho muito (ou atÃ© mesmo travar). ğŸš¨

### Criando um `Dockerfile`

Aqui estÃ¡ como vocÃª criaria um `Dockerfile` baseado nessa imagem:

```Dockerfile
FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9

COPY ./requirements.txt /app/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /app/requirements.txt

COPY ./app /app
```

### AplicaÃ§Ãµes Maiores

Se vocÃª seguiu a seÃ§Ã£o sobre a criaÃ§Ã£o de [AplicaÃ§Ãµes Maiores com MÃºltiplos Arquivos](../tutorial/bigger-applications.md){.internal-link target=_blank}, seu `Dockerfile` pode parecer com isso:

```Dockerfile

```Dockerfile hl_lines="7"
FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9

COPY ./requirements.txt /app/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /app/requirements.txt

COPY ./app /app/app
```

### Quando Usar

VocÃª provavelmente **nÃ£o** deve usar essa imagem base oficial (ou qualquer outra semelhante) se estiver usando **Kubernetes** (ou outros) e jÃ¡ estiver definindo **replicaÃ§Ã£o** no nÃ­vel do cluster, com vÃ¡rios **contÃªineres**. Nesses casos, Ã© melhor **construir uma imagem do zero** conforme descrito acima: [Construindo uma Imagem Docker para FastAPI](#construindo-uma-imagem-docker-para-fastapi).

Essa imagem seria Ãºtil principalmente nos casos especiais descritos acima em [ContÃªineres com MÃºltiplos Processos e Casos Especiais](#contÃªineres-com-mÃºltiplos-processos-e-casos-Especiais). Por exemplo, se sua aplicaÃ§Ã£o for **simples o suficiente** para que a configuraÃ§Ã£o padrÃ£o de nÃºmero de processos com base na CPU funcione bem, vocÃª nÃ£o quer se preocupar com a configuraÃ§Ã£o manual da replicaÃ§Ã£o no nÃ­vel do cluster e nÃ£o estÃ¡ executando mais de um contÃªiner com seu aplicativo. Ou se vocÃª estiver implantando com **Docker Compose**, executando em um Ãºnico servidor, etc.

## Deploy da Imagem do ContÃªiner

Depois de ter uma imagem de contÃªiner (Docker), existem vÃ¡rias maneiras de implantÃ¡-la.

Por exemplo:

* Com **Docker Compose** em um Ãºnico servidor
* Com um cluster **Kubernetes**
* Com um cluster Docker Swarm Mode
* Com outra ferramenta como o Nomad
* Com um serviÃ§o de nuvem que pega sua imagem de contÃªiner e a implanta

## Imagem Docker com Poetry

Se vocÃª usa <a href="https://python-poetry.org/" class="external-link" target="_blank">Poetry</a> para gerenciar as dependÃªncias do seu projeto, pode usar a construÃ§Ã£o multi-estÃ¡gio do Docker:

```{ .dockerfile .annotate }
# (1)
FROM python:3.9 as requirements-stage

# (2)
WORKDIR /tmp

# (3)
RUN pip install poetry

# (4)
COPY ./pyproject.toml ./poetry.lock* /tmp/

# (5)
RUN poetry export -f requirements.txt --output requirements.txt --without-hashes

# (6)
FROM python:3.9

# (7)
WORKDIR /code

# (8)
COPY --from=requirements-stage /tmp/requirements.txt /code/requirements.txt

# (9)
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (10)
COPY ./app /code/app

# (11)
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80"]
```

1. Esse Ã© o primeiro estÃ¡gio, ele Ã© chamado `requirements-stage`.

2. Defina `/tmp` como o diretÃ³rio de trabalho atual.

    Aqui Ã© onde geraremos o arquivo `requirements.txt`

3. Instale o Poetry nesse estÃ¡gio do Docker.

4. Copie os arquivos `pyproject.toml` e `poetry.lock` para o diretÃ³rio `/tmp`.

    Porque estÃ¡ usando `./poetry.lock*` (terminando com um `*`), nÃ£o irÃ¡ falhar se esse arquivo ainda nÃ£o estiver disponÃ­vel.

5. Gere o arquivo `requirements.txt`.

6. Este Ã© o estÃ¡gio final, tudo aqui serÃ¡ preservado na imagem final do contÃªiner.

7. Defina o diretÃ³rio de trabalho atual como `/code`.

8. Copie o arquivo `requirements.txt` para o diretÃ³rio `/code`.

    Essse arquivo sÃ³ existe no estÃ¡gio anterior do Docker, Ã© por isso que usamos `--from-requirements-stage` para copiÃ¡-lo.

9. Instale as dependÃªncias de pacote do arquivo `requirements.txt` gerado.

10. Copie o diretÃ³rio `app` para o diretÃ³rio `/code`.

11. Execute o comando `uvicorn`, informando-o para usar o objeto `app` importado de `app.main`.

!!! tip
    Clique nos nÃºmeros das bolhas para ver o que cada linha faz.

Um **estÃ¡gio do Docker** Ã© uma parte de um `Dockerfile` que funciona como uma **imagem temporÃ¡ria do contÃªiner** que sÃ³ Ã© usada para gerar alguns arquivos para serem usados posteriormente.

O primeiro estÃ¡gio serÃ¡ usado apenas para **instalar Poetry** e para **gerar o `requirements.txt`** com as dependÃªncias do seu projeto a partir do arquivo `pyproject.toml` do Poetry.

Esse arquivo `requirements.txt` serÃ¡ usado com `pip` mais tarde no **prÃ³ximo estÃ¡gio**.

Na imagem final do contÃªiner, **somente o estÃ¡gio final** Ã© preservado. Os estÃ¡gios anteriores serÃ£o descartados.

Quando usar Poetry, faz sentido usar **construÃ§Ãµes multi-estÃ¡gio do Docker** porque vocÃª realmente nÃ£o precisa ter o Poetry e suas dependÃªncias instaladas na imagem final do contÃªiner, vocÃª **apenas precisa** ter o arquivo `requirements.txt` gerado para instalar as dependÃªncias do seu projeto.

EntÃ£o, no prÃ³ximo (e Ãºltimo) estÃ¡gio, vocÃª construiria a imagem mais ou menos da mesma maneira descrita anteriormente.

### Por trÃ¡s de um proxy de terminaÃ§Ã£o TLS - Poetry

Novamente, se vocÃª estiver executando seu contÃªiner atrÃ¡s de um proxy de terminaÃ§Ã£o TLS (balanceador de carga) como Nginx ou Traefik, adicione a opÃ§Ã£o `--proxy-headers` ao comando:

```Dockerfile
CMD ["uvicorn", "app.main:app", "--proxy-headers", "--host", "0.0.0.0", "--port", "80"]
```

## Recapitulando

Usando sistemas de contÃªiner (por exemplo, com **Docker** e **Kubernetes**), torna-se bastante simples lidar com todos os **conceitos de implantaÃ§Ã£o**:

* HTTPS
* Executando na inicializaÃ§Ã£o
* ReinÃ­cios
* ReplicaÃ§Ã£o (o nÃºmero de processos rodando)
* MemÃ³ria
* Passos anteriores antes de inicializar

Na maioria dos casos, vocÃª provavelmente nÃ£o desejarÃ¡ usar nenhuma imagem base e, em vez disso, **construir uma imagem de contÃªiner do zero** baseada na imagem oficial do Docker Python.

Tendo cuidado com a **ordem** das instruÃ§Ãµes no `Dockerfile` e o **cache do Docker**, vocÃª pode **minimizar os tempos de construÃ§Ã£o**, para maximizar sua produtividade (e evitar a tÃ©dio). ğŸ˜

Em alguns casos especiais, vocÃª pode querer usar a imagem oficial do Docker para o FastAPI. ğŸ¤“
