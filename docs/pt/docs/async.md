# ConcorrÃªncia e async / await { #concurrency-and-async-await }

Detalhes sobre a sintaxe `async def` para *funÃ§Ãµes de operaÃ§Ã£o de rota* e alguns conceitos de cÃ³digo assÃ­ncrono, concorrÃªncia e paralelismo.

## Com pressa? { #in-a-hurry }

<abbr title="too long; didn't read â€“ muito longo; nÃ£o li"><strong>TL;DR:</strong></abbr>

Se vocÃª estiver utilizando bibliotecas de terceiros que dizem para vocÃª chamar as funÃ§Ãµes com `await`, como:

```Python
results = await some_library()
```

EntÃ£o, declare suas *funÃ§Ãµes de operaÃ§Ã£o de rota* com `async def` como:

```Python hl_lines="2"
@app.get('/')
async def read_results():
    results = await some_library()
    return results
```

/// note | Nota

VocÃª sÃ³ pode usar `await` dentro de funÃ§Ãµes criadas com `async def`.

///

---

Se vocÃª estÃ¡ usando uma biblioteca de terceiros que se comunica com alguma coisa (um banco de dados, uma API, o sistema de arquivos etc.) e nÃ£o tem suporte para utilizar `await` (esse Ã© atualmente o caso para a maioria das bibliotecas de banco de dados), entÃ£o declare suas *funÃ§Ãµes de operaÃ§Ã£o de rota* normalmente, com apenas `def`, como:

```Python hl_lines="2"
@app.get('/')
def results():
    results = some_library()
    return results
```

---

Se sua aplicaÃ§Ã£o (de alguma forma) nÃ£o tem que se comunicar com nada mais e esperar que o respondam, use `async def`, mesmo que vocÃª nÃ£o precise usar `await` dentro dela.

---

Se vocÃª simplesmente nÃ£o sabe, use apenas `def`.

---

**Note**: VocÃª pode misturar `def` e `async def` nas suas *funÃ§Ãµes de operaÃ§Ã£o de rota* tanto quanto necessÃ¡rio e definir cada funÃ§Ã£o usando a melhor opÃ§Ã£o para vocÃª. FastAPI irÃ¡ fazer a coisa certa com elas.

De qualquer forma, em ambos os casos acima, FastAPI irÃ¡ trabalhar assincronamente e ser extremamente rÃ¡pido.

Mas, seguindo os passos acima, ele serÃ¡ capaz de fazer algumas otimizaÃ§Ãµes de performance.

## Detalhes TÃ©cnicos { #technical-details }

VersÃµes modernas de Python tÃªm suporte para **"cÃ³digo assÃ­ncrono"** usando algo chamado **"corrotinas"**, com sintaxe **`async` e `await`**.

Vamos ver aquela frase por partes nas seÃ§Ãµes abaixo:

* **CÃ³digo assÃ­ncrono**
* **`async` e `await`**
* **Corrotinas**

## CÃ³digo assÃ­ncrono { #asynchronous-code }

CÃ³digo assÃ­ncrono apenas significa que a linguagem ğŸ’¬ tem um jeito de dizer para o computador / programa ğŸ¤– que em certo ponto do cÃ³digo, ele ğŸ¤– terÃ¡ que esperar *algo* finalizar em outro lugar. Vamos dizer que esse *algo* seja chamado "arquivo lento" ğŸ“.

EntÃ£o, durante esse tempo, o computador pode ir e fazer outro trabalho, enquanto o "arquivo lento" ğŸ“ termina.

EntÃ£o o computador / programa ğŸ¤– irÃ¡ voltar sempre que tiver uma chance, seja porque ele estÃ¡ esperando novamente, ou quando ele ğŸ¤– terminar todo o trabalho que tem atÃ© esse ponto. E ele ğŸ¤– irÃ¡ ver se alguma das tarefas que estava esperando jÃ¡ terminaram de fazer o que quer que tinham que fazer.

Depois, ele ğŸ¤– pega a primeira tarefa para finalizar (vamos dizer, nosso "arquivo lento" ğŸ“) e continua o que tem que fazer com ela.

Esse "esperar por algo" normalmente se refere a operaÃ§Ãµes <abbr title="Input and Output â€“ Entrada e SaÃ­da">I/O</abbr> que sÃ£o relativamente "lentas" (comparadas Ã  velocidade do processador e da memÃ³ria RAM), como esperar por:

* dados do cliente para serem enviados atravÃ©s da rede
* dados enviados pelo seu programa serem recebidos pelo cliente atravÃ©s da rede
* conteÃºdo de um arquivo no disco ser lido pelo sistema e entregue ao seu programa
* conteÃºdo que seu programa deu ao sistema para ser escrito no disco
* uma operaÃ§Ã£o em uma API remota
* uma operaÃ§Ã£o no banco de dados finalizar
* uma solicitaÃ§Ã£o no banco de dados retornar o resultado
* etc.

Quanto o tempo de execuÃ§Ã£o Ã© consumido majoritariamente pela espera de operaÃ§Ãµes <abbr title="Input and Output â€“ Entrada e SaÃ­da">I/O</abbr>, essas operaÃ§Ãµes sÃ£o chamadas operaÃ§Ãµes "limitadas por I/O".

Isso Ã© chamado de "assÃ­ncrono" porque o computador / programa nÃ£o tem que ser "sincronizado" com a tarefa lenta, esperando pelo momento exato em que a tarefa finaliza, enquanto nÃ£o faz nada, para ser capaz de pegar o resultado da tarefa e dar continuidade ao trabalho.

Ao invÃ©s disso, sendo um sistema "assÃ­ncrono", uma vez finalizada, a tarefa pode esperar na fila um pouco (alguns microssegundos) para que o computador / programa finalize o que quer que esteja fazendo, e entÃ£o volte para pegar o resultado e continue trabalhando com ele.

Para "sÃ­ncrono" (contrÃ¡rio de "assÃ­ncrono") tambÃ©m Ã© utilizado o termo "sequencial", porquÃª o computador / programa segue todos os passos, em sequÃªncia, antes de trocar para uma tarefa diferente, mesmo se alguns passos envolvam esperar.

### ConcorrÃªncia e hambÃºrgueres { #concurrency-and-burgers }

Essa ideia de cÃ³digo **assÃ­ncrono** descrita acima Ã© Ã s vezes chamada de **"concorrÃªncia"**. Isso Ã© diferente de **"paralelismo"**.

**ConcorrÃªncia** e **paralelismo** ambos sÃ£o relacionados a "diferentes coisas acontecendo mais ou menos ao mesmo tempo".

Mas os detalhes entre *concorrÃªncia* e *paralelismo* sÃ£o bem diferentes.

Para ver essa diferenÃ§a, imagine a seguinte histÃ³ria sobre hambÃºrgueres:

### HambÃºrgueres concorrentes { #concurrent-burgers }

VocÃª vai com seu _crush_ na lanchonete, e fica na fila enquanto o caixa pega os pedidos das pessoas na sua frente. ğŸ˜

<img src="/img/async/concurrent-burgers/concurrent-burgers-01.png" class="illustration">

EntÃ£o chega a sua vez, vocÃª pede dois saborosos hambÃºrgueres para vocÃª e seu _crush_.  ğŸ”ğŸ”

<img src="/img/async/concurrent-burgers/concurrent-burgers-02.png" class="illustration">

O caixa diz alguma coisa para o cozinheiro na cozinha para que eles saibam que tÃªm que preparar seus hambÃºrgueres (mesmo que ele esteja atualmente preparando os lanches dos outros clientes).

<img src="/img/async/concurrent-burgers/concurrent-burgers-03.png" class="illustration">

VocÃª paga. ğŸ’¸

O caixa te entrega seu nÃºmero de chamada.

<img src="/img/async/concurrent-burgers/concurrent-burgers-04.png" class="illustration">

Enquanto vocÃª espera, vocÃª vai com seu _crush_ e pega uma mesa, senta e conversa com seu _crush_ por um bom tempo (jÃ¡ que seus hambÃºrgueres sÃ£o muito saborosos, e leva um tempo para serem preparados).

JÃ¡ que vocÃª estÃ¡ sentado na mesa com seu _crush_, esperando os hambÃºrgueres, vocÃª pode passar esse tempo admirando o quÃ£o lindo, maravilhoso e esperto Ã© seu _crush_ âœ¨ğŸ˜âœ¨.

<img src="/img/async/concurrent-burgers/concurrent-burgers-05.png" class="illustration">

Enquanto espera e conversa com seu _crush_, de tempos em tempos, vocÃª verifica o nÃºmero da chamada exibido no balcÃ£o para ver se jÃ¡ Ã© sua vez.

EntÃ£o em algum momento, Ã© finalmente sua vez. VocÃª vai ao balcÃ£o, pega seus hambÃºrgueres e volta para a mesa.

<img src="/img/async/concurrent-burgers/concurrent-burgers-06.png" class="illustration">

VocÃª e seu _crush_ comem os hambÃºrgueres e aproveitam o tempo. âœ¨

<img src="/img/async/concurrent-burgers/concurrent-burgers-07.png" class="illustration">

/// info | InformaÃ§Ã£o

Belas ilustraÃ§Ãµes de <a href="https://www.instagram.com/ketrinadrawsalot" class="external-link" target="_blank">Ketrina Thompson</a>. ğŸ¨

///

---

Imagine que vocÃª seja o computador / programa ğŸ¤– nessa histÃ³ria.

Enquanto vocÃª estÃ¡ na fila, vocÃª estÃ¡ somente ocioso ğŸ˜´, esperando por sua vez, sem fazer nada muito "produtivo". Mas a fila Ã© rÃ¡pida porque o caixa sÃ³ estÃ¡ pegando os pedidos (nÃ£o os preparando), entÃ£o estÃ¡ tudo bem.

EntÃ£o, quando Ã© sua vez, vocÃª faz trabalho realmente "produtivo", vocÃª processa o menu, decide o que quer, pega a escolha de seu _crush_, paga, verifica se entregou o cartÃ£o ou a cÃ©dula correta, verifica se foi cobrado corretamente, verifica se seu pedido estÃ¡ correto etc.

Mas entÃ£o, embora vocÃª ainda nÃ£o tenha os hambÃºrgueres, seu trabalho no caixa estÃ¡ "pausado" â¸, porque vocÃª tem que esperar ğŸ•™ seus hambÃºrgueres ficarem prontos.

Contudo, Ã  medida que vocÃª se afasta do balcÃ£o e senta na mesa, com um nÃºmero para sua chamada, vocÃª pode trocar ğŸ”€ sua atenÃ§Ã£o para seu _crush_, e "trabalhar" â¯ ğŸ¤“ nisso. EntÃ£o vocÃª estÃ¡ novamente fazendo algo muito "produtivo", como flertar com seu _crush_ ğŸ˜.

EntÃ£o o caixa ğŸ’ diz que "seus hambÃºrgueres estÃ£o prontos" colocando seu nÃºmero no balcÃ£o, mas vocÃª nÃ£o corre que nem um maluco imediatamente quando o nÃºmero exibido Ã© o seu. VocÃª sabe que ninguÃ©m irÃ¡ roubar seus hambÃºrgueres porque vocÃª tem o seu nÃºmero da chamada, e os outros tÃªm os deles.

EntÃ£o vocÃª espera seu _crush_ terminar a histÃ³ria que estava contando (terminar o trabalho atual â¯ / tarefa sendo processada ğŸ¤“), sorri gentilmente e diz que vocÃª estÃ¡ indo buscar os hambÃºrgueres â¸.

EntÃ£o vocÃª vai ao balcÃ£o ğŸ”€, para a tarefa inicial que agora estÃ¡ finalizada â¯, pega os hambÃºrgueres, agradece, e leva-os para a mesa. Isso finaliza esse passo / tarefa da interaÃ§Ã£o com o balcÃ£o â¹. Isso, por sua vez, cria uma nova tarefa, a de "comer hambÃºrgueres" ğŸ”€ â¯, mas a tarefa anterior de "pegar os hambÃºrgueres" jÃ¡ estÃ¡ finalizada â¹.

### HambÃºrgueres paralelos { #parallel-burgers }

Agora vamos imaginar que esses nÃ£o sÃ£o "HambÃºrgueres Concorrentes", e sim "HambÃºrgueres Paralelos".

VocÃª vai com seu _crush_ na lanchonete paralela.

VocÃª fica na fila enquanto vÃ¡rios (vamos dizer 8) caixas que tambÃ©m sÃ£o cozinheiros pegam os pedidos das pessoas na sua frente.

Todo mundo na sua frente estÃ¡ esperando seus hambÃºrgueres ficarem prontos antes de deixar o caixa porque cada um dos 8 caixas vai e prepara o hambÃºrguer logo apÃ³s receber o pedido, antes de pegar o prÃ³ximo pedido.

<img src="/img/async/parallel-burgers/parallel-burgers-01.png" class="illustration">

EntÃ£o Ã© finalmente sua vez, vocÃª pede 2 hambÃºrgueres muito saborosos para vocÃª e seu _crush_.

VocÃª paga ğŸ’¸.

<img src="/img/async/parallel-burgers/parallel-burgers-02.png" class="illustration">

O caixa vai para a cozinha.

VocÃª espera, na frente do balcÃ£o ğŸ•™, para que ninguÃ©m pegue seus hambÃºrgueres antes de vocÃª, jÃ¡ que nÃ£o tem nÃºmeros de chamadas.

<img src="/img/async/parallel-burgers/parallel-burgers-03.png" class="illustration">

Como vocÃª e seu _crush_ estÃ£o ocupados nÃ£o permitindo que ninguÃ©m passe na frente e pegue seus hambÃºrgueres assim que estiverem prontos, vocÃª nÃ£o pode dar atenÃ§Ã£o ao seu _crush_. ğŸ˜

Isso Ã© trabalho "sÃ­ncrono", vocÃª estÃ¡ "sincronizado" com o caixa / cozinheiro ğŸ‘¨â€ğŸ³. VocÃª tem que esperar ğŸ•™ e estar lÃ¡ no exato momento que o caixa / cozinheiro ğŸ‘¨â€ğŸ³ terminar os hambÃºrgueres e os der a vocÃª, ou entÃ£o, outro alguÃ©m pode pegÃ¡-los.

<img src="/img/async/parallel-burgers/parallel-burgers-04.png" class="illustration">

EntÃ£o seu caixa / cozinheiro ğŸ‘¨â€ğŸ³ finalmente volta com seus hambÃºrgueres, depois de um longo tempo esperando ğŸ•™ por eles em frente ao balcÃ£o.

<img src="/img/async/parallel-burgers/parallel-burgers-05.png" class="illustration">

VocÃª pega seus hambÃºrgueres e vai para a mesa com seu _crush_.

VocÃªs comem os hambÃºrgueres, e o trabalho estÃ¡ terminado. â¹

<img src="/img/async/parallel-burgers/parallel-burgers-06.png" class="illustration">

NÃ£o houve muita conversa ou flerte jÃ¡ que a maior parte do tempo foi gasto esperando ğŸ•™ na frente do balcÃ£o. ğŸ˜

/// info | InformaÃ§Ã£o

Belas ilustraÃ§Ãµes de <a href="https://www.instagram.com/ketrinadrawsalot" class="external-link" target="_blank">Ketrina Thompson</a>. ğŸ¨

///

---

Nesse cenÃ¡rio dos hambÃºrgueres paralelos, vocÃª Ã© um computador / programa ğŸ¤– com dois processadores (vocÃª e seu _crush_), ambos esperando ğŸ•™ e dedicando sua atenÃ§Ã£o â¯ "esperando no balcÃ£o" ğŸ•™ por um bom tempo.

A lanchonete paralela tem 8 processadores (caixas / cozinheiros), enquanto a lanchonete dos hambÃºrgueres concorrentes tinha apenas 2 (um caixa e um cozinheiro).

Ainda assim, a experiÃªncia final nÃ£o foi a melhor. ğŸ˜

---

Essa seria o equivalente paralelo Ã  histÃ³ria dos hambÃºrgueres. ğŸ”

Para um exemplo "mais real", imagine um banco.

AtÃ© recentemente, a maioria dos bancos tinham muitos caixas ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ e uma grande fila ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™.

Todos os caixas fazendo todo o trabalho, um cliente apÃ³s o outro ğŸ‘¨â€ğŸ’¼â¯.

E vocÃª tinha que esperar ğŸ•™ na fila por um longo tempo ou poderia perder a vez.

VocÃª provavelmente nÃ£o gostaria de levar seu _crush_ ğŸ˜ com vocÃª para um rolezinho no banco ğŸ¦.

### ConclusÃ£o dos hambÃºrgueres { #burger-conclusion }

Nesse cenÃ¡rio dos "hambÃºrgueres com seu _crush_", como tem muita espera, faz mais sentido ter um sistema concorrente â¸ğŸ”€â¯.

Esse Ã© o caso da maioria das aplicaÃ§Ãµes web.

Muitos, muitos usuÃ¡rios, mas seu servidor estÃ¡ esperando ğŸ•™ pela sua conexÃ£o nÃ£o tÃ£o boa enviar suas requisiÃ§Ãµes.

E entÃ£o esperando ğŸ•™ novamente as respostas voltarem.

Essa "espera" ğŸ•™ Ã© medida em microssegundos, mas ainda assim, somando tudo, Ã© um monte de espera no final.

Por isso que faz bastante sentido utilizar cÃ³digo assÃ­ncrono â¸ğŸ”€â¯ para APIs web.

Esse tipo de assincronicidade Ã© o que fez NodeJS popular (embora NodeJS nÃ£o seja paralelo) e essa Ã© a forÃ§a do Go como uma linguagem de programaÃ§Ã£o.

E esse Ã© o mesmo nÃ­vel de performance que vocÃª tem com o **FastAPI**.

E como vocÃª pode ter paralelismo e assincronicidade ao mesmo tempo, vocÃª tem uma maior performance do que a maioria dos frameworks NodeJS testados e lado a lado com Go, que Ã© uma linguagem compilada, mais prÃ³xima ao C <a href="https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query&l=zijmkf-1" class="external-link" target="_blank">(tudo graÃ§as ao Starlette)</a>.

### ConcorrÃªncia Ã© melhor que paralelismo? { #is-concurrency-better-than-parallelism }

NÃ£o! Essa nÃ£o Ã© a moral da histÃ³ria.

ConcorrÃªncia Ã© diferente de paralelismo. E Ã© melhor em cenÃ¡rios **especÃ­ficos** que envolvam um monte de espera. Por isso, geralmente Ã© muito melhor do que paralelismo para desenvolvimento de aplicaÃ§Ãµes web. Mas nÃ£o para tudo.

EntÃ£o, para equilibrar tudo, imagine a seguinte historinha:

> VocÃª tem que limpar uma casa grande e suja.

*Sim, essa Ã© toda a histÃ³ria*.

---

NÃ£o hÃ¡ espera ğŸ•™ em lugar algum, apenas um monte de trabalho para ser feito, em mÃºltiplos cÃ´modos da casa.

VocÃª poderia ter turnos como no exemplo dos hambÃºrgueres, primeiro a sala de estar, entÃ£o a cozinha, mas como vocÃª nÃ£o estÃ¡ esperando por nada, apenas limpando e limpando, as chamadas nÃ£o afetariam em nada.

Levaria o mesmo tempo para finalizar com ou sem turnos (concorrÃªncia) e vocÃª teria feito o mesmo tanto de trabalho.

Mas nesse caso, se vocÃª trouxesse os 8 ex-caixas / cozinheiros / agora-faxineiros, e cada um deles (mais vocÃª) pudessem dividir a casa para limpÃ¡-la, vocÃªs fariam toda a limpeza em **paralelo**, com a ajuda extra, e terminariam muito mais cedo.

Nesse cenÃ¡rio, cada um dos faxineiros (incluindo vocÃª) poderia ser um processador, fazendo a sua parte do trabalho.

E a maior parte do tempo de execuÃ§Ã£o Ã© tomada por trabalho real (ao invÃ©s de ficar esperando), e o trabalho em um computador Ã© feito pela <abbr title="Central Processing Unit â€“ Unidade Central de Processamento">CPU</abbr>. Eles chamam esses problemas de "limitados por CPU".

---

Exemplos comuns de operaÃ§Ãµes limitadas por CPU sÃ£o coisas que exigem processamento matemÃ¡tico complexo.

Por exemplo:

* **Processamento de Ã¡udio** ou **imagem**
* **VisÃ£o Computacional**: uma imagem Ã© composta por milhÃµes de pixels, cada pixel tem 3 valores / cores, processar isso normalmente exige alguma computaÃ§Ã£o em todos esses pixels ao mesmo tempo
* **Aprendizado de MÃ¡quina**: Normalmente exige muita multiplicaÃ§Ã£o de matrizes e vetores. Pense numa grande planilha com nÃºmeros e em multiplicar todos eles juntos e ao mesmo tempo.
* **Deep Learning**: Esse Ã© um subcampo do Aprendizado de MÃ¡quina, entÃ£o, o mesmo se aplica. A diferenÃ§a Ã© que nÃ£o hÃ¡ apenas uma grande planilha com nÃºmeros para multiplicar, mas um grande conjunto delas, e em muitos casos, vocÃª utiliza um processador especial para construir e/ou usar esses modelos.

### ConcorrÃªncia + Paralelismo: Web + Aprendizado de MÃ¡quina { #concurrency-parallelism-web-machine-learning }

Com **FastAPI** vocÃª pode levar a vantagem da concorrÃªncia que Ã© muito comum para desenvolvimento web (o mesmo atrativo de NodeJS).

Mas vocÃª tambÃ©m pode explorar os benefÃ­cios do paralelismo e multiprocessamento (tendo mÃºltiplos processadores rodando em paralelo) para trabalhos **limitados por CPU** como aqueles em sistemas de Aprendizado de MÃ¡quina.

Isso, somado ao simples fato que Python Ã© a principal linguagem para **Data Science**, Aprendizado de MÃ¡quina e especialmente Deep Learning, faz do FastAPI uma Ã³tima escolha para APIs web e aplicaÃ§Ãµes com Data Science / Aprendizado de MÃ¡quina (entre muitas outras).

Para ver como alcanÃ§ar esse paralelismo em produÃ§Ã£o veja a seÃ§Ã£o sobre [ImplantaÃ§Ã£o](deployment/index.md){.internal-link target=_blank}.

## `async` e `await` { #async-and-await }

VersÃµes modernas do Python tÃªm um modo muito intuitivo para definir cÃ³digo assÃ­ncrono. Isso faz parecer do mesmo jeito do cÃ³digo normal "sequencial" e fazer a "espera" para vocÃª nos momentos certos.

Quando tem uma operaÃ§Ã£o que exigirÃ¡ espera antes de dar os resultados e tem suporte para esses novos recursos do Python, vocÃª pode escrever assim:

```Python
burgers = await get_burgers(2)
```

A chave aqui Ã© o `await`. Ele diz ao Python que ele tem que esperar â¸ por `get_burgers(2)` finalizar suas coisas ğŸ•™ antes de armazenar os resultados em `burgers`. Com isso, o Python saberÃ¡ que ele pode ir e fazer outras coisas ğŸ”€ â¯ nesse meio tempo (como receber outra requisiÃ§Ã£o).

Para o `await` funcionar, tem que estar dentro de uma funÃ§Ã£o que suporte essa assincronicidade. Para fazer isso, apenas declare a funÃ§Ã£o com `async def`:

```Python hl_lines="1"
async def get_burgers(number: int):
    # Faz alguma coisa assÃ­ncrona para criar os hambÃºrgueres
    return burgers
```

...ao invÃ©s de `def`:

```Python hl_lines="2"
# Isso nÃ£o Ã© assÃ­ncrono
def get_sequential_burgers(number: int):
    # Faz alguma coisa sequencial para criar os hambÃºrgueres
    return burgers
```

Com `async def`, o Python sabe que, dentro dessa funÃ§Ã£o, ele deve estar ciente das expressÃµes `await`, e que isso poderÃ¡ "pausar" â¸ a execuÃ§Ã£o dessa funÃ§Ã£o, e ir fazer outra coisa ğŸ”€ antes de voltar.

Quando vocÃª quiser chamar uma funÃ§Ã£o `async def`, vocÃª tem que "esperar" ela. EntÃ£o, isso nÃ£o funcionarÃ¡:

```Python
# Isso nÃ£o irÃ¡ funcionar, porquÃª get_burgers foi definido com: async def
burgers = get_burgers(2)
```

---

EntÃ£o, se vocÃª estÃ¡ usando uma biblioteca que diz que vocÃª pode chamÃ¡-la com `await`, vocÃª precisa criar as *funÃ§Ãµes de operaÃ§Ã£o de rota* com `async def`, como em:

```Python hl_lines="2-3"
@app.get('/burgers')
async def read_burgers():
    burgers = await get_burgers(2)
    return burgers
```

### Mais detalhes tÃ©cnicos { #more-technical-details }

VocÃª deve ter observado que `await` pode ser usado somente dentro de funÃ§Ãµes definidas com `async def`.

Mas ao mesmo tempo, funÃ§Ãµes definidas com `async def` tÃªm que ser "aguardadas". EntÃ£o, funÃ§Ãµes com `async def` podem ser chamadas somente dentro de funÃ§Ãµes definidas com `async def` tambÃ©m.

EntÃ£o, sobre o ovo e a galinha, como vocÃª chama a primeira funÃ§Ã£o async?

Se vocÃª estivar trabalhando com **FastAPI** nÃ£o terÃ¡ que se preocupar com isso, porquÃª essa "primeira" funÃ§Ã£o serÃ¡ a sua *funÃ§Ã£o de operaÃ§Ã£o de rota*, e o FastAPI saberÃ¡ como fazer a coisa certa.

Mas se vocÃª quiser usar `async` / `await` sem FastAPI, vocÃª tambÃ©m pode fazÃª-lo.

### Escreva seu prÃ³prio cÃ³digo assÃ­ncrono { #write-your-own-async-code }

Starlette (e **FastAPI**) sÃ£o baseados no <a href="https://anyio.readthedocs.io/en/stable/" class="external-link" target="_blank">AnyIO</a>, o que o torna compatÃ­vel com ambos o <a href="https://docs.python.org/3/library/asyncio-task.html" class="external-link" target="_blank">asyncio</a> da biblioteca padrÃ£o do Python, e o <a href="https://trio.readthedocs.io/en/stable/" class="external-link" target="_blank">Trio</a>.

Em particular, vocÃª pode usar diretamente o <a href="https://anyio.readthedocs.io/en/stable/" class="external-link" target="_blank">AnyIO</a> para seus casos de uso avanÃ§ados de concorrÃªncia que requerem padrÃµes mais avanÃ§ados no seu prÃ³prio cÃ³digo.

E atÃ© se vocÃª nÃ£o estiver utilizando FastAPI, vocÃª tambÃ©m pode escrever suas prÃ³prias aplicaÃ§Ãµes assÃ­ncronas com o <a href="https://anyio.readthedocs.io/en/stable/" class="external-link" target="_blank">AnyIO</a> por ser altamente compatÃ­vel e ganhar seus benefÃ­cios (e.g. *concorrÃªncia estruturada*).

Eu criei outra biblioteca em cima do AnyIO, como uma fina camada acima, para melhorar um pouco as anotaÃ§Ãµes de tipo e obter melhor **preenchimento automÃ¡tico**, **erros inline**, etc. Ela tambÃ©m possui uma introduÃ§Ã£o amigÃ¡vel e um tutorial para ajudar vocÃª a **entender** e escrever **seu prÃ³prio cÃ³digo async**: <a href="https://asyncer.tiangolo.com/" class="external-link" target="_blank">Asyncer</a>. Seria particularmente Ãºtil se vocÃª precisar **combinar cÃ³digo async com cÃ³digo regular** (bloqueador/sÃ­ncrono).

### Outras formas de cÃ³digo assÃ­ncrono { #other-forms-of-asynchronous-code }

Esse estilo de usar `async` e `await` Ã© relativamente novo na linguagem.

Mas ele faz o trabalho com cÃ³digo assÃ­ncrono muito mais fÃ¡cil.

Essa mesma sintaxe (ou quase a mesma) foi tambÃ©m incluÃ­da recentemente em versÃµes modernas do JavaScript (no navegador e NodeJS).

Mas antes disso, controlar cÃ³digo assÃ­ncrono era bem mais complexo e difÃ­cil.

Nas versÃµes anteriores do Python, vocÃª poderia utilizar threads ou <a href="https://www.gevent.org/" class="external-link" target="_blank">Gevent</a>. Mas o cÃ³digo Ã© bem mais complexo de entender, debugar, e pensar sobre.

Nas versÃµes anteriores do NodeJS / Navegador JavaScript, vocÃª utilizaria "callbacks". O que leva ao "inferno do callback".

## Corrotinas { #coroutines }

**Corrotina** Ã© apenas um jeito bonitinho para a coisa que Ã© retornada de uma funÃ§Ã£o `async def`. O Python sabe que Ã© algo como uma funÃ§Ã£o, que pode comeÃ§ar e que vai terminar em algum ponto, mas que pode ser pausada â¸ internamente tambÃ©m, sempre que tiver um `await` dentro dela.

Mas toda essa funcionalidade de cÃ³digo assÃ­ncrono com `async` e `await` Ã© muitas vezes resumida como usando "corrotinas". Ã‰ comparÃ¡vel ao principal recurso chave do Go, a "Gorrotina".

## ConclusÃ£o { #conclusion }

Vamos ver a mesma frase de cima:

> VersÃµes modernas do Python tÃªm suporte para **"cÃ³digo assÃ­ncrono"** usando algo chamado **"corrotinas"**, com sintaxe **`async` e `await`**.

Isso pode fazer mais sentido agora. âœ¨

Tudo isso Ã© o que empodera o FastAPI (atravÃ©s do Starlette) e que o faz ter uma performance tÃ£o impressionante.

## Detalhes muito tÃ©cnicos { #very-technical-details }

/// warning | AtenÃ§Ã£o

VocÃª pode provavelmente pular isso.

Esses sÃ£o detalhes muito tÃ©cnicos de como **FastAPI** funciona por baixo do capÃ´.

Se vocÃª tem certo conhecimento tÃ©cnico (corrotinas, threads, blocking etc) e estÃ¡ curioso sobre como o FastAPI controla o `async def` vs normal `def`, vÃ¡ em frente.

///

### FunÃ§Ãµes de operaÃ§Ã£o de rota { #path-operation-functions }

Quando vocÃª declara uma *funÃ§Ã£o de operaÃ§Ã£o de rota* com `def` normal ao invÃ©s de `async def`, ela Ã© rodada em uma threadpool externa que Ã© entÃ£o aguardada, ao invÃ©s de ser chamada diretamente (jÃ¡ que ela bloquearia o servidor).

Se vocÃª estÃ¡ chegando de outro framework assÃ­ncrono que nÃ£o funciona como descrito acima e vocÃª estÃ¡ acostumado a definir *funÃ§Ãµes de operaÃ§Ã£o de rota* triviais somente de computaÃ§Ã£o com simples `def` para ter um mÃ­nimo ganho de performance (cerca de 100 nanosegundos), por favor observe que no **FastAPI** o efeito pode ser bem o oposto. Nesses casos, Ã© melhor usar `async def` a menos que suas *funÃ§Ãµes de operaÃ§Ã£o de rota* utilizem cÃ³digo que performe bloqueamento <abbr title="Input/Output â€“ Entrada e SaÃ­da: leitura ou escrita no disco, comunicaÃ§Ãµes de rede.">I/O</abbr>.

Ainda, em ambas as situaÃ§Ãµes, as chances sÃ£o que o **FastAPI** [ainda serÃ¡ mais rÃ¡pido](index.md#performance){.internal-link target=_blank} do que (ou ao menos comparÃ¡vel a) seu framework anterior.

### DependÃªncias { #dependencies }

O mesmo se aplica para as [dependÃªncias](tutorial/dependencies/index.md){.internal-link target=_blank}. Se uma dependÃªncia tem as funÃ§Ãµes com padrÃ£o `def` ao invÃ©s de `async def`, ela Ã© rodada no threadpool externo.

### Sub-dependÃªncias { #sub-dependencies }

VocÃª pode ter mÃºltiplas dependÃªncias e [sub-dependÃªncias](tutorial/dependencies/sub-dependencies.md){.internal-link target=_blank} requisitando uma Ã  outra (como parÃ¢metros de definiÃ§Ãµes de funÃ§Ãµes), algumas delas podem ser criadas com `async def` e algumas com `def` normal. Isso ainda funcionaria, e aquelas criadas com `def` normal seriam chamadas em uma thread externa (do threadpool) ao invÃ©s de serem "aguardadas".

### Outras funÃ§Ãµes de utilidade { #other-utility-functions }

Qualquer outra funÃ§Ã£o de utilidade que vocÃª chame diretamente pode ser criada com `def` normal ou `async def` e o FastAPI nÃ£o irÃ¡ afetar o modo como vocÃª a chama.

Isso estÃ¡ em contraste Ã s funÃ§Ãµes que o FastAPI chama para vocÃª: *funÃ§Ãµes de operaÃ§Ã£o de rota* e dependÃªncias.

Se sua funÃ§Ã£o de utilidade Ã© uma funÃ§Ã£o normal com `def`, ela serÃ¡ chamada diretamente (como vocÃª a escreve no cÃ³digo), nÃ£o em uma threadpool, se a funÃ§Ã£o Ã© criada com `async def` entÃ£o vocÃª deve esperar por essa funÃ§Ã£o quando vocÃª chamÃ¡-la no seu cÃ³digo.

---

Novamente, esses sÃ£o detalhes muito tÃ©cnicos que provavelmente seriam Ãºteis caso vocÃª esteja procurando por eles.

Caso contrÃ¡rio, vocÃª deve ficar bem com as dicas da seÃ§Ã£o acima: <a href="#in-a-hurry">Com pressa?</a>.
