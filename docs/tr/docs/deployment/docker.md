# Container'larda FastAPI - Docker { #fastapi-in-containers-docker }

FastAPI uygulamalarÄ±nÄ± deploy ederken yaygÄ±n bir yaklaÅŸÄ±m, bir **Linux container image** oluÅŸturmaktÄ±r. Bu genellikle <a href="https://www.docker.com/" class="external-link" target="_blank">**Docker**</a> kullanÄ±larak yapÄ±lÄ±r. ArdÄ±ndan bu container image'Ä± birkaÃ§ farklÄ± yÃ¶ntemden biriyle deploy edebilirsiniz.

Linux container'larÄ± kullanmanÄ±n **gÃ¼venlik**, **tekrarlanabilirlik**, **basitlik** gibi birÃ§ok avantajÄ± vardÄ±r.

/// tip | Ä°pucu

Aceleniz var ve bunlarÄ± zaten biliyor musunuz? AÅŸaÄŸÄ±daki [`Dockerfile`'a atlayÄ±n ğŸ‘‡](#build-a-docker-image-for-fastapi).

///

<details>
<summary>Dockerfile Ã–nizleme ğŸ‘€</summary>

```Dockerfile
FROM python:3.14

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

CMD ["fastapi", "run", "app/main.py", "--port", "80"]

# If running behind a proxy like Nginx or Traefik add --proxy-headers
# CMD ["fastapi", "run", "app/main.py", "--port", "80", "--proxy-headers"]
```

</details>

## Container Nedir { #what-is-a-container }

Container'lar (Ã¶zellikle Linux container'larÄ±), bir uygulamayÄ± tÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ± ve gerekli dosyalarÄ±yla birlikte paketlemenin, aynÄ± sistemdeki diÄŸer container'lardan (diÄŸer uygulama ya da bileÅŸenlerden) izole tutarken yapÄ±lan, Ã§ok **hafif** bir yoludur.

Linux container'larÄ±, host'un (makine, sanal makine, cloud server vb.) aynÄ± Linux kernel'ini kullanarak Ã§alÄ±ÅŸÄ±r. Bu da, tÃ¼m bir iÅŸletim sistemini emÃ¼le eden tam sanal makinelere kÄ±yasla Ã§ok daha hafif olduklarÄ± anlamÄ±na gelir.

Bu sayede container'lar **az kaynak** tÃ¼ketir; sÃ¼reÃ§leri doÄŸrudan Ã§alÄ±ÅŸtÄ±rmaya benzer bir seviyede (bir sanal makine Ã§ok daha fazla tÃ¼ketirdi).

Container'larÄ±n ayrÄ±ca kendi **izole** Ã§alÄ±ÅŸan process'leri (Ã§oÄŸunlukla tek bir process), dosya sistemi ve aÄŸÄ± vardÄ±r. Bu da deployment, gÃ¼venlik, geliÅŸtirme vb. sÃ¼reÃ§leri kolaylaÅŸtÄ±rÄ±r.

## Container Image Nedir { #what-is-a-container-image }

Bir **container**, bir **container image**'dan Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.

Container image; bir container iÃ§inde bulunmasÄ± gereken tÃ¼m dosyalarÄ±n, environment variable'larÄ±n ve varsayÄ±lan komut/programÄ±n **statik** bir sÃ¼rÃ¼mÃ¼dÃ¼r. Buradaki **statik**, container **image**'Ä±nÄ±n Ã§alÄ±ÅŸmadÄ±ÄŸÄ±, execute edilmediÄŸi; sadece paketlenmiÅŸ dosyalar ve metadata olduÄŸu anlamÄ±na gelir.

DepolanmÄ±ÅŸ statik iÃ§erik olan "**container image**"Ä±n aksine, "**container**" normalde Ã§alÄ±ÅŸan instance'Ä±, yani **execute edilen** ÅŸeyi ifade eder.

**Container** baÅŸlatÄ±lÄ±p Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda (bir **container image**'dan baÅŸlatÄ±lÄ±r), dosyalar oluÅŸturabilir/deÄŸiÅŸtirebilir, environment variable'larÄ± deÄŸiÅŸtirebilir vb. Bu deÄŸiÅŸiklikler sadece o container iÃ§inde kalÄ±r; alttaki container image'da kalÄ±cÄ± olmaz (diske kaydedilmez).

Bir container image, **program** dosyasÄ± ve iÃ§eriklerine benzetilebilir; Ã¶rn. `python` ve `main.py` gibi bir dosya.

Ve **container**'Ä±n kendisi (container image'a karÅŸÄ±t olarak) image'Ä±n gerÃ§ek Ã§alÄ±ÅŸan instance'Ä±dÄ±r; bir **process**'e benzer. Hatta bir container, yalnÄ±zca iÃ§inde **Ã§alÄ±ÅŸan bir process** varken Ã§alÄ±ÅŸÄ±r (ve genelde tek process olur). Ä°Ã§inde Ã§alÄ±ÅŸan process kalmayÄ±nca container durur.

## Container Image'lar { #container-images }

Docker, **container image** ve **container** oluÅŸturup yÃ¶netmek iÃ§in kullanÄ±lan baÅŸlÄ±ca araÃ§lardan biri olmuÅŸtur.

AyrÄ±ca birÃ§ok araÃ§, ortam, veritabanÄ± ve uygulama iÃ§in Ã¶nceden hazÄ±rlanmÄ±ÅŸ **resmi container image**'larÄ±n bulunduÄŸu herkese aÃ§Ä±k bir <a href="https://hub.docker.com/" class="external-link" target="_blank">Docker Hub</a> vardÄ±r.

Ã–rneÄŸin, resmi bir <a href="https://hub.docker.com/_/python" class="external-link" target="_blank">Python Image</a> bulunur.

Ve veritabanlarÄ± gibi farklÄ± ÅŸeyler iÃ§in de birÃ§ok image vardÄ±r; Ã¶rneÄŸin:

* <a href="https://hub.docker.com/_/postgres" class="external-link" target="_blank">PostgreSQL</a>
* <a href="https://hub.docker.com/_/mysql" class="external-link" target="_blank">MySQL</a>
* <a href="https://hub.docker.com/_/mongo" class="external-link" target="_blank">MongoDB</a>
* <a href="https://hub.docker.com/_/redis" class="external-link" target="_blank">Redis</a>, vb.

HazÄ±r bir container image kullanarak farklÄ± araÃ§larÄ± **birleÅŸtirmek** ve birlikte kullanmak Ã§ok kolaydÄ±r. Ã–rneÄŸin yeni bir veritabanÄ±nÄ± denemek iÃ§in. Ã‡oÄŸu durumda **resmi image**'larÄ± kullanÄ±p sadece environment variable'lar ile yapÄ±landÄ±rmanÄ±z yeterlidir.

Bu ÅŸekilde, Ã§oÄŸu zaman container'lar ve Docker hakkÄ±nda Ã¶ÄŸrendiklerinizi farklÄ± araÃ§ ve bileÅŸenlerde tekrar kullanabilirsiniz.

DolayÄ±sÄ±yla; veritabanÄ±, Python uygulamasÄ±, React frontend uygulamasÄ± olan bir web server gibi farklÄ± ÅŸeyler iÃ§in **birden fazla container** Ã§alÄ±ÅŸtÄ±rÄ±r ve bunlarÄ± internal network Ã¼zerinden birbirine baÄŸlarsÄ±nÄ±z.

Docker veya Kubernetes gibi tÃ¼m container yÃ¶netim sistemlerinde bu aÄŸ Ã¶zellikleri entegre olarak bulunur.

## Container'lar ve Process'ler { #containers-and-processes }

Bir **container image** normalde metadata iÃ§inde, **container** baÅŸlatÄ±ldÄ±ÄŸÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±lacak varsayÄ±lan program/komutu ve o programa geÃ§irilecek parametreleri iÃ§erir. Bu, komut satÄ±rÄ±nda yazacaÄŸÄ±nÄ±z ÅŸeye Ã§ok benzer.

Bir **container** baÅŸlatÄ±ldÄ±ÄŸÄ±nda bu komutu/programÄ± Ã§alÄ±ÅŸtÄ±rÄ±r (ancak isterseniz bunu override edip baÅŸka bir komut/program Ã§alÄ±ÅŸtÄ±rabilirsiniz).

Bir container, **ana process** (komut/program) Ã§alÄ±ÅŸtÄ±ÄŸÄ± sÃ¼rece Ã§alÄ±ÅŸÄ±r.

Container'larda normalde **tek bir process** olur. Ancak ana process iÃ§inden subprocess'ler baÅŸlatmak da mÃ¼mkÃ¼ndÃ¼r; bÃ¶ylece aynÄ± container iÃ§inde **birden fazla process** olur.

Ama **en az bir Ã§alÄ±ÅŸan process olmadan** Ã§alÄ±ÅŸan bir container olamaz. Ana process durursa container da durur.

## FastAPI iÃ§in Docker Image OluÅŸturalÄ±m { #build-a-docker-image-for-fastapi }

Tamam, ÅŸimdi bir ÅŸeyler inÅŸa edelim! ğŸš€

Resmi **Python** image'Ä±nÄ± temel alarak, FastAPI iÃ§in **sÄ±fÄ±rdan** bir **Docker image** nasÄ±l oluÅŸturulur gÃ¶stereceÄŸim.

Bu, Ã¶rneÄŸin ÅŸu durumlarda **Ã§oÄŸu zaman** yapmak isteyeceÄŸiniz ÅŸeydir:

* **Kubernetes** veya benzeri araÃ§lar kullanÄ±rken
* **Raspberry Pi** Ã¼zerinde Ã§alÄ±ÅŸtÄ±rÄ±rken
* Container image'Ä±nÄ±zÄ± sizin iÃ§in Ã§alÄ±ÅŸtÄ±ran bir cloud servisi kullanÄ±rken, vb.

### Paket Gereksinimleri { #package-requirements }

UygulamanÄ±zÄ±n **paket gereksinimleri** genelde bir dosyada yer alÄ±r.

Bu, gereksinimleri **yÃ¼klemek** iÃ§in kullandÄ±ÄŸÄ±nÄ±z araca gÃ¶re deÄŸiÅŸir.

En yaygÄ±n yÃ¶ntem, paket adlarÄ± ve versiyonlarÄ±nÄ±n satÄ±r satÄ±r yazÄ±ldÄ±ÄŸÄ± bir `requirements.txt` dosyasÄ±na sahip olmaktÄ±r.

Versiyon aralÄ±klarÄ±nÄ± belirlemek iÃ§in elbette [FastAPI sÃ¼rÃ¼mleri hakkÄ±nda](versions.md){.internal-link target=_blank} bÃ¶lÃ¼mÃ¼nde okuduÄŸunuz fikirleri kullanÄ±rsÄ±nÄ±z.

Ã–rneÄŸin `requirements.txt` ÅŸÃ¶yle gÃ¶rÃ¼nebilir:

```
fastapi[standard]>=0.113.0,<0.114.0
pydantic>=2.7.0,<3.0.0
```

Ve bu baÄŸÄ±mlÄ±lÄ±klarÄ± normalde `pip` ile yÃ¼klersiniz, Ã¶rneÄŸin:

<div class="termy">

```console
$ pip install -r requirements.txt
---> 100%
Successfully installed fastapi pydantic
```

</div>

/// info | Bilgi

Paket baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± tanÄ±mlamak ve yÃ¼klemek iÃ§in baÅŸka formatlar ve araÃ§lar da vardÄ±r.

///

### **FastAPI** Kodunu OluÅŸturun { #create-the-fastapi-code }

* Bir `app` dizini oluÅŸturun ve iÃ§ine girin.
* BoÅŸ bir `__init__.py` dosyasÄ± oluÅŸturun.
* AÅŸaÄŸÄ±dakilerle bir `main.py` dosyasÄ± oluÅŸturun:

```Python
from fastapi import FastAPI

app = FastAPI()


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.get("/items/{item_id}")
def read_item(item_id: int, q: str | None = None):
    return {"item_id": item_id, "q": q}
```

### Dockerfile { #dockerfile }

Åimdi aynÄ± proje dizininde `Dockerfile` adlÄ± bir dosya oluÅŸturun ve iÃ§ine ÅŸunlarÄ± yazÄ±n:

```{ .dockerfile .annotate }
# (1)!
FROM python:3.14

# (2)!
WORKDIR /code

# (3)!
COPY ./requirements.txt /code/requirements.txt

# (4)!
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (5)!
COPY ./app /code/app

# (6)!
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

1. Resmi Python base image'Ä±ndan baÅŸlayÄ±n.

2. GeÃ§erli Ã§alÄ±ÅŸma dizinini `/code` olarak ayarlayÄ±n.

    `requirements.txt` dosyasÄ±nÄ± ve `app` dizinini buraya koyacaÄŸÄ±z.

3. Gereksinimleri iÃ§eren dosyayÄ± `/code` dizinine kopyalayÄ±n.

    Ã–nce kodun tamamÄ±nÄ± deÄŸil, **sadece** gereksinim dosyasÄ±nÄ± kopyalayÄ±n.

    Bu dosya **Ã§ok sÄ±k deÄŸiÅŸmediÄŸi** iÃ§in Docker bunu tespit eder ve bu adÄ±mda **cache** kullanÄ±r; bÃ¶ylece bir sonraki adÄ±m iÃ§in de cache devreye girer.

4. Gereksinim dosyasÄ±ndaki paket baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼kleyin.

    `--no-cache-dir` seÃ§eneÄŸi, indirilen paketlerin yerel olarak kaydedilmemesini `pip`'e sÃ¶yler. Bu kayÄ±t, `pip` aynÄ± paketleri tekrar yÃ¼klemek iÃ§in yeniden Ã§alÄ±ÅŸtÄ±rÄ±lacaksa iÅŸe yarar; ancak container'larla Ã§alÄ±ÅŸÄ±rken genelde bu durum geÃ§erli deÄŸildir.

    /// note | Not

    `--no-cache-dir` yalnÄ±zca `pip` ile ilgilidir; Docker veya container'larla ilgili deÄŸildir.

    ///

    `--upgrade` seÃ§eneÄŸi, paketler zaten yÃ¼klÃ¼yse `pip`'e onlarÄ± yÃ¼kseltmesini sÃ¶yler.

    Bir Ã¶nceki adÄ±m (dosyayÄ± kopyalama) **Docker cache** tarafÄ±ndan tespit edilebildiÄŸi iÃ§in, bu adÄ±m da uygun olduÄŸunda **Docker cache'i kullanÄ±r**.

    Bu adÄ±mda cache kullanmak, geliÅŸtirme sÄ±rasÄ±nda image'Ä± tekrar tekrar build ederken size Ã§ok **zaman** kazandÄ±rÄ±r; her seferinde baÄŸÄ±mlÄ±lÄ±klarÄ± **indirip yÃ¼klemek** zorunda kalmazsÄ±nÄ±z.

5. `./app` dizinini `/code` dizininin iÃ§ine kopyalayÄ±n.

    Burada en sÄ±k deÄŸiÅŸen ÅŸey olan kodun tamamÄ± bulunduÄŸundan, bu adÄ±m (ve genelde bundan sonraki adÄ±mlar) iÃ§in Docker **cache**'i kolay kolay kullanÄ±lamaz.

    Bu yÃ¼zden, container image build sÃ¼relerini optimize etmek iÃ§in bunu `Dockerfile`'Ä±n **sonlarÄ±na yakÄ±n** koymak Ã¶nemlidir.

6. Altta Uvicorn kullanan `fastapi run` komutunu **command** olarak ayarlayÄ±n.

    `CMD` bir string listesi alÄ±r; bu string'lerin her biri komut satÄ±rÄ±nda boÅŸlukla ayrÄ±lmÄ±ÅŸ ÅŸekilde yazacaÄŸÄ±nÄ±z parÃ§alarÄ± temsil eder.

    Bu komut, yukarÄ±da `WORKDIR /code` ile ayarladÄ±ÄŸÄ±nÄ±z `/code` dizininden Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.

/// tip | Ä°pucu

Kod iÃ§indeki her numara balonuna tÄ±klayarak her satÄ±rÄ±n ne yaptÄ±ÄŸÄ±nÄ± gÃ¶zden geÃ§irin. ğŸ‘†

///

/// warning | UyarÄ±

AÅŸaÄŸÄ±da aÃ§Ä±klandÄ±ÄŸÄ± gibi `CMD` talimatÄ±nÄ±n **her zaman** **exec form**'unu kullandÄ±ÄŸÄ±nÄ±zdan emin olun.

///

#### `CMD` KullanÄ±mÄ± - Exec Form { #use-cmd-exec-form }

<a href="https://docs.docker.com/reference/dockerfile/#cmd" class="external-link" target="_blank">`CMD`</a> Docker talimatÄ± iki formda yazÄ±labilir:

âœ… **Exec** form:

```Dockerfile
# âœ… Do this
CMD ["fastapi", "run", "app/main.py", "--port", "80"]
```

â›”ï¸ **Shell** form:

```Dockerfile
# â›”ï¸ Don't do this
CMD fastapi run app/main.py --port 80
```

FastAPI'nin dÃ¼zgÃ¼n ÅŸekilde kapanabilmesi ve [lifespan event](../advanced/events.md){.internal-link target=_blank}'lerinin tetiklenmesi iÃ§in her zaman **exec** formunu kullanÄ±n.

Detaylar iÃ§in <a href="https://docs.docker.com/reference/dockerfile/#shell-and-exec-form" class="external-link" target="_blank">shell ve exec form iÃ§in Docker dokÃ¼manlarÄ±na</a> bakabilirsiniz.

Bu durum `docker compose` kullanÄ±rken oldukÃ§a belirgin olabilir. Daha teknik detaylar iÃ§in ÅŸu Docker Compose FAQ bÃ¶lÃ¼mÃ¼ne bakÄ±n: <a href="https://docs.docker.com/compose/faq/#why-do-my-services-take-10-seconds-to-recreate-or-stop" class="external-link" target="_blank">Hizmetlerimin yeniden oluÅŸturulmasÄ± veya durmasÄ± neden 10 saniye sÃ¼rÃ¼yor?</a>.

#### Dizin YapÄ±sÄ± { #directory-structure }

ArtÄ±k dizin yapÄ±nÄ±z ÅŸÃ¶yle olmalÄ±:

```
.
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

#### TLS Termination Proxy ArkasÄ±nda { #behind-a-tls-termination-proxy }

Container'Ä±nÄ±zÄ± Nginx veya Traefik gibi bir TLS Termination Proxy (load balancer) arkasÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z `--proxy-headers` seÃ§eneÄŸini ekleyin. Bu, Uvicorn'a (FastAPI CLI Ã¼zerinden) uygulamanÄ±n HTTPS arkasÄ±nda Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± sÃ¶yleyen proxy header'larÄ±na gÃ¼venmesini sÃ¶yler.

```Dockerfile
CMD ["fastapi", "run", "app/main.py", "--proxy-headers", "--port", "80"]
```

#### Docker Cache { #docker-cache }

Bu `Dockerfile` iÃ§inde Ã¶nemli bir numara var: Ã¶nce kodun geri kalanÄ±nÄ± deÄŸil, **sadece baÄŸÄ±mlÄ±lÄ±k dosyasÄ±nÄ±** kopyalÄ±yoruz. Nedenini anlatayÄ±m.

```Dockerfile
COPY ./requirements.txt /code/requirements.txt
```

Docker ve benzeri araÃ§lar bu container image'larÄ±nÄ± **artÄ±mlÄ± (incremental)** olarak **build** eder; `Dockerfile`'Ä±n en Ã¼stÃ¼nden baÅŸlayÄ±p her talimatÄ±n oluÅŸturduÄŸu dosyalarÄ± ekleyerek **katman katman (layer)** ilerler.

Docker ve benzeri araÃ§lar image build ederken ayrÄ±ca bir **internal cache** kullanÄ±r. Son build'den beri bir dosya deÄŸiÅŸmediyse, dosyayÄ± tekrar kopyalayÄ±p sÄ±fÄ±rdan yeni bir layer oluÅŸturmak yerine, daha Ã¶nce oluÅŸturulan **aynÄ± layer**'Ä± yeniden kullanÄ±r.

Sadece dosya kopyalamayÄ± azaltmak her zaman bÃ¼yÃ¼k fark yaratmaz. Ancak o adÄ±mda cache kullanÄ±ldÄ±ÄŸÄ± iÃ§in, **bir sonraki adÄ±mda da cache kullanÄ±labilir**. Ã–rneÄŸin baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyen ÅŸu talimat iÃ§in:

```Dockerfile
RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt
```

Paket gereksinimleri dosyasÄ± **sÄ±k sÄ±k deÄŸiÅŸmez**. Bu yÃ¼zden sadece bu dosyayÄ± kopyalayÄ±nca, Docker bu adÄ±mda **cache** kullanabilir.

Sonra Docker, baÄŸÄ±mlÄ±lÄ±klarÄ± indirip yÃ¼kleyen **bir sonraki adÄ±mda** da cache kullanabilir. AsÄ±l **Ã§ok zaman kazandÄ±ÄŸÄ±mÄ±z** yer de burasÄ±dÄ±r. âœ¨ ...ve beklerken sÄ±kÄ±lmayÄ± engeller. ğŸ˜ªğŸ˜†

BaÄŸÄ±mlÄ±lÄ±klarÄ± indirip yÃ¼klemek **dakikalar sÃ¼rebilir**, fakat **cache** kullanmak en fazla **saniyeler** alÄ±r.

GeliÅŸtirme sÄ±rasÄ±nda kod deÄŸiÅŸikliklerinizin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in container image'Ä± tekrar tekrar build edeceÄŸinizden, bu ciddi birikimli zaman kazancÄ± saÄŸlar.

Sonra `Dockerfile`'Ä±n sonlarÄ±na doÄŸru tÃ¼m kodu kopyalarÄ±z. En sÄ±k deÄŸiÅŸen kÄ±sÄ±m bu olduÄŸu iÃ§in sona koyarÄ±z; Ã§Ã¼nkÃ¼ neredeyse her zaman bu adÄ±mdan sonra gelen adÄ±mlar cache kullanamaz.

```Dockerfile
COPY ./app /code/app
```

### Docker Image'Ä±nÄ± Build Edin { #build-the-docker-image }

TÃ¼m dosyalar hazÄ±r olduÄŸuna gÃ¶re container image'Ä± build edelim.

* Proje dizinine gidin (`Dockerfile`'Ä±nÄ±zÄ±n olduÄŸu ve `app` dizininizi iÃ§eren dizin).
* FastAPI image'Ä±nÄ±zÄ± build edin:

<div class="termy">

```console
$ docker build -t myimage .

---> 100%
```

</div>

/// tip | Ä°pucu

Sondaki `.` ifadesine dikkat edin; `./` ile aynÄ± anlama gelir ve Docker'a container image build etmek iÃ§in hangi dizini kullanacaÄŸÄ±nÄ± sÃ¶yler.

Bu Ã¶rnekte, mevcut dizindir (`.`).

///

### Docker Container'Ä±nÄ± BaÅŸlatÄ±n { #start-the-docker-container }

* Image'Ä±nÄ±zdan bir container Ã§alÄ±ÅŸtÄ±rÄ±n:

<div class="termy">

```console
$ docker run -d --name mycontainer -p 80:80 myimage
```

</div>

## Kontrol Edin { #check-it }

Docker container'Ä±nÄ±zÄ±n URL'inden kontrol edebilmelisiniz. Ã–rneÄŸin: <a href="http://192.168.99.100/items/5?q=somequery" class="external-link" target="_blank">http://192.168.99.100/items/5?q=somequery</a> veya <a href="http://127.0.0.1/items/5?q=somequery" class="external-link" target="_blank">http://127.0.0.1/items/5?q=somequery</a> (ya da Docker host'unuzu kullanarak eÅŸdeÄŸeri).

Åuna benzer bir ÅŸey gÃ¶rÃ¼rsÃ¼nÃ¼z:

```JSON
{"item_id": 5, "q": "somequery"}
```

## EtkileÅŸimli API DokÃ¼manlarÄ± { #interactive-api-docs }

Åimdi <a href="http://192.168.99.100/docs" class="external-link" target="_blank">http://192.168.99.100/docs</a> veya <a href="http://127.0.0.1/docs" class="external-link" target="_blank">http://127.0.0.1/docs</a> adresine gidebilirsiniz (ya da Docker host'unuzla eÅŸdeÄŸeri).

Otomatik etkileÅŸimli API dokÃ¼mantasyonunu gÃ¶rÃ¼rsÃ¼nÃ¼z ( <a href="https://github.com/swagger-api/swagger-ui" class="external-link" target="_blank">Swagger UI</a> tarafÄ±ndan saÄŸlanÄ±r):

![Swagger UI](https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png)

## Alternatif API DokÃ¼manlarÄ± { #alternative-api-docs }

AyrÄ±ca <a href="http://192.168.99.100/redoc" class="external-link" target="_blank">http://192.168.99.100/redoc</a> veya <a href="http://127.0.0.1/redoc" class="external-link" target="_blank">http://127.0.0.1/redoc</a> adresine de gidebilirsiniz (ya da Docker host'unuzla eÅŸdeÄŸeri).

Alternatif otomatik dokÃ¼mantasyonu gÃ¶rÃ¼rsÃ¼nÃ¼z (<a href="https://github.com/Rebilly/ReDoc" class="external-link" target="_blank">ReDoc</a> tarafÄ±ndan saÄŸlanÄ±r):

![ReDoc](https://fastapi.tiangolo.com/img/index/index-02-redoc-simple.png)

## Tek DosyalÄ±k FastAPI ile Docker Image OluÅŸturma { #build-a-docker-image-with-a-single-file-fastapi }

FastAPI uygulamanÄ±z tek bir dosyaysa; Ã¶rneÄŸin `./app` dizini olmadan sadece `main.py` varsa, dosya yapÄ±nÄ±z ÅŸÃ¶yle olabilir:

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt
```

Bu durumda `Dockerfile` iÃ§inde dosyayÄ± kopyaladÄ±ÄŸÄ±nÄ±z path'leri buna gÃ¶re deÄŸiÅŸtirmeniz yeterlidir:

```{ .dockerfile .annotate hl_lines="10  13" }
FROM python:3.14

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

# (1)!
COPY ./main.py /code/

# (2)!
CMD ["fastapi", "run", "main.py", "--port", "80"]
```

1. `main.py` dosyasÄ±nÄ± doÄŸrudan `/code` dizinine kopyalayÄ±n (herhangi bir `./app` dizini olmadan).

2. Tek dosya olan `main.py` iÃ§indeki uygulamanÄ±zÄ± sunmak iÃ§in `fastapi run` kullanÄ±n.

DosyayÄ± `fastapi run`'a verdiÄŸinizde, bunun bir package'Ä±n parÃ§asÄ± deÄŸil tek bir dosya olduÄŸunu otomatik olarak algÄ±lar; nasÄ±l import edip FastAPI uygulamanÄ±zÄ± nasÄ±l serve edeceÄŸini bilir. ğŸ˜

## Deployment KavramlarÄ± { #deployment-concepts }

AynÄ± [Deployment KavramlarÄ±](concepts.md){.internal-link target=_blank}nÄ± bu kez container'lar aÃ§Ä±sÄ±ndan tekrar konuÅŸalÄ±m.

Container'lar, bir uygulamayÄ± **build etme ve deploy etme** sÃ¼recini basitleÅŸtiren bir araÃ§tÄ±r. Ancak bu **deployment kavramlarÄ±**nÄ± ele almak iÃ§in belirli bir yaklaÅŸÄ±mÄ± zorunlu kÄ±lmazlar; birkaÃ§ farklÄ± strateji mÃ¼mkÃ¼ndÃ¼r.

**Ä°yi haber** ÅŸu: Hangi stratejiyi seÃ§erseniz seÃ§in, deployment kavramlarÄ±nÄ±n tamamÄ±nÄ± kapsayacak bir yol vardÄ±r. ğŸ‰

Bu **deployment kavramlarÄ±**nÄ± container'lar aÃ§Ä±sÄ±ndan gÃ¶zden geÃ§irelim:

* HTTPS
* Startup'ta Ã§alÄ±ÅŸtÄ±rma
* Restart'lar
* Replication (Ã§alÄ±ÅŸan process sayÄ±sÄ±)
* Memory
* BaÅŸlatmadan Ã¶nceki adÄ±mlar

## HTTPS { #https }

Bir FastAPI uygulamasÄ±nÄ±n sadece **container image**'Ä±na (ve sonra Ã§alÄ±ÅŸan **container**'a) odaklanÄ±rsak, HTTPS genellikle **haricen** baÅŸka bir araÃ§la ele alÄ±nÄ±r.

Ã–rneÄŸin <a href="https://traefik.io/" class="external-link" target="_blank">Traefik</a> kullanan baÅŸka bir container olabilir; **HTTPS** ve **sertifika**larÄ±n **otomatik** alÄ±nmasÄ±nÄ± o yÃ¶netebilir.

/// tip | Ä°pucu

Traefik; Docker, Kubernetes ve diÄŸerleriyle entegre Ã§alÄ±ÅŸÄ±r. Bu sayede container'larÄ±nÄ±z iÃ§in HTTPS'i kurup yapÄ±landÄ±rmak oldukÃ§a kolaydÄ±r.

///

Alternatif olarak HTTPS, bir cloud provider'Ä±n sunduÄŸu servislerden biri tarafÄ±ndan da yÃ¶netilebilir (uygulama yine container iÃ§inde Ã§alÄ±ÅŸÄ±rken).

## Startup'ta Ã‡alÄ±ÅŸtÄ±rma ve Restart'lar { #running-on-startup-and-restarts }

Container'Ä±nÄ±zÄ± **baÅŸlatÄ±p Ã§alÄ±ÅŸtÄ±rmaktan** sorumlu genellikle baÅŸka bir araÃ§ olur.

Bu; doÄŸrudan **Docker**, **Docker Compose**, **Kubernetes**, bir **cloud service** vb. olabilir.

Ã‡oÄŸu (veya tÃ¼m) durumda, container'Ä± startup'ta Ã§alÄ±ÅŸtÄ±rmayÄ± ve hata durumlarÄ±nda restart'larÄ± etkinleÅŸtirmeyi saÄŸlayan basit bir seÃ§enek vardÄ±r. Ã–rneÄŸin Docker'da bu, `--restart` komut satÄ±rÄ± seÃ§eneÄŸidir.

Container kullanmadan, uygulamalarÄ± startup'ta Ã§alÄ±ÅŸtÄ±rmak ve restart mekanizmasÄ± eklemek zahmetli ve zor olabilir. Ancak **container'larla Ã§alÄ±ÅŸÄ±rken** Ã§oÄŸu zaman bu iÅŸlevler varsayÄ±lan olarak hazÄ±r gelir. âœ¨

## Replication - Process SayÄ±sÄ± { #replication-number-of-processes }

EÄŸer bir <dfn title="Bir ÅŸekilde birbirine baÄŸlanacak ve birlikte Ã§alÄ±ÅŸacak ÅŸekilde yapÄ±landÄ±rÄ±lmÄ±ÅŸ makineler grubu.">kÃ¼me</dfn> (cluster) olarak yapÄ±landÄ±rÄ±lmÄ±ÅŸ makineler grubunuz varsa ve bunlarÄ± **Kubernetes**, Docker Swarm Mode, Nomad veya benzeri, birden Ã§ok makinede daÄŸÄ±tÄ±k container'larÄ± yÃ¶neten karmaÅŸÄ±k bir sistemle yÃ¶netiyorsanÄ±z, replication'Ä± her container iÃ§inde bir **process manager** (Ã¶r. worker'lÄ± Uvicorn) kullanarak yÃ¶netmek yerine, muhtemelen **kÃ¼me seviyesinde (cluster level)** ele almak istersiniz.

Kubernetes gibi daÄŸÄ±tÄ±k container yÃ¶netim sistemleri, gelen request'ler iÃ§in **load balancing** desteÄŸi sunarken aynÄ± zamanda **container replication**'Ä±nÄ± yÃ¶netmek iÃ§in entegre mekanizmalara sahiptir. Hepsi **cluster seviyesinde**.

Bu tÃ¼r durumlarda, yukarÄ±da [anlatÄ±ldÄ±ÄŸÄ± gibi](#dockerfile) baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyip **sÄ±fÄ±rdan bir Docker image** build etmek ve birden fazla Uvicorn worker kullanmak yerine **tek bir Uvicorn process** Ã§alÄ±ÅŸtÄ±rmak istersiniz.

### Load Balancer { #load-balancer }

Container'lar kullanÄ±rken, genellikle ana port'ta dinleyen bir bileÅŸen olur. Bu, **HTTPS**'i ele almak iÃ§in bir **TLS Termination Proxy** olan baÅŸka bir container da olabilir ya da benzeri bir araÃ§ olabilir.

Bu bileÅŸen request'lerin **yÃ¼kÃ¼nÃ¼** alÄ±p worker'lar arasÄ±nda (umarÄ±m) **dengeli** ÅŸekilde daÄŸÄ±ttÄ±ÄŸÄ± iÃ§in yaygÄ±n olarak **Load Balancer** diye de adlandÄ±rÄ±lÄ±r.

/// tip | Ä°pucu

HTTPS iÃ§in kullanÄ±lan aynÄ± **TLS Termination Proxy** bileÅŸeni muhtemelen bir **Load Balancer** olarak da Ã§alÄ±ÅŸÄ±r.

///

Container'larla Ã§alÄ±ÅŸÄ±rken, onlarÄ± baÅŸlatÄ±p yÃ¶nettiÄŸiniz sistem; bu **load balancer**'dan (aynÄ± zamanda **TLS Termination Proxy** de olabilir) uygulamanÄ±zÄ±n bulunduÄŸu container(lar)a **network communication**'Ä± (Ã¶r. HTTP request'leri) iletmek iÃ§in zaten dahili araÃ§lar sunar.

### Tek Load Balancer - Ã‡oklu Worker Container { #one-load-balancer-multiple-worker-containers }

**Kubernetes** veya benzeri daÄŸÄ±tÄ±k container yÃ¶netim sistemleriyle Ã§alÄ±ÅŸÄ±rken, dahili aÄŸ mekanizmalarÄ± sayesinde ana **port**'u dinleyen tek bir **load balancer**, uygulamanÄ±zÄ± Ã§alÄ±ÅŸtÄ±ran muhtemelen **birden fazla container**'a request'leri iletebilir.

UygulamanÄ±zÄ± Ã§alÄ±ÅŸtÄ±ran bu container'larÄ±n her birinde normalde **tek bir process** olur (Ã¶r. FastAPI uygulamanÄ±zÄ± Ã§alÄ±ÅŸtÄ±ran bir Uvicorn process). Hepsi aynÄ± ÅŸeyi Ã§alÄ±ÅŸtÄ±ran **Ã¶zdeÅŸ container**'lardÄ±r; ancak her birinin kendi process'i, memory'si vb. vardÄ±r. BÃ¶ylece CPU'nun **farklÄ± core**'larÄ±nda, hatta **farklÄ± makinelerde** paralelleÅŸtirmeden yararlanÄ±rsÄ±nÄ±z.

Load balancer'lÄ± daÄŸÄ±tÄ±k sistem, request'leri uygulamanÄ±zÄ±n bulunduÄŸu container'larÄ±n her birine sÄ±rayla **daÄŸÄ±tÄ±r**. BÃ¶ylece her request, uygulamanÄ±zÄ±n birden fazla **replicated container**'Ä±ndan biri tarafÄ±ndan iÅŸlenebilir.

Ve bu **load balancer** normalde cluster'Ä±nÄ±zdaki *diÄŸer* uygulamalara giden request'leri de (Ã¶r. farklÄ± bir domain ya da farklÄ± bir URL path prefix altÄ±nda) yÃ¶netebilir ve iletiÅŸimi o *diÄŸer* uygulamanÄ±n doÄŸru container'larÄ±na iletir.

### Container BaÅŸÄ±na Tek Process { #one-process-per-container }

Bu senaryoda, replication'Ä± zaten cluster seviyesinde yaptÄ±ÄŸÄ±nÄ±z iÃ§in, muhtemelen **container baÅŸÄ±na tek bir (Uvicorn) process** istersiniz.

DolayÄ±sÄ±yla bu durumda container iÃ§inde `--workers` gibi bir komut satÄ±rÄ± seÃ§eneÄŸiyle Ã§oklu worker istemezsiniz. Container baÅŸÄ±na sadece **tek bir Uvicorn process** istersiniz (ama muhtemelen birden fazla container).

Container iÃ§ine ekstra bir process manager koymak (Ã§oklu worker gibi) Ã§oÄŸu zaman zaten cluster sisteminizle Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼z ÅŸeye ek **gereksiz karmaÅŸÄ±klÄ±k** katar.

### Birden Fazla Process'li Container'lar ve Ã–zel Durumlar { #containers-with-multiple-processes-and-special-cases }

Elbette bazÄ± **Ã¶zel durumlarda** bir container iÃ§inde birden fazla **Uvicorn worker process** Ã§alÄ±ÅŸtÄ±rmak isteyebilirsiniz.

Bu durumlarda Ã§alÄ±ÅŸtÄ±rmak istediÄŸiniz worker sayÄ±sÄ±nÄ± `--workers` komut satÄ±rÄ± seÃ§eneÄŸiyle ayarlayabilirsiniz:

```{ .dockerfile .annotate }
FROM python:3.14

WORKDIR /code

COPY ./requirements.txt /code/requirements.txt

RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt

COPY ./app /code/app

# (1)!
CMD ["fastapi", "run", "app/main.py", "--port", "80", "--workers", "4"]
```

1. Burada worker sayÄ±sÄ±nÄ± 4 yapmak iÃ§in `--workers` komut satÄ±rÄ± seÃ§eneÄŸini kullanÄ±yoruz.

Bunun mantÄ±klÄ± olabileceÄŸi birkaÃ§ Ã¶rnek:

#### Basit Bir Uygulama { #a-simple-app }

UygulamanÄ±z tek bir server Ã¼zerinde (cluster deÄŸil) Ã§alÄ±ÅŸacak kadar **basitse**, container iÃ§inde bir process manager isteyebilirsiniz.

#### Docker Compose { #docker-compose }

**Docker Compose** ile **tek bir server**'a (cluster deÄŸil) deploy ediyor olabilirsiniz. Bu durumda, paylaÅŸÄ±lan aÄŸÄ± ve **load balancing**'i koruyarak container replication'Ä±nÄ± (Docker Compose ile) yÃ¶netmenin kolay bir yolu olmayabilir.

Bu durumda, tek bir container iÃ§inde **bir process manager** ile **birden fazla worker process** baÅŸlatmak isteyebilirsiniz.

---

Ana fikir ÅŸu: BunlarÄ±n **hiÃ§biri** kÃ¶rÃ¼ kÃ¶rÃ¼ne uymanÄ±z gereken **deÄŸiÅŸmez kurallar** deÄŸildir. Bu fikirleri, kendi kullanÄ±m senaryonuzu **deÄŸerlendirmek** ve sisteminiz iÃ§in en iyi yaklaÅŸÄ±mÄ± seÃ§mek iÃ§in kullanabilirsiniz. Åu kavramlarÄ± nasÄ±l yÃ¶neteceÄŸinize bakarak karar verin:

* GÃ¼venlik - HTTPS
* Startup'ta Ã§alÄ±ÅŸtÄ±rma
* Restart'lar
* Replication (Ã§alÄ±ÅŸan process sayÄ±sÄ±)
* Memory
* BaÅŸlatmadan Ã¶nceki adÄ±mlar

## Memory { #memory }

**Container baÅŸÄ±na tek process** Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z, her container'Ä±n tÃ¼keteceÄŸi memory miktarÄ± aÅŸaÄŸÄ± yukarÄ± tanÄ±mlÄ±, stabil ve sÄ±nÄ±rlÄ± olur (replication varsa birden fazla container iÃ§in).

Sonra aynÄ± memory limit ve gereksinimlerini container yÃ¶netim sisteminizin (Ã¶r. **Kubernetes**) konfigÃ¼rasyonlarÄ±nda belirleyebilirsiniz. BÃ¶ylece sistem; ihtiyaÃ§ duyulan memory miktarÄ±nÄ± ve cluster'daki makinelerde mevcut memory'yi dikkate alarak **uygun makinelerde container'larÄ± replicate edebilir**.

UygulamanÄ±z **basitse**, muhtemelen bu **bir sorun olmaz** ve katÄ± memory limitleri belirlemeniz gerekmeyebilir. Ancak **Ã§ok memory kullanÄ±yorsanÄ±z** (Ã¶r. **machine learning** modelleriyle), ne kadar memory tÃ¼kettiÄŸinizi kontrol edip **her makinede** Ã§alÄ±ÅŸacak **container sayÄ±sÄ±nÄ±** ayarlamalÄ±sÄ±nÄ±z (ve gerekirse cluster'a daha fazla makine eklemelisiniz).

**Container baÅŸÄ±na birden fazla process** Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z, baÅŸlatÄ±lan process sayÄ±sÄ±nÄ±n mevcut olandan **fazla memory tÃ¼ketmediÄŸinden** emin olmanÄ±z gerekir.

## BaÅŸlatmadan Ã–nceki AdÄ±mlar ve Container'lar { #previous-steps-before-starting-and-containers }

Container kullanÄ±yorsanÄ±z (Ã¶rn. Docker, Kubernetes), temelde iki yaklaÅŸÄ±m vardÄ±r.

### Birden Fazla Container { #multiple-containers }

**Birden fazla container**'Ä±nÄ±z varsa ve muhtemelen her biri **tek process** Ã§alÄ±ÅŸtÄ±rÄ±yorsa (Ã¶r. bir **Kubernetes** cluster'Ä±nda), replication yapÄ±lan worker container'lar Ã§alÄ±ÅŸmadan **Ã¶nce**, **baÅŸlatmadan Ã¶nceki adÄ±mlar**Ä±n iÅŸini yapan **ayrÄ± bir container** kullanmak isteyebilirsiniz (tek container, tek process).

/// info | Bilgi

Kubernetes kullanÄ±yorsanÄ±z, bu muhtemelen bir <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" class="external-link" target="_blank">Init Container</a> olur.

///

KullanÄ±m senaryonuzda bu adÄ±mlarÄ± **paralel olarak birden fazla kez** Ã§alÄ±ÅŸtÄ±rmak sorun deÄŸilse (Ã¶rneÄŸin veritabanÄ± migration Ã§alÄ±ÅŸtÄ±rmÄ±yor, sadece veritabanÄ± hazÄ±r mÄ± diye kontrol ediyorsanÄ±z), o zaman her container'da ana process baÅŸlamadan hemen Ã¶nce de Ã§alÄ±ÅŸtÄ±rabilirsiniz.

### Tek Container { #single-container }

Basit bir kurulumda; **tek bir container** olup onun iÃ§inde birden fazla **worker process** (ya da sadece bir process) baÅŸlatÄ±yorsanÄ±z, bu adÄ±mlarÄ± aynÄ± container iÃ§inde, uygulama process'ini baÅŸlatmadan hemen Ã¶nce Ã§alÄ±ÅŸtÄ±rabilirsiniz.

### Base Docker Image { #base-docker-image }

Eskiden resmi bir FastAPI Docker image'Ä± vardÄ±: <a href="https://github.com/tiangolo/uvicorn-gunicorn-fastapi-docker" class="external-link" target="_blank">tiangolo/uvicorn-gunicorn-fastapi</a>. Ancak artÄ±k kullanÄ±mdan kaldÄ±rÄ±ldÄ± (deprecated). â›”ï¸

Muhtemelen bu base Docker image'Ä±nÄ± (veya benzeri baÅŸka bir image'Ä±) kullanmamalÄ±sÄ±nÄ±z.

**Kubernetes** (veya diÄŸerleri) kullanÄ±yor ve cluster seviyesinde birden fazla **container** ile **replication** ayarlÄ±yorsanÄ±z, bu durumda yukarÄ±da anlatÄ±ldÄ±ÄŸÄ± gibi **sÄ±fÄ±rdan bir image build etmek** daha iyi olur: [FastAPI iÃ§in Docker Image OluÅŸturalÄ±m](#build-a-docker-image-for-fastapi).

Ve birden fazla worker gerekiyorsa, sadece `--workers` komut satÄ±rÄ± seÃ§eneÄŸini kullanabilirsiniz.

/// note | Teknik Detaylar

Bu Docker image, Uvicorn dead worker'larÄ± yÃ¶netmeyi ve yeniden baÅŸlatmayÄ± desteklemediÄŸi dÃ¶nemde oluÅŸturulmuÅŸtu. Bu yÃ¼zden Uvicorn ile birlikte Gunicorn kullanmak gerekiyordu; sÄ±rf Gunicorn, Uvicorn worker process'lerini yÃ¶netip yeniden baÅŸlatsÄ±n diye oldukÃ§a fazla karmaÅŸÄ±klÄ±k ekleniyordu.

Ancak artÄ±k Uvicorn (ve `fastapi` komutu) `--workers` kullanÄ±mÄ±nÄ± desteklediÄŸine gÃ¶re, kendi image'Ä±nÄ±zÄ± build etmek yerine bir base Docker image kullanmanÄ±n bir nedeni kalmadÄ± (kod miktarÄ± da hemen hemen aynÄ± ğŸ˜…).

///

## Container Image'Ä± Deploy Etme { #deploy-the-container-image }

Bir Container (Docker) Image'Ä±nÄ±z olduktan sonra bunu deploy etmenin birkaÃ§ yolu vardÄ±r.

Ã–rneÄŸin:

* Tek bir server'da **Docker Compose** ile
* Bir **Kubernetes** cluster'Ä± ile
* Docker Swarm Mode cluster'Ä± ile
* Nomad gibi baÅŸka bir araÃ§la
* Container image'Ä±nÄ±zÄ± alÄ±p deploy eden bir cloud servisiyle

## `uv` ile Docker Image { #docker-image-with-uv }

Projenizi yÃ¼klemek ve yÃ¶netmek iÃ§in <a href="https://github.com/astral-sh/uv" class="external-link" target="_blank">uv</a> kullanÄ±yorsanÄ±z, onlarÄ±n <a href="https://docs.astral.sh/uv/guides/integration/docker/" class="external-link" target="_blank">uv Docker rehberini</a> takip edebilirsiniz.

## Ã–zet { #recap }

Container sistemleri (Ã¶rn. **Docker** ve **Kubernetes** ile) kullanÄ±nca tÃ¼m **deployment kavramlarÄ±**nÄ± ele almak oldukÃ§a kolaylaÅŸÄ±r:

* HTTPS
* Startup'ta Ã§alÄ±ÅŸtÄ±rma
* Restart'lar
* Replication (Ã§alÄ±ÅŸan process sayÄ±sÄ±)
* Memory
* BaÅŸlatmadan Ã¶nceki adÄ±mlar

Ã‡oÄŸu durumda bir base image kullanmak istemezsiniz; bunun yerine resmi Python Docker image'Ä±nÄ± temel alarak **sÄ±fÄ±rdan bir container image** build edersiniz.

`Dockerfile` iÃ§indeki talimatlarÄ±n **sÄ±rasÄ±na** ve **Docker cache**'ine dikkat ederek **build sÃ¼relerini minimize edebilir**, Ã¼retkenliÄŸinizi artÄ±rabilirsiniz (ve beklerken sÄ±kÄ±lmayÄ± Ã¶nlersiniz). ğŸ˜
