# EÅŸzamanlÄ±lÄ±k ve async / await

*path operasyon fonksiyonu* iÃ§in `async def`sÃ¶zyazÄ±mÄ±,  asenkron kod, eÅŸzamanlÄ±lÄ±k ve paralellik hakkÄ±nda bazÄ± bilgiler.

## Aceleniz mi var?

<abbr title="too long; didn't read"><strong>TL;DR:</strong></abbr>

EÄŸer onlarÄ± `await` ile Ã§aÄŸÄ±rmanÄ±zÄ± sÃ¶yleyen Ã¼Ã§Ã¼ncÃ¼ taraf bir kÃ¼tÃ¼phane kullanÄ±yorsanÄ±z, Ã¶rneÄŸin:

```Python
results = await some_library()
```

O zaman *path operasyon fonksiyonunu*  `async def` ile tanÄ±mlayÄ±n:

```Python hl_lines="2"
@app.get('/')
async def read_results():
    results = await some_library()
    return results
```

!!! not
    `await` yalnÄ±zca `async def` ile tanÄ±mlanan fonksiyonlarÄ±n iÃ§inde kullanÄ±labilir.

---

EÄŸer Ã¼Ã§Ã¼ncÃ¼ parti kÃ¼tÃ¼phaneler ile beraber birÅŸeyler ile etkileÅŸimde bulunuyorsak(veri tabanÄ±,  API, dosya iÅŸlemleri, vb.) ve  `await` kulanÄ±mÄ± desteklenmiyorsa, (birÃ§ok veri tabanÄ± kÃ¼tÃ¼phanesi iÃ§in geÃ§erlidir), o zaman *path operasyon fonksiyonunu* normal bir ÅŸekilde, yalnÄ±zca `def` kullanarak da tanÄ±mlayabiliriz, Ã¶rneÄŸin:

```Python hl_lines="2"
@app.get('/')
def results():
    results = some_library()
    return results
```

---

EÄŸer uygulamanÄ±z (bir ÅŸekilde) baÅŸka bir ÅŸeyle iletiÅŸim kurmasÄ± gerekmiyor ama  yanÄ±t vermesini beklemeniz gerekiyorsa `async def` kullanabilirsiniz.

---

Sadece bilmiyorsanÄ±z, normal `def` kullanÄ±n.

---

**Not**: *path operasyon fonksiyonlarÄ±nda* istediÄŸiniz ÅŸekilde `def` yada `async def` kullanabilirsiniz. Sizin iÃ§in en iyi olan seÃ§eneÄŸi kullanabilirsiniz. FastAPI onlarla doÄŸru olanÄ± yapacaktÄ±r.

YukarÄ±daki durumlardan herhangi birinde FastAPI yine de asenkron olarak Ã§alÄ±ÅŸacak ve son derece hÄ±zlÄ± olacaktÄ±r.

Ancak yukarÄ±daki adÄ±mlarÄ± takip ederek bazÄ± performans optimizasyonlarÄ± yapabiliriz

## Teknik Detaylar

Python modern versiyonlarÄ±nda **`async` ve `await`** sÃ¶zdizimi ile **"coroutines"**  kullanan **"asenkron kod"** desteÄŸine sahiptir.

Bu ifadeyi aÅŸaÄŸÄ±daki bÃ¶lÃ¼mlerde daha da ayrÄ±ntÄ±lÄ± aÃ§Ä±klayalÄ±m:

* **Asenkron kod**
* **`async` ve `await`**
* **Coroutines**

## Asenkron kod

Asenkron kod programlama dilinin ğŸ’¬ bilgisayara / programa ğŸ¤– kodun bir noktasÄ±nda, *baÅŸka bir kodun* bir yerde bitmesini ğŸ¤– beklemesi gerektiÄŸini sÃ¶ylemenin bir yoludur. Bu *baÅŸka koda* "slow-file" denir ğŸ“.

BÃ¶ylece, bu sÃ¼reÃ§te bilgisayar "slow-file" ğŸ“ tamamlanÄ±rken gidip baÅŸka iÅŸler yapabilir.

Sonra bilgisayar / program ğŸ¤– her fÄ±rsatÄ± olduÄŸunda o noktada yaptÄ±ÄŸÄ± tÃ¼m iÅŸleri ğŸ¤– bitirene kadar geri dÃ¶nÃ¼cek. Ve ğŸ¤– yapmasÄ± gerekeni yaparak, beklediÄŸi gÃ¶revlerden herhangi birinin bitip bitmediÄŸini gÃ¶recek.

ArdÄ±ndan, ğŸ¤– bitirmek iÃ§in ilk gÃ¶revi alÄ±r ("slow-file" ğŸ“) ve onunla ne yapmasÄ± gerekiyorsa onu devam ettirir.

Bu "baÅŸka bir ÅŸey iÃ§in bekle" normalde, aÅŸaÄŸÄ±dakileri beklemek gibi (iÅŸlemcinin ve RAM belleÄŸinin hÄ±zÄ±na kÄ±yasla) nispeten "yavaÅŸ" olan <abbr title="Input ve Output (GiriÅŸ ve Ã‡Ä±kÄ±ÅŸ)">I/O</abbr> iÅŸlemlerine atÄ±fta bulunur:  

* istemci tarafÄ±ndan aÄŸ Ã¼zerinden veri gÃ¶ndermek
* aÄŸ Ã¼zerinden istemciye gÃ¶nderilen veriler
* sistem tarafÄ±ndan okunacak ve programÄ±nÄ±za verilecek bir dosya iÃ§eriÄŸi
* programÄ±nÄ±zÄ±n diske yazÄ±lmak Ã¼zere sisteme verdiÄŸi dosya iÃ§erikleri
* uzak bir API iÅŸlemi
* bir veritabanÄ± bitirme iÅŸlemi
* sonuÃ§larÄ± dÃ¶ndÃ¼rmek iÃ§in bir veritabanÄ± sorgusu
* vb.

YÃ¼rÃ¼tme sÃ¼resi Ã§oÄŸunlukla  <abbr title="Input ve Output (GiriÅŸ ve Ã‡Ä±kÄ±ÅŸ)">I/O</abbr> iÅŸlemleri beklenerek tÃ¼ketildiÄŸinden bunlara "I/O baÄŸlantÄ±lÄ±" iÅŸlemler denir.

Buna "asenkron" denir, Ã§Ã¼nkÃ¼ bilgisayar/program yavaÅŸ gÃ¶revle "senkronize" olmak zorunda deÄŸildir, gÃ¶revin tam olarak biteceÄŸi anÄ± bekler, hiÃ§bir ÅŸey yapmadan, gÃ¶rev sonucunu alabilmek ve Ã§alÄ±ÅŸmaya devam edebilmek iÃ§in .

Bunun yerine, "asenkron" bir sistem olarak, bir kez bittiÄŸinde,  bilgisayarÄ±n / programÄ±n yapmasÄ± gerekeni bitirmesi iÃ§in biraz (birkaÃ§ mikrosaniye) sÄ±rada bekleyebilir ve ardÄ±ndan sonuÃ§larÄ± almak iÃ§in geri gelebilir ve onlarla Ã§alÄ±ÅŸmaya devam edebilir.

"Senkron" ("asenkron"un aksine) iÃ§in genellikle "sÄ±ralÄ±" terimini de kullanÄ±rlar, Ã§Ã¼nkÃ¼ bilgisayar/program, bu adÄ±mlar beklemeyi iÃ§erse bile, farklÄ± bir gÃ¶reve geÃ§meden Ã¶nce tÃ¼m adÄ±mlarÄ± sÄ±rayla izler.


### EÅŸzamanlÄ±lÄ±k (Concurrency) ve Burgerler


YukarÄ±da aÃ§Ä±klanan bu **asenkron** kod fikrine bazen **"eÅŸzamanlÄ±lÄ±k"** da denir. **"Paralellikten"** farklÄ±dÄ±r.

**EÅŸzamanlÄ±lÄ±k** ve **paralellik**, "aynÄ± anda az ya da Ã§ok olan farklÄ± iÅŸler" ile ilgilidir.

Ancak *eÅŸzamanlÄ±lÄ±k* ve *paralellik* arasÄ±ndaki ayrÄ±ntÄ±lar oldukÃ§a farklÄ±dÄ±r.


FarkÄ± gÃ¶rmek iÃ§in burgerlerle ilgili aÅŸaÄŸÄ±daki hikayeyi hayal edin:

### EÅŸzamanlÄ± Burgerler

<!-- Cinsiyetten baÄŸÄ±msÄ±z olan aÅŸÃ§Ä± emojisi "ğŸ§‘â€ğŸ³" tarayÄ±cÄ±larda yeterince iyi gÃ¶rÃ¼ntÃ¼lenmiyor. Bu yÃ¼zden erken "ğŸ‘¨â€ğŸ³" ve kadÄ±n "ğŸ‘©â€ğŸ³" aÅŸÃ§Ä±larÄ± karÄ±ÅŸÄ±k bir ÅŸekilde kullanÄ±caÄŸÄ±m. -->

AÅŸkÄ±nla beraber ğŸ˜ dÄ±ÅŸarÄ± hamburger yemeye Ã§Ä±ktÄ±nÄ±z ğŸ”, kasiyer ğŸ’ Ã¶ndeki insanlardan sipariÅŸ alÄ±rken siz sÄ±raya girdiniz.

SÄ±ra sizde ve sen aÅŸkÄ±n ğŸ˜ ve kendin iÃ§in 2 Ã§Ä±lgÄ±n hamburger ğŸ” sÃ¶ylÃ¼yorsun.

Ã–demeyi yaptÄ±n ğŸ’¸.

Kasiyer ğŸ’ mutfakdaki aÅŸÃ§Ä±ya ğŸ‘¨â€ğŸ³ hamburgerleri ğŸ” hazÄ±rlamasÄ± gerektiÄŸini sÃ¶yler ve aÅŸÃ§Ä± bunu bilir (o an Ã¶nceki mÃ¼ÅŸterilerin sipariÅŸlerini hazÄ±rlÄ±yor olsa bile).

Kasiyer ğŸ’ size bir sÄ±ra numarasÄ± verir.

Beklerken askÄ±nla ğŸ˜ bir masaya oturur ve uzun bir sÃ¼re konuÅŸursunuz(Burgerleriniz Ã§ok Ã§Ä±lgÄ±n olduÄŸundan ve hazÄ±rlanmasÄ± biraz zaman alÄ±yor âœ¨ğŸ”âœ¨).

Hamburgeri beklerkenki zamanÄ± ğŸ”, aÅŸkÄ±nÄ±n ne kadar zeki ve tatlÄ± olduÄŸuna hayran kalarak harcayabilirsin âœ¨ğŸ˜âœ¨.

AÅŸkÄ±nla ğŸ˜ konuÅŸurken arada sÄ±ranÄ±n size gelip gelmediÄŸini kontrol ediyorsun.

Nihayet sÄ±ra size geldi. Tezgaha gidip hamburgerleri ğŸ”kapÄ±p masaya geri dÃ¶nÃ¼yorsun.

AÅŸkÄ±nla hamburgerlerinizi yiyor ğŸ” ve iyi vakit geÃ§iriyorsunuz âœ¨.

---

Bu hikayedeki bilgisayar / program ğŸ¤– olduÄŸunuzu hayal edin.

SÄ±rada beklerken boÅŸtasÄ±n ğŸ˜´, sÄ±ranÄ± beklerken herhangi bir "Ã¼retim" yapmÄ±yorsun. Ama bu sÄ±ra hÄ±zlÄ± Ã§Ã¼nkÃ¼ kasiyer sadece sipariÅŸleri alÄ±yor (onlarÄ± hazÄ±rlamÄ±yor), burada bir sÄ±knÄ±tÄ± yok.

Sonra sÄ±ra size geldiÄŸinde gerÃ§ekten "Ã¼retken" iÅŸler yapabilirsiniz ğŸ¤“, menÃ¼yÃ¼ oku, ne istediÄŸine larar ver, aÅŸkÄ±nÄ±n seÃ§imini al ğŸ˜, Ã¶de ğŸ’¸, doÄŸru kartÄ± Ã§Ä±kart, Ã¶demeyi kontrol et, faturayÄ± kontrol et, sipariÅŸin doÄŸru olup olmadÄ±ÄŸÄ±nÄ± kontrol et, vb.

Ama hamburgerler ğŸ” hazÄ±r olmamasÄ±na raÄŸmen Kasiyer ğŸ’ ile iÅŸiniz "duraklÄ±yor" â¸, Ã§Ã¼nkÃ¼ hamburgerlerin hazÄ±r olmasÄ±nÄ± bekliyoruz ğŸ•™.

Ama tezgahtan uzaklaÅŸÄ±p sÄ±ranÄ±z gelene kadarmasanÄ±za dÃ¶nebilir ğŸ”€ ve dikkatinizi aÅŸkÄ±nÄ±za ğŸ˜ verebilirsiniz vr bunun Ã¼zerine "Ã§alÄ±ÅŸabilirsiniz" â¯ ğŸ¤“. ArtÄ±k "Ã¼retken" birÅŸey yapÄ±yorsunuz ğŸ¤“, sevgilinle ğŸ˜ flÃ¶rt eder gibi.

Kasiyer ğŸ’  "Hamburgerler hazÄ±r !" ğŸ” dediÄŸinde ve gÃ¶rÃ¼ntÃ¼lenen numara sizin numaranÄ±z olduÄŸunda hemen koÅŸup hamburgerlerinizi almaya Ã§alÄ±ÅŸmÄ±yorsunuz. Biliyorsunuzki kimse sizin hamburgerlerinizi ğŸ” Ã§almayacak Ã§Ã¼nkÃ¼ sÄ±ra sizin.

Yani AÅŸkÄ±nÄ±zÄ±nğŸ˜ hikayeyi bitirmesini bekliyorsunuz (Ã§alÄ±ÅŸmayÄ± bitir â¯ / gÃ¶rev iÅŸleniyor.. ğŸ¤“), nazikÃ§e gÃ¼lÃ¼mseyin ve hamburger yemeye gittiÄŸinizi sÃ¶yleyin â¸.

ArdÄ±ndan tezgaha ğŸ”€, ÅŸimdi biten ilk gÃ¶reve â¯ gidin, Hamburgerleri ğŸ” alÄ±n, teÅŸekkÃ¼r edin ve masaya gÃ¶tÃ¼rÃ¼n. sayacÄ±n bu adÄ±mÄ± tamamlanÄ±r â¹. Bu da yeni bir gÃ¶rev olan  "hamburgerleri ye" ğŸ”€ â¯ gÃ¶revini baÅŸlatÄ±rken "hamburgerleri al" â¹ gÃ¶revini bitirir.

### Parallel Hamburgerler

Åimdi bunlarÄ±n "EÅŸzamanlÄ± Hamburger" deÄŸil, "Paralel Hamburger" olduÄŸunu dÃ¼ÅŸÃ¼nelim.

Hamburger ğŸ” almak iÃ§in ğŸ˜ aÅŸkÄ±nla Paralel fast food'a gidiyorsun.

You stand in line while several (let's say 8) cashiers that at the same time are cooks ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ take the orders from the people in front of you.

Everyone before you is waiting ğŸ•™ for their burgers ğŸ” to be ready before leaving the counter because each of the 8 cashiers goes and prepares the burger right away before getting the next order.

Then it's finally your turn, you place your order of 2 very fancy burgers ğŸ” for your crush ğŸ˜ and you.

You pay ğŸ’¸.

The cashier goes to the kitchen ğŸ‘¨â€ğŸ³.

You wait, standing in front of the counter ğŸ•™, so that no one else takes your burgers ğŸ” before you do, as there are no numbers for turns.

As you and your crush ğŸ˜ are busy not letting anyone get in front of you and take your burgers whenever they arrive ğŸ•™, you cannot pay attention to your crush ğŸ˜.

This is "synchronous" work, you are "synchronized" with the cashier/cook ğŸ‘¨â€ğŸ³. You have to wait ğŸ•™ and be there at the exact moment that the cashier/cook ğŸ‘¨â€ğŸ³ finishes the burgers ğŸ” and gives them to you, or otherwise, someone else might take them.

Then your cashier/cook ğŸ‘¨â€ğŸ³ finally comes back with your burgers ğŸ”, after a long time waiting ğŸ•™ there in front of the counter.

You take your burgers ğŸ” and go to the table with your crush ğŸ˜.

You just eat them, and you are done ğŸ” â¹.

There was not much talk or flirting as most of the time was spent waiting ğŸ•™ in front of the counter ğŸ˜.

---

In this scenario of the parallel burgers, you are a computer / program ğŸ¤– with two processors (you and your crush ğŸ˜), both waiting ğŸ•™ and dedicating their attention â¯ to be "waiting on the counter" ğŸ•™ for a long time.

The fast food store has 8 processors (cashiers/cooks) ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³. While the concurrent burgers store might have had only 2 (one cashier and one cook) ğŸ’ ğŸ‘¨â€ğŸ³.

But still, the final experience is not the best ğŸ˜.

---

This would be the parallel equivalent story for burgers ğŸ”.

For a more "real life" example of this, imagine a bank.

Up to recently, most of the banks had multiple cashiers ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ and a big line ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™.

All of the cashiers doing all the work with one client after the other ğŸ‘¨â€ğŸ’¼â¯.

And you have to wait ğŸ•™ in the line for a long time or you lose your turn.

You probably wouldn't want to take your crush ğŸ˜ with you to do errands at the bank ğŸ¦.

### Burger Conclusion

In this scenario of "fast food burgers with your crush", as there is a lot of waiting ğŸ•™, it makes a lot more sense to have a concurrent system â¸ğŸ”€â¯.

This is the case for most of the web applications.

Many, many users, but your server is waiting ğŸ•™ for their not-so-good connection to send their requests.

And then waiting ğŸ•™ again for the responses to come back.

This "waiting" ğŸ•™ is measured in microseconds, but still, summing it all, it's a lot of waiting in the end.

That's why it makes a lot of sense to use asynchronous â¸ğŸ”€â¯ code for web APIs.

Most of the existing popular Python frameworks (including Flask and Django) were created before the new asynchronous features in Python existed. So, the ways they can be deployed support parallel execution and an older form of asynchronous execution that is not as powerful as the new capabilities.

Even though the main specification for asynchronous web Python (ASGI) was developed at Django, to add support for WebSockets.

That kind of asynchronicity is what made NodeJS popular (even though NodeJS is not parallel) and that's the strength of Go as a programming language.

And that's the same level of performance you get with **FastAPI**.

And as you can have parallelism and asynchronicity at the same time, you get higher performance than most of the tested NodeJS frameworks and on par with Go, which is a compiled language closer to C <a href="https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query&l=zijmkf-1" class="external-link" target="_blank">(all thanks to Starlette)</a>.

### Is concurrency better than parallelism?

Nope! That's not the moral of the story.

Concurrency is different than parallelism. And it is better on **specific** scenarios that involve a lot of waiting. Because of that, it generally is a lot better than parallelism for web application development. But not for everything.

So, to balance that out, imagine the following short story:

> You have to clean a big, dirty house.

*Yep, that's the whole story*.

---

There's no waiting ğŸ•™ anywhere, just a lot of work to be done, on multiple places of the house.

You could have turns as in the burgers example, first the living room, then the kitchen, but as you are not waiting ğŸ•™ for anything, just cleaning and cleaning, the turns wouldn't affect anything.

It would take the same amount of time to finish with or without turns (concurrency) and you would have done the same amount of work.

But in this case, if you could bring the 8 ex-cashier/cooks/now-cleaners ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ³, and each one of them (plus you) could take a zone of the house to clean it, you could do all the work in **parallel**, with the extra help, and finish much sooner.

In this scenario, each one of the cleaners (including you) would be a processor, doing their part of the job.

And as most of the execution time is taken by actual work (instead of waiting), and the work in a computer is done by a <abbr title="Central Processing Unit">CPU</abbr>, they call these problems "CPU bound".

---

Common examples of CPU bound operations are things that require complex math processing.

For example:

* **Audio** or **image processing**.
* **Computer vision**: an image is composed of millions of pixels, each pixel has 3 values / colors, processing that normally requires computing something on those pixels, all at the same time.
* **Machine Learning**: it normally requires lots of "matrix" and "vector" multiplications. Think of a huge spreadsheet with numbers and multiplying all of them together at the same time.
* **Deep Learning**: this is a sub-field of Machine Learning, so, the same applies. It's just that there is not a single spreadsheet of numbers to multiply, but a huge set of them, and in many cases, you use a special processor to build and / or use those models.

### Concurrency + Parallelism: Web + Machine Learning

With **FastAPI** you can take the advantage of concurrency that is very common for web development (the same main attractive of NodeJS).

But you can also exploit the benefits of parallelism and multiprocessing (having multiple processes running in parallel) for **CPU bound** workloads like those in Machine Learning systems.

That, plus the simple fact that Python is the main language for **Data Science**, Machine Learning and especially Deep Learning, make FastAPI a very good match for Data Science / Machine Learning web APIs and applications (among many others).

To see how to achieve this parallelism in production see the section about [Deployment](deployment/index.md){.internal-link target=_blank}.

## `async` and `await`

Modern versions of Python have a very intuitive way to define asynchronous code. This makes it look just like normal "sequential" code and do the "awaiting" for you at the right moments.

When there is an operation that will require waiting before giving the results and has support for these new Python features, you can code it like:

```Python
burgers = await get_burgers(2)
```

The key here is the `await`. It tells Python that it has to wait â¸ for `get_burgers(2)` to finish doing its thing ğŸ•™ before storing the results in `burgers`. With that, Python will know that it can go and do something else ğŸ”€ â¯ in the meanwhile (like receiving another request).

For `await` to work, it has to be inside a function that supports this asynchronicity. To do that, you just declare it with `async def`:

```Python hl_lines="1"
async def get_burgers(number: int):
    # Do some asynchronous stuff to create the burgers
    return burgers
```

...instead of `def`:

```Python hl_lines="2"
# This is not asynchronous
def get_sequential_burgers(number: int):
    # Do some sequential stuff to create the burgers
    return burgers
```

With `async def`, Python knows that, inside that function, it has to be aware of `await` expressions, and that it can "pause" â¸ the execution of that function and go do something else ğŸ”€ before coming back.

When you want to call an `async def` function, you have to "await" it. So, this won't work:

```Python
# This won't work, because get_burgers was defined with: async def
burgers = get_burgers(2)
```

---

So, if you are using a library that tells you that you can call it with `await`, you need to create the *path operation functions* that uses it with `async def`, like in:

```Python hl_lines="2-3"
@app.get('/burgers')
async def read_burgers():
    burgers = await get_burgers(2)
    return burgers
```

### More technical details

You might have noticed that `await` can only be used inside of functions defined with `async def`.

But at the same time, functions defined with `async def` have to be "awaited". So, functions with `async def` can only be called inside of functions defined with `async def` too.

So, about the egg and the chicken, how do you call the first `async` function?

If you are working with **FastAPI** you don't have to worry about that, because that "first" function will be your *path operation function*, and FastAPI will know how to do the right thing.

But if you want to use `async` / `await` without FastAPI, <a href="https://docs.python.org/3/library/asyncio-task.html#coroutine" class="external-link" target="_blank">check the official Python docs</a>.

### Other forms of asynchronous code

This style of using `async` and `await` is relatively new in the language.

But it makes working with asynchronous code a lot easier.

This same syntax (or almost identical) was also included recently in modern versions of JavaScript (in Browser and NodeJS).

But before that, handling asynchronous code was quite more complex and difficult.

In previous versions of Python, you could have used threads or <a href="https://www.gevent.org/" class="external-link" target="_blank">Gevent</a>. But the code is way more complex to understand, debug, and think about.

In previous versions of NodeJS / Browser JavaScript, you would have used "callbacks". Which leads to <a href="http://callbackhell.com/" class="external-link" target="_blank">callback hell</a>.

## Coroutines

**Coroutine** is just the very fancy term for the thing returned by an `async def` function. Python knows that it is something like a function that it can start and that it will end at some point, but that it might be paused â¸ internally too, whenever there is an `await` inside of it.

But all this functionality of using asynchronous code with `async` and `await` is many times summarized as using "coroutines". It is comparable to the main key feature of Go, the "Goroutines".

## Conclusion

Let's see the same phrase from above:

> Modern versions of Python have support for **"asynchronous code"** using something called **"coroutines"**, with **`async` and `await`** syntax.

That should make more sense now. âœ¨

All that is what powers FastAPI (through Starlette) and what makes it have such an impressive performance.

## Very Technical Details

!!! warning
    You can probably skip this.

    These are very technical details of how **FastAPI** works underneath.

    If you have quite some technical knowledge (co-routines, threads, blocking, etc) and are curious about how FastAPI handles `async def` vs normal `def`, go ahead.

### Path operation functions

When you declare a *path operation function* with normal `def` instead of `async def`, it is run in an external threadpool that is then awaited, instead of being called directly (as it would block the server).

If you are coming from another async framework that does not work in the way described above and you are used to define trivial compute-only *path operation functions* with plain `def` for a tiny performance gain (about 100 nanoseconds), please note that in **FastAPI** the effect would be quite opposite. In these cases, it's better to use `async def` unless your *path operation functions* use code that performs blocking <abbr title="Input/Output: disk reading or writing, network communications.">I/O</abbr>.

Still, in both situations, chances are that **FastAPI** will [still be faster](/#performance){.internal-link target=_blank} than (or at least comparable to) your previous framework.

### Dependencies

The same applies for dependencies. If a dependency is a standard `def` function instead of `async def`, it is run in the external threadpool.

### Sub-dependencies

You can have multiple dependencies and sub-dependencies requiring each other (as parameters of the function definitions), some of them might be created with `async def` and some with normal `def`. It would still work, and the ones created with normal `def` would be called on an external thread (from the threadpool) instead of being "awaited".

### Other utility functions

Any other utility function that you call directly can be created with normal `def` or `async def` and FastAPI won't affect the way you call it.

This is in contrast to the functions that FastAPI calls for you: *path operation functions* and dependencies.

If your utility function is a normal function with `def`, it will be called directly (as you write it in your code), not in a threadpool, if the function is created with `async def` then you should `await` for that function when you call it in your code.

---

Again, these are very technical details that would probably be useful if you came searching for them.

Otherwise, you should be good with the guidelines from the section above: <a href="#in-a-hurry">In a hurry?</a>.
